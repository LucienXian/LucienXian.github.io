<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="LucienXian's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="LucienXian&#39;s Garden">
<meta property="og:type" content="website">
<meta property="og:title" content="LucienXian&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="LucienXian&#39;s Blog">
<meta property="og:description" content="LucienXian&#39;s Garden">
<meta property="og:locale">
<meta property="article:author" content="LucienXian">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/"/>





  <title>LucienXian's Blog</title>
  














<meta name="generator" content="Hexo 6.3.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LucienXian's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-/tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/05/Scaling-Memcache-at-Facebook%E2%80%94%E2%80%94MIT6-824/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/05/Scaling-Memcache-at-Facebook%E2%80%94%E2%80%94MIT6-824/" itemprop="url">Scaling Memcache at Facebook——MIT6-824</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-05T00:03:08+08:00">
                2021-01-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="scaling-memcache-at-facebook">Scaling Memcache at Facebook</h1>
<blockquote>
<p>Memcache是一个有名的且简单的纯内存缓存方案。论文主要讲了Facebook基于Memcache来构建一个分布式kv存储来为它的社交网站服务，处理几十亿的QPS，存储了上万亿的数据项</p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>本文主要讲述了Facebook如何改进memcached的开源版本，这是一个全内存哈希表的开源实现，能够以较低的开销提供了对存储的访问。Facebook的目标之一是展现部署在不同规模系统的实现，同时需要保持性能、效率、容错能力和一致性。</p>
<h2 id="overview">Overview</h2>
<p>论文提到的设计面临的场景是：读多写少，需要能从多个数据源读取数据。</p>
<p>MemCached提供了一组简单的操作（set、get和delete），这使它能够成为大规模分布式系统重要的基础组件。开源版本是一个单机内存哈希表，本文基于这个开源版本构建了一个可以处理每秒数十亿请求的分布式的KV储存系统。下文将用“memcached”来指代它的源码或者它运行的二进制实例，用“memcache”来指代由每个实例构成的分布式系统。</p>
<p><img
src="https://pic.downk.cc/item/5ff33a4b3ffa7d37b349c45c.png" /></p>
<p><strong>Query
cache</strong>：依赖memcache来减轻读取数据库的负担。如上图所示，读取的时候先读memcache，不命中再读数据库，查询成功后会更新memcache。写请求则是写到数据库，接着发删除请求到memcache。</p>
<p><strong>Generic
cache</strong>：论文还讲了如何使memcache成为一个更加通用的kv系统，如保存机器学习算法的中间结果。</p>
<p><img
src="https://pic.downk.cc/item/5ff33a4b3ffa7d37b349c464.png" /></p>
<p>在系统的迭代中，论文考虑了两个重要的设计：</p>
<ul>
<li>只有对用户或者运维产生影响的问题，才值得优化；</li>
<li>系统可能会暴露轻微陈旧的数据以便后台免受高负载的影响；</li>
</ul>
<h2 id="in-a-cluster-latency-and-load">In a Cluster : Latency and
Load</h2>
<p>这一章主要聚焦于拉取缓存数据时的延迟和缓存不命中时带来的负载</p>
<h3 id="reducing-latency">Reducing Latency</h3>
<p>为了减轻数据库的负载，需要准备由数百台memcache机器组成的缓存集群，但多个web服务器对多台memcache服务器的关系，可能会在短时间内导致incast
congestion。数据副本可以缓解这种情况，但又会带来内存浪费。</p>
<p>因此论文中提到的减少延迟的方法主要集中在memcache客户端。</p>
<p><strong>Parallel requests and
batching</strong>：为了尽可能减少网络请求，该系统通过做拓扑图分析来表示数据间的依赖，整合将多个独立请求，并尽可能进行并发操作。</p>
<p><strong>Client-server
communication</strong>：memcached服务器之间并不会直接通信，而是相关控制逻辑集成到client上，memcache的client分为两个部分：sdk和一个叫mcrouter的的proxy，mcrouter在web服务器和memcached服务器之间，提供与memcached相同的接口。</p>
<p>考虑到对数据错误容忍度高，memcached
client的get请求使用UDP与memcached服务器通信，减少了创建和维护连接带来的开销。一旦出现丢包或者乱序包，client会将其作为异常处理，即视作cache
miss，get请求会被重传到数据库，论文中提到系统在高峰期也只有0.25%的请求会被丢弃。为了可靠性，对于set和delete，则是通过可靠的TCP通信。</p>
<p><strong>Incast congestion</strong>：对于Incast
congestion问题，memcached的client实现了类似TCP的拥塞控制逻辑，根据网络情况控制滑动窗口。</p>
<h3 id="reducing-load">Reducing Load</h3>
<p>为了减轻负载，论文提到了三种技术；</p>
<h4 id="leases">Leases</h4>
<p>文中引入了租约机制来解决下面两个问题：stale sets和thundering
herds，前者是保证了并发更新下的最终一致性，后者则是缓解惊群效应。</p>
<p>对于stale sets，是因为发生cache
miss的时候，并发读取数据库后需要重新写入到memcache，这样就可能出现过期的数据在数据被删除之后才写入，导致数据库和memcache内的数据不一致。通过引入租约，每次出现cache
miss的时候都会返回一个与key绑定的lease
id，当数据被删除后，之前发出的lease
id会失效，写入数据时，sdk需要带上上次收到的lease
id，根据该id是否失效来仲裁写入与否。</p>
<p>对于惊群效应，当数据出现热点的时候，可能会出现大量的cache
miss，导致数据库负载增大。memcache通过控制每个key的lease发送速率，比如每个key在10秒内只发送一个lease
id，在这期间有对这个key的请求时，会让客户端等待重试，这时数据可能已经被获得lease的给填上，这时就会重试成功。</p>
<p><strong>过期值</strong>：对于某些能接受过期数据的应用，memcache会将已经删除的数据短暂地保存到另一个数据结构中，此时web
server可以决定是等待新的数据还是读取过期数据，从而减轻负载。</p>
<h4 id="memcache-pools">Memcache Pools</h4>
<p>将memcache作为通用缓存意味着所有不同的workloads会共享这一设施，Facebook统计过更新频率高的key很可能会将更新频率低的key给逐出来。</p>
<p>考虑到这一点，Facebook将集群的memcache服务器分割成独立的池，一个默认pool，一个访问频率高但cache
miss成本低的small poll，一个访问频率低但cache miss成本高的large
pool。</p>
<h3 id="replication-with-in-pools">Replication With in Pools</h3>
<p>对于某些pool，可以通过数据冗余的方式来提高请求的并发能力。</p>
<p>###Handling Failures</p>
<p>论文对于故障处理主要提到了两个维度的故障：网络故障和集群自身服务器宕机。</p>
<p>对于少数几个server宕机或者网络故障，Facebook主要依赖一个自动恢复机制，如果大规模的停机，Facebook会将用户请求直接转移到另一个数据中心。为了避免在自动恢复的那几分钟里对数据库或者后台服务带来的雪崩，memcached的client会将请求转移到Gutter机器上接管故障服务器的能力。</p>
<p>一般来说，每次失败的请求都会导致转移到Gutter的存取，从而减轻数据库的负载。</p>
<h2 id="in-a-region-replication">In a Region: Replication</h2>
<p>随着流量的增大，需要对Memcached做横向扩展，并且能够解决key的热点问题和网络incast
congestion，论文在replication和sharding之间做了取舍，选择了将memcached
servers切分成多个集群，这一个memcached集群、前端访问集群还有共享存储集群统称为region。</p>
<h3 id="regional-invalidations">Regional Invalidations</h3>
<p>考虑到由于存在多个memcached
server集群，需要确保数据的一致性，避免同一条数据的不同版本出现在不同集群上。论文的做法是，监控MySQL，一旦出现数据被删除或者更新，且事务提交，那么对应key就会被一个mcsqueal守护进程记录（读取MySQL的commit
log），然后批量地将删除明亮发送给对应的Memcached实例。</p>
<p><img
src="https://pic.downk.cc/item/5ff33a4b3ffa7d37b349c46b.png" /></p>
<h3 id="regional-pools">Regional Pools</h3>
<p>考虑对部分数据的QPS很低，Facebook的做法是不把所有数据在一个region内存储多份冗余，而是在单个region内划分出一个pool来存储那些访问率低的数据。</p>
<h3 id="cold-cluster-warmup">Cold Cluster Warmup</h3>
<p>由于现有集群需要进行定期维护，在新集群上线时，缓存命中率会很低。Facebook构建了一个Cold
Cluster Warmup的系统，在新集群发生cache
miss时从热集群中加载数据，而不是去读持久化存储。</p>
<h2 id="across-regions-consistency">Across Regions: Consistency</h2>
<p>Facebook在全球都有数据中心，因此每个数据中心都会有若干个region来服务用户。基于MySQL的复制机制，Facebook将一个region设为master，其他的都是只读region，web
servers请求的时候只会访问本地的DB或者memcache。至于写入，所有的请求只是发给master处理，然后mysql再将其同步到从region。这样就可能带来一致性的问题，即从region的memcache一直保留着过期数据。</p>
<p>对于这种场景，该系统保持一致性的方法是：</p>
<ul>
<li><p>如果在master
region写，前端集群收到更新，请求转发到数据库，同时删除本集群的memcache记录。数据库的进程同步修改到其他集群，其他region删除过期的记录；</p></li>
<li><p>在非master region写数据d：</p>
<ul>
<li>本地的memcache会设置remote marker，rd；</li>
<li>将d写到master region的db；</li>
<li>将d从memcache中删除；</li>
<li>等待master DB同步带有rd信息的数据到非master DB；</li>
<li>该非master DB通过解析数据，然后删除掉rd；</li>
</ul>
<p>在这个过程中，非master region有对该数据d进行读取，并发生cache
miss时，如果发现了数据带有rd，则直接跨region访问master
DB，否则直接读取本地DB。</p></li>
</ul>
<h2 id="总结">总结</h2>
<p>论文主要是基于memcache技术来满足Facebook的业务需求，有很多取舍在优化线上系统性能时都非常值得参考。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/05/Resilient-Distributed-Datasets-A-Fault-Tolerant-Abstraction-for-In-Memory-Cluster-Computing%E2%80%94%E2%80%94MIT6-824-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/05/Resilient-Distributed-Datasets-A-Fault-Tolerant-Abstraction-for-In-Memory-Cluster-Computing%E2%80%94%E2%80%94MIT6-824-1/" itemprop="url">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing——MIT6-824</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-05T00:02:46+08:00">
                2021-01-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1
id="resilient-distributed-datasets-a-fault-tolerant-abstraction-for-in-memory-cluster-computing">Resilient
Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster
Computing</h1>
<blockquote>
<p>本文提出了一种称之为RDDs的分布式内存抽象，以此解决在大规模集群中以容错的方式提供内存计算的方式。当前的计算框架对于迭代算法和交互式数据挖掘的效率都很低，RDDs通过将数据留在内存来提高性能。本文通过Spark系统来实现RDDs。</p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>诸如MapReduce
和Dryad之类的集群计算框架已被广泛用于大规模数据分析。这些系统使用户可以使用一组高级API来编写并行计算，而不必担心工作分配和容错能力。</p>
<p>尽管当前的框架为集群的计算资源提供了许多抽象，但它们还是缺乏对利用分布式内存的抽象。这就导致了在多个计算之间复用中间结果时，显得非常低效。数据重用在许多迭代机器学习和图计算中很常见。另外在交互式数据挖掘中，用户会需要对数据的同一子集运行多个临时查询。然而在大多数框架中，在计算之间（例如在两个MapReducce作业之间）重用数据的唯一方法是将其写入外部稳定的存储系统，例如分布式文件系统。由于数据复制，磁盘IO和序列化，这会导致相当大的开销，这可能会影响应用程序的执行时间。</p>
<p>在这篇论文中提出了一个全新的抽象，叫做RDDs(Resilient Distributed
Datasets)，它可以在广泛的应用程序中实现有效的数据重用。RDDs
是一个可以容错且并行的数据结构，它可以让用户显式的将中间结果数据集保存在内中。</p>
<p>现存的分布式内存抽象系统，都是基于对可变状态的细粒度更新。这种接口保证容错的方式无非是将数据进行多副本备份，需要在机器节点间复制大量的数据，宽带传输数据的速度远远比RAM
内存慢。</p>
<p>与这些系统相比，RDD提供了基于粗粒度转换的接口（map，reduce，filter）。这些接口可以对多条数据条目应用相同的操作，这样就可以通过记录来生成某个数据集的一系列转换，而不是记录真实的数据。如果RDD丢失，则RDD具有足够的有关如何从其他RDD派生的信息，可以仅重新计算该分区。因此，丢失的数据通常可以很快恢复。</p>
<h2 id="resilient-distributed-datasets">Resilient Distributed
Datasets</h2>
<p>本章主要介绍RDD和Spark编程接口，并与细粒度共享内存做对比。</p>
<h3 id="rdd-abstraction">RDD Abstraction</h3>
<p>RDD是一个只读的、可分区的数据集，可以通过对稳定的存储系统或者其他的RDD进行操作来创建一个新的RDD，这些操作称之为transformations，比如map，filter
以及join。另外用户可以控制RDD的存储和分区，指定存储策略，也可以根据key做hash来做数据分区。</p>
<h3 id="spark-programming-interface">Spark Programming Interface</h3>
<p>Spark通过集成编程语言API来表示RDD，每一个数据集就是一个对象，通过对象的方法来操作对象。RDD有两种操作，一种是上面说的transformations，另一种则是action，action操作可以得到应用结果值，比如count可以返回数据集的元素个数、collect返回数据集的所有元素以及save则是将输出结果写入到存储系统中。</p>
<p>Spark定义RDDs是并不会计算，只是采取lazy特性，可以将transformations组成pipeline，触发了actions操作才会真正计算。用户可以通过RDDs的preset方法来缓存数据，也可以调整缓存策略。</p>
<h3 id="advantages-of-the-rdd-model">Advantages of the RDD Model</h3>
<p>论文将RDD和分布式共享内存系统DSM做了比较，RDD只能粗粒度的操作转换，而DSM可以在任意内存位置进行写入。这样RDD的容错机制更加高效，不需要发生非常耗时的checkpoint，只需重新计算丢数据的分区。另外一个好处就是任务备份比较简单，因为RDD是不变的。还有就是，RDD可以进行进行任务调度来提高大批量的写入效率，在scan-base的操作中也能根据需要将内存数据写到磁盘中。</p>
<h3 id="applications-not-suitable-for-rdds">Applications Not Suitable
for RDDs</h3>
<p>RDD更适合批量的数据处理场景，并不适合于需要异步且细粒度的更新共享状态的应用。</p>
<h2 id="spark-programming-interface-1">Spark Programming Interface</h2>
<p>Spark提供了一个用Scala编写的语言集成API。为了使用Spark，开发者编写了一个driver，该driver会连接workers集群，并定义若干个RDDs，在RDDs上执行action，在driver上的Spark代码会追踪RDDs的lineage。workers是一直运行的进程，能在内存中存储RDD分区。</p>
<h3 id="rdd-operations-in-spark">RDD Operations in Spark</h3>
<p>下图列出了Spark中RDD的transformations和actions操作。transformations是定义新RDD的lazy操作，而actions才是真正计算结果或者写数据到外部存储；</p>
<p><img
src="https://pic.downk.cc/item/5ff33b793ffa7d37b34abc98.png" /></p>
<h2 id="representing-rdds">Representing RDDs</h2>
<p>抽象RDDs会带来一个问题：如何在广泛转换中表示追踪lineage。理想情况下，一个实现RDDs的系统应该能够提供丰富的·转换算子，用户可以以任意方式进行组合。在Spark中则是提出了一个简单的图表示来达到以上目的。</p>
<p>论文提出了一个通用接口去表示RDD，接口表达了五种信息：</p>
<ul>
<li>一组分片（partitions），数据集的原子组成；</li>
<li>一组父RDDs上的依赖；</li>
<li>一个基于父数据集计算的函数；</li>
<li>分片策略元数据，一个分片函数partitioner；</li>
<li>数据位置策略，存储每个partition的优先位置；</li>
</ul>
<p>论文将RDDs之间的依赖分为了两类：</p>
<ul>
<li>窄依赖：父RDD的每个分片被子RDD至多一个分片使用；</li>
<li>宽依赖：多个子分片依赖一个父分片；</li>
</ul>
<p>例如，代表HDFS文件的RDD对文件的每个块都有一个分片，并且通过数据位置策略知道每个块在哪台计算机上。</p>
<figure>
<img src="https://pic.downk.cc/item/5ff33b793ffa7d37b34abcd2.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>窄依赖能在一个节点上流水线执行，节点故障的时候也能高效地通过重新计算父分片来进行恢复；而宽依赖，单一节点故障可能会导致一个RDD的所有祖先分片丢失，需要完全重新执行。</p>
<h2 id="implementation">Implementation</h2>
<p>Spark可以从任何的Hadoop输入源中读取数据，比如HDFS和HBase。本章主要关注下面的几个部分：任务调度、Spark解释器的交互式使用、内存管理和checkpoint。</p>
<h3 id="job-scheduling">Job Scheduling</h3>
<p>Spark的调度器与Dryad类似，另外还会考虑持久化了的RDD的哪些分片在内存中可用。任何时候用户在RDD上执行action，调度器就会检查RDD的lineage，建立由stages组成的DAG，然后执行这个图。调度器会使每个stage包含尽可能多的窄依赖，stages的边界是宽依赖shuffle操作，或者任何计算过的分片。</p>
<figure>
<img src="https://pic.downk.cc/item/5ff33b793ffa7d37b34abd14.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>调度器会根据数据存放位置使用延迟调度给机器指派任务。</p>
<p>若一个任务失败了，只要stage的父分片还在，就可以在另一个节点重新运行。如果一些stages都不可用了，就需要重新提交任务去并行计算丢失分片。</p>
<h3 id="interpreter-integration">Interpreter Integration</h3>
<p>Scala包含一个类似于Ruby和Python的交互式shell，考虑到内存数据的低延迟，Spark可以让用户在解释器上运行。</p>
<p>Spark中的编译器相对Scala做了一些改变：</p>
<ul>
<li>类传输：通过HTTP传输创建类的字节码；</li>
<li>代码生成：代码生成的单例对象是通过生成类的静态方法访问的，为了避免序列化一个访问不到前面定义变量的闭包，Spark将代码生成逻辑改成直接引用每行对象的实例；</li>
</ul>
<figure>
<img src="https://pic.downk.cc/item/5ff33b793ffa7d37b34abd29.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="memory-management">Memory Management</h3>
<p>Spark对RDD的持久化提供了三个选项：</p>
<ul>
<li>序列成Java对象，存在内存中；性能最好</li>
<li>作为序列化数据存在内存中；内存空间有限时使用</li>
<li>存在硬盘中；RDDs过大无法存入内存</li>
</ul>
<p>当计算新的RDD分片后，如果没有足够空间去存储，就会基于LRU的淘汰策略去淘汰一个分片。但如果新旧分片属于同一个RDD，则会将旧的分片写入内存，避免相同RDD的分片循环读写。</p>
<h3 id="support-for-checkpointing">Support for Checkpointing</h3>
<p>虽然lineage可以帮助恢复RDDs，但如果lineage很长的时候就会变得很耗时，因此RDD可以执行checkpoint存入稳定内存。</p>
<p>Spark为checkpoint提供了一个API，让用户决定checkpoint哪个数据。同样，Spark的调度器也制定每个数据集大小，了解第一次计算的耗时，因此也会基于一定的策略选择一个优化RDDs集合来执行checkpoint，缩短系统恢复时间。</p>
<h2 id="总结">总结</h2>
<p>本文主要介绍了一个在集群中共享数据的高效的、具备容错能力的的抽象——RDD。RDD能表达通用的并行应用，提供了一个基于粗粒度转换的API，也能通过lineage来快速恢复数据。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/15/No-compromises-distributed-transactions-with-consistency-availability-and-performance%E2%80%94%E2%80%94MIT6-824-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/15/No-compromises-distributed-transactions-with-consistency-availability-and-performance%E2%80%94%E2%80%94MIT6-824-1/" itemprop="url">No compromises distributed transactions with consistency, availability, and performance——MIT6-824</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-15T01:43:49+08:00">
                2020-11-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1
id="no-compromises-distributed-transactions-with-consistency-availability-and-performance">No
compromises: distributed transactions with consistency, availability,
and performance</h1>
<blockquote>
<p>强一致性和高可用性的事务简化了分布式系统的构建，但在从前，分布式事务的设计实现不大理想，这就迫使以前构建分布式系统的时候抛弃分布式事务或者使用弱一致性，或者使用单机事务，要求业务方通过数据分区的方式，保证事务数据落在一个机器上。</p>
<p>本文一个名为FaRM的内存分布式计算平台，具备以下特性：强序列化，高性能，持久性和高可用性。</p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>具有高可用性和强序列化的事务通过简单的抽象来简化了分布式系统的编程和推理：单机永不失败，一次执行一个实时同步的事务。但是，先前在分布式系统中实现此抽象的尝试都导致了较差的性能。因此，诸如Dynamo或Memcached之类的系统通过不支持事务或实施弱一致性保证来提高性能。其他系统仅在所有数据都驻留在一台机器中时才提供事务。</p>
<p>本文证明了现代数据中心中的新软件可以消除折衷的要求。它在一种称为FaRM的内存分布式计算平台中描述了事务，复制和恢复协议。
FaRM为分布式ACID事务提供严格的可简化性，高可用性，高吞吐量和低延迟。FaRM平台利用了两个趋势：带有RDMA的网络和提供非易失性DRAM，消除了存储和网络瓶颈，并通过减少消息数量，使用单面RDMA读写存储而不是消息以及有效利用并行性，来解决CPU瓶颈。</p>
<p>FaRM允许数据分布在不同机器，同时允许事务跨越任何数量的机器。FaRM通过使用vertical
Paxos，而不是通过Paxos协议进行coordinators和数据的复制，此时副本是主-备，然后协调者是单个，不进行复制。FaRM使用具有四个阶段提交协议（锁定，验证，提交备份和主要提交）。</p>
<p>在事务执行和验证期间和在事务中修改的对象副本上将记录记录到非易失性预写日志WAL时，都会使用RDMA，避免了本地CPU开销。不再需要CPU参与，意味着传统的故障恢复（failure-recovery）协议不再适合FaRM，因此文章使用了precise
membership的解决方案：保证所有机器都在当前membership
configuration上达成一致，并且只会发送请求给组员。</p>
<p>FaRM中的故障恢复速度很快，因为它有效地利用了并行性。它在集群中平均分配恢复的数据，并在每台计算机之间并行进行恢复。</p>
<h2 id="hardware-trends">Hardware trends</h2>
<p>FaRM的设计受到数据中心机器中大量廉价DRAM的推动。FaRM利用两种硬件趋势来消除存储和网络瓶颈：非易失性DRAM和具有RDMA的网络。</p>
<h3 id="non-volatile-dram">Non-volatile DRAM</h3>
<p>distributed uninterruptible power supply
(UPS)利用锂离子电池的广泛可用性来降低数据中心UPS的成本，与传统的UPS相比，这种方法更加可靠：锂离子电池配备了多个独立的电池单元，并且电池故障仅会影响机架的一部分。</p>
<p>分布式UPS有效地使DRAM持久耐用。发生电源故障时，分布式UPS使用电池中的能量将内存内容保存到SSD中。这不仅避免了对SSD的同步写入，从而提高了常见情况的性能，而且还通过仅在发生故障时对其进行写入来延长SSD的寿命。另一种方法是使用非易失性DIMM（NVDIMM），它们包含自己的专用闪存，控制器和超级电容器，但这种设备成本更高。</p>
<p>FaRM将所有数据存储在内存中，并在将其写入多个副本上的NVRAM中时，将其作为持久数据。</p>
<h3 id="rdma-networking">RDMA networking</h3>
<p>FaRM尽可能使用单边RDMA操作，因为它们不使用远程CPU。与RPC相比，RDMA的读取性能更高，并且消除了NIC消息速率瓶颈。但RPC和RDMA与CPU有关，减少CPU开销能更好释放新硬件的潜力。</p>
<h2 id="programming-model-and-architecture">Programming model and
architecture</h2>
<p>FaRM提供了一个全局的抽象地址空间，提供对事务中本地和远程对象的透明访问。应用程序线程可以随时启动事务，而后会成为事务的协调者。在事务执行期间，线程可以执行任何逻辑，包括读取，写入，分配和释放对象。在执行结束时，线程调用FaRM提交事务。</p>
<p>FaRM事务使用乐观并发控制，更新在执行期间会缓冲在本地，并且仅在成功提交后才对其他事务可见，FaRM对成功提交的事务提供了严格的串行性。至于读，FaRM保证对单个对象操作的原子性，每次读总能返回最新的值。不同对象间的读取不保证原子性，但保证严格串行。</p>
<p>下图显示了具有四台计算机的FaRM实例和机器A的内部组成。每台机器在用户进程中运行FaRM，且内核线程固定在每个硬件线程上。每个内核线程运行一个事件循环，该循环执行应用程序代码并轮询RDMA完成队列。</p>
<p><img
src="https://pic.downk.cc/item/5fa03c371cd1bbb86b8e1d77.png" /></p>
<p>扩缩容的时候，FaRM实例会随着时间推移逐步进行一系列配置，配置是⟨i, S,
F ,
CM⟩，其中i是唯一单调递增的64位配置id，S是配置的机器集合，F是Pair&lt;机器,
独立故障域&gt;，CM是配置管理机器。FaRM使用Zookeeper来确保机器就当前配置达成一致并进行存储，但是它不像通常那样依靠Zookeeper来管理租约，检测故障或协调恢复。
而是使用配置管理器通过RDMA快速恢复来负责。</p>
<p>FaRM的全局内存以2GB进行划分，每个2GB称为一个region，每个region保存在1个primary和f个backups上，每个region存储在非易失内存中，能够被其他机器通过RMDA直接读取。一般会先读primary，如果在本地有就读本地内存，远程有就读RDMA。region到primary-backups的映射关系信息则是保存在CM上。</p>
<p>机器可以与CM联系分配新区域。CM从单调递增的计数器分配region
id，为该区域选择副本，并尽可能平衡各个机器的region数。与一致性哈希的方法相比，这种集中式方法提供了更大的灵活性来满足故障独立性和局部性约束。它还使平衡机器之间的负载和接近容量运行变得更加容易。</p>
<p>每台机器还存储基于FIFO队列的环形缓冲区，用于事务日志或消息队列。每个发送方-接收方对都有自己的日志和消息队列，但物理上位于接收方处。发送方通过RDMA直接写到尾部，然后NIC直接回ACK，接收方则周期性的从头部读取数据处理。</p>
<h2 id="distributed-transactions-and-replication">Distributed
transactions and replication</h2>
<p>FaRM结合了事务协议和副本协议来提高性能，并利用单端RDMA读写来提高cpu的有效性和低延迟。FaRM在非易失的内存中使用主备副本协议来存储数据和事务日志，协调器没有副本，并且协调器会直接和主备副本进行通信。在执行阶段，事务使用单面RDMA（如果与协调器在同一个机器则使用本地内存）读取对象，并且它们在本地缓冲写操作，下图是FaRM事务的执行时间表：</p>
<p><img
src="https://pic.downk.cc/item/5fa803141cd1bbb86b451dff.png" /></p>
<p>执行结束后，通过以下步骤进行提交：</p>
<ol type="1">
<li>lock：协调器将LOCK记录（版本、新值和region列表）写入所有被修改对象的primary中。然后primary会使用CAS尝试锁住这些对象的指定版本，返回是否锁成功的消息。如果自从事务读取对象以来发生任何对象版本的更改，或者当前对象已被另一个事务锁定，则锁定可能失败，协调器终止事务；</li>
<li>Validate：协调器对事务内所有的只读对象进行读校验，从这些只读对象的primary发起RMDA读或RPC读。默认情况下使用单面RDMA读取，只读对象的数量超过4个，则使用RPC。如果版本号变更了，事务就被终止；</li>
<li>Commit backups：通过RDMA写log到所有backups，等待网卡的确认；</li>
<li>Commit primaries：在确认所有COMMIT-BACKUP写入之后，协调器将Commit
primaries记录写入每个primary的日志中，收到至少一个响应，协调器马上返回给应用成功。primary通过更新对象，增加其版本并对其进行解锁来处理这些记录，从而完成了事务所提交的写入；</li>
<li>Truncate：协调器在收到来自所有primary的确认后，会延迟地truncate事务内的primary和backup的日志；</li>
</ol>
<p>正确性；</p>
<p>在获取所有写锁时，已提交的读写事务是串行的，这是在串行点上所有读取和写入对象的版本与执行期间看到的版本相同。锁阶段保证了写对象的串行性，而校验阶段保证了只读对象的串行性，在没有失败的情况下，这等效于在串行点原子地执行和提交整个事务。</p>
<p>为了确保故障时的串行性，必须在写入COMMIT-PRIMARY之前等待所有backup的确认。否则当某些COMMIT-BACKUP失败，且协调器故障了，就会丢失记录。</p>
<p>由于读的集合只保存在协调器中，一旦协调器挂了就没有commit记录可以证明验证成功了，这样就会导致事务abort。所以协调器等待一个primary的提交成功才会响应给client成功。这样能避免f个backup和coordinator一起挂了使得锁记录保存但丢失校验没成功的记录。</p>
<p>传统的二阶段提交协议，可以在准备阶段去检查有没有资源。但FaRM因为只用单边RDMA，无法使用远程CPU，因此必须要保留空间去记录所有的提交协议记录，包括在开始commit之前截断primary和backup的记录。日志保留是协调器上的本地操作，因为协调器会将记录写入其在每个参与者处拥有的日志中，写完相应记录之后会释放保留空间。</p>
<h3 id="failure-detection">Failure detection</h3>
<p>FaRM使用租约机制来检测故障。除CM之外，每台机器都在CM处拥有租约，而CM则对其他所有机器拥有租约，这是一个双向租约的机制。租约使用三次握手的方式授权，每台机器向CM发送一个租约请求，CM返回的响应消息即代表对机器的授权，也是CM对该机器的租约请求，最后该机器授权租约给CM。</p>
<p>FaRM租期非常短，这是高可用性的关键。在高负载下，FaRM可以为90台计算机群集使用5毫秒的租约，而不会产生误报。</p>
<p>为了在高负载的情况下获得短期租约，FaRM使用专门的队列来支持租约，这样就能避免租约消息的延迟。另外为了避免性能的影响，FaRM的租约管理器通过无连接的不可靠数据包去发送和接收租约。默认情况下，租约的延续一般是租约超时周期的五分之一。</p>
<p>续租还必须及时在CPU上定时调度，FaRM使用专用的租约管理器线程，该线程以最高的用户空间优先级运行，并且租约管理器线程没有固定到任何的硬件线程，它使用中断而不是轮询来避免在每个硬件线程上定期运行的关键OS任务饿死，导致误报租约过期。虽然增加了几毫秒的消息延迟，但对于租约来说不是问题。</p>
<p>最后，在初始化期间预先分配租约管理器使用的所有内存，然后分页并固定其使用的所有代码，以避免由于内存管理而造成的延迟。</p>
<h3 id="reconfiguration">Reconfiguration</h3>
<p>重新配置协议将FaRM实例从一种配置移到另一种，FaRM使用了RDMA操作来保证极高的性能，因为缺少CPU的使用，因此无法利用租约机制来实现一致性。FaRM使用的是精确的成员身份来实现这个问题，发生故障后，采用新配置的所有计算机必须先同意其成员身份，然后才能进行对象更改。这就允许了在客户端做检查而不是服务端。配置中的计算机不会向不在其中的计算机发出RDMA请求，并且也会忽略配置中不再存在的计算机做回应。</p>
<p><img
src="https://pic.downk.cc/item/5fb00c44ef76db7fe8909662.png" /></p>
<ol type="1">
<li>猜测：当CM上的一个机器租约过期时，CM会猜测那个机器挂了，并初始化重新配置，这个时间点开始阻塞所有外部客户端的请求。如果一个非CM机器上的租约过期了，它会推断CM挂了，这个非CM租约上的机器会尝试请求少量的CM备机去初始化配置。如果超时后配置未更改，则它将尝试重新配置自身。这种设计避免了在CM故障时会有大量机器同时尝试重新配置，在所有情况下，启动重新配置的机器都将尝试成为新的CM，作为重新配置的一部分。</li>
<li>探测：新的CM向配置中的所有机器发出RDMA读取，除了前面猜测故障的机器和读失败的机器，这些读取探测允许通过一次重新配置来处理影响多台机器的相关故障，例如电源和开关故障。新CM仅在获得大多数响应后才继续进行重新配置。这样可以确保如果网络已分区，则CM不会位于较小的分区中。</li>
<li>更新配置：CM尝试更新zk的配置为 ⟨c + 1, S, F ,
CM(id)⟩，c是当前的配置版本号id，S是探测有返回的机器列表，F是故障域映射，CM(id)是自己的id。FaRM使用zk的znode序列号去实现原子的CAS，只有当前配置的的版本仍然是c是，CAS才成功。</li>
<li>重新映射区域：新CM重新分配先前映射到故障机器的区域，以将副本数恢复到f
+
1。它尝试平衡负载并满足容量和故障独立性约束的应用程序指定的局部性提示。对于失败的主数据库，它会将尚存的备份升级为新的主数据库，以减少恢复时间。如果它检测到丢失了所有副本的区域，或者没有空间可以重新复制区域，则会发出错误消息。</li>
<li>发送新配置：重新映射区域后，CM会使用配置标识符，其自身的标识符，配置中其他机器的标识符以及区域到机器的所有新映射，向配置中的所有机器发送NEW-CONFIG消息。并根据需要重置租约或者进行租约交换；</li>
<li>应用新配置：当机器收到配置标识符大于其自身配置的NEW-CONFIG时，它将更新其当前配置标识符及其区域映射的缓存副本，并分配空间以容纳分配给它的所有新区域副本。同时还会给CM进行租约的授权。</li>
<li>提交新配置：一旦CM从配置中的所有计算机接收到NEW-CONFIG-ACK消息，它会等待所有不在新配置中的机器的租约过期。然后CM向所有配置成员发送NEW-CONFIG-COMMIT，和第6步租约申请的授权，最后所有成员解锁外部客户端请求；</li>
</ol>
<h3 id="transaction-state-recovery">Transaction state recovery</h3>
<p>在配置更改后，FaRM使用事务修改的对象副本之间的日志来恢复事务状态。这涉及到事务修改的对象副本和协调器恢复状态，以决定事务的结果。</p>
<p><img
src="https://pic.downk.cc/item/5fb016c63e3fc2acb7182059.png" /></p>
<ol type="1">
<li>阻塞访问正在恢复的region：当一个primary的region挂了，其中一个备份就会被提升为primary，在所有更新该region的操作都反映到该primary之前都不允许访问该region；</li>
<li>清除日志：单面RDMA写一般会和故障恢复冲突，FaRM无法通过网卡来拒绝来自旧配置的消息，只能在收到NEW-CONFIG-COMMIT消息时清除所有的日志记录，然后拒绝新来的日志；</li>
<li>找到正在恢复的日志：</li>
<li>锁定恢复：region的每个primary会等本地机器日志被排出，并且从所有backup中收到NEED-RECOVERY消息，然后primary并行地从backup中拉取任意的、本地没有存储的事务日志记录，并对任何被恢复事务修改的对象进行锁定。当锁定恢复完成了一个region时，这个region就可以被本地或远程的coordinator获得本地指针和RDMA引用；</li>
<li>备份日志记录：在primary中的线通过发送REPLICATE-TX-STATE消息给backup来备份日志记录；</li>
<li>投票：恢复事务的coordinator基于每个被该事务修改的region的投票决定是否提交或abort事务；</li>
<li>决定：如果从所有region收到了commit-primary，coordinator就会决定提交事务；如果至少有一个region投票了commit-backup并且所有其他的被事务修改的region提交了lock或commit-backup或truncated，则等待所有region去投票和提交；其他情况会abort；</li>
</ol>
<h3 id="recovering-data">Recovering data</h3>
<p>FaRM一定会将region数据复制数据到新的backup上，以便将来能容忍f个故障。一个region的一个新的backup初始化空间为0。region被划分给worker线程并行地恢复数据。每一个线程发出一个单端RDMA操作去读primary的一个block。每个恢复对象被复制到backup之前都会做版本检查，然后使用CAS更新对象状态。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/21/Spanner-Google%E2%80%99s-Globally-Distributed-Database%E2%80%94%E2%80%94MIT6-824/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/21/Spanner-Google%E2%80%99s-Globally-Distributed-Database%E2%80%94%E2%80%94MIT6-824/" itemprop="url">Spanner: Google’s Globally-Distributed Database——MIT6-824</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-08-21T00:50:14+08:00">
                2020-08-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="spanner-googles-globally-distributed-database">Spanner: Google’s
Globally-Distributed Database</h1>
<blockquote>
<p>Spanner是谷歌提出的一个可扩展、多版本、全球分布和支持同步复制的数据库。这是第一个在全球范围内分发数据并支持外部一致性的分布式系统</p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>Spanner作为一个数据库，它由遍布全球的数据中心的许多Paxos状态机进行数据分片。Spanner会随着数据量或者服务器数量的变化自动在计算机之间重新分片数据，并自动在计算机之间迁移数据。应用程序可以通过跨大洲复制数据的方式来使用Spanner实现高可用性。</p>
<p>Spanner的主要重心在于管理跨数据中心的复制数据，但也花了不少时间在分布式系统架构上设计和实现重要的数据库功能。</p>
<p>作为全球分布的数据库，Spanner提供了一些有趣的功能。应用程序可以细粒度动态地控制数据的复制配置，支持在数据中心透明地移动数据，平衡资源使用，也对外提供外部一致的读写等等。</p>
<p>Spanner会为事务分配具有全局意义的提交时间戳，这里关键因素是新的TrueTime
API及其实现。下面会重点介绍。</p>
<h2 id="implementation">Implementation</h2>
<p>本章主要介绍Spanner实现的基础架构和原理。然后描述了目录抽象，最后则是描述了数据模型。</p>
<p>一个Spanner的部署被称为Universe，Spanner则被组织为一组区域，这是管理部署的单位和物理隔离的单位。下图描述了Spanner
Universe的服务器，一个区域具有一个zone
master和若干个spanserver，通过location
proxy来定位提供服务的spannerver。universe master 和 placement
driver则是一个单例，前者主要是一个控制台，后者则是定期与spanserver通信，以找出需要移动的数据。</p>
<p><img
src="https://pic.downk.cc/item/5f15cfcd14195aa594670175.png" /></p>
<h3 id="spanserver-software-stack">Spanserver Software Stack</h3>
<p>这一章主要讲spanserver的实现，软件架构如图所示，底部为每个spanserver负责的100-1000个称为tablet的数据结构，它实现了一组以下的的映射：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(key:string, timestamp:int64) → string</span><br></pre></td></tr></table></figure>
<p>tablet的状态存储在一个类似B树的文件和一个预写日志中，所有这些都存在一个叫Colossus的组件里。</p>
<p><img
src="https://pic.downk.cc/item/5f17213614195aa594fd18a2.png" /></p>
<p>为了支持复制，Spanserver都在每个tablet的顶部实现了Paxos状态机，用来存储其元数据和tablet的日志。这里的Paxos实现通过基于时间的leader租约来支持生命周期长的leader。Spanner的实现中会写两次Paxos日志，一次在tablet中，一次在Paxos日志里。</p>
<p>在leader副本中，Spanserver会实现一个锁表来做并发控制，这包含了两阶段锁的状态，能将key的范围映射到锁的状态。需要同步的操作（例如事务性读取）会在锁表中获取锁；其余操作绕过锁表。</p>
<p>另外，在leader副本中，spansever还实现了一个事务管理器来支持分布式事务。如果一个事物仅仅涉及到一个Paxos组，则可以绕过事务管理器。否则这些组的leader会协调执行两阶段提交。</p>
<h3 id="directories-and-placement">Directories and Placement</h3>
<p>在一系列键值映射的上层，Spanner
实现支持一个被称为“目录”的桶抽象，为包含公共前缀的连续键的集合。一个目录是数据放置的基本单位，同一个目录下的所有数据具有相同的副本配置。当数据在不同的paxos组间移动时，会进行逐个目录的移动。如下图所示：</p>
<p><img
src="https://pic.downk.cc/item/5f1c387614195aa594c3a268.png" /></p>
<p>一个Paxos组包含了若干个目录，tablet不一定是一个行空间内按照字典顺序排序的分区，可以是行空间内的多个分区。Movedir
是一个后台任务，用来在不同的 Paxos
组之间转移目录，也可以用来为Paxos组增加或删除副本。</p>
<p>一个目录也是应用可以指定的放置策略的最小单元，一个应用就可以控制数据的复制。例如，一个应用可能会在自己的目录里存储每个终端用户的数据，这就有可能使得用户
A 的数据在欧洲有三个副本，用户 B 的数据在北美有 5 个副本。</p>
<p>当一个目录变得太大时，Spanner会进行分片存储。每个分片可能被保存到不同的Paxos组。Movedir在不同组之间不再是转移目录，而是转移分片。</p>
<h3 id="data-model">Data Model</h3>
<p>Spanner暴露给应用的数据特性包括了：基于模式化的半关系表数据模型，SQL类型的查询语言和通用事务。</p>
<p>应用的数据模型是在被目录桶装的键值层之上，一个应用会在一个universe中创建若干个数据库，每个数据库可以包含无限的模式化表。每个表都和关系数据库表类似，具备行、列和版本值。</p>
<h3 id="truetime">TrueTime</h3>
<table>
<thead>
<tr class="header">
<th>Method</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>TT.now()</td>
<td>TTinterval: [earliest, latest]</td>
</tr>
<tr class="even">
<td>TT.after(t)</td>
<td>true if t has definitely passed</td>
</tr>
<tr class="odd">
<td>TT.before(t)</td>
<td>true if t has definitely not arrived</td>
</tr>
</tbody>
</table>
<p>本章主要讲TrueTime
API，但更多的内容在另一篇论文里。上面的表列出了API的方法，TrueTime是一款高度可用的分布式时钟，面向所有Google服务器上的应用提供，会把时间表达成一个时间区间TTinterval，具有一个有限的时间不确定性。TT.now()方法会返回一个
TTinterval，它可以保证包含调用TT.now()方法时的绝对时间。</p>
<p>在底层，TrueTime使用的时间是基于GPS和原子钟实现的，这两种类型的时间具有不同的失败模式。GPS的弱点是天线和接收器失效、局部电磁干扰等等。而由于频率误差，在经过很长的时间以后，原子钟也会产生明显误差。</p>
<p>TrueTime是由每个数据中心里的许多time
master机器和每个机器上的一个timeslave
daemon实现的。大多数master都具备专门的相互隔离的GPS接收器，而剩余的master则会配置了原子钟。所有master的时间参考值会进行彼此校对，每个master也会交叉检查时间参考值和本地时间的比值，如果二者差别太大，就会把自己踢出去。</p>
<p>每个daemon会从许多master中收集投票，获知时间参考值，根据确定的界限，来剔除本地时钟误差较大的机器。</p>
<p>在同步期间，一个daemon会表现出逐渐增加的时间不确定性。ε是从应用的最差时钟漂移中得到的。ε取决于time
master的不确定性，以及与time
master之间的通讯延迟。论文提到的线上应用环境里，ε通常是一个关于时间的锯齿函数，在1到7ms之间变化。</p>
<h2 id="concurrency-control">Concurrency Control</h2>
<p>本章主要讲trueTime是如何保证并发控制的正确性，简单来说则是实现这样的特性：在时间戳为t的读操作，一定能看到在t时刻之前提交的事务。</p>
<h3 id="timestamp-management">Timestamp Management</h3>
<p>Spanner支持三种操作类型：读写事务、只读事务和快照读取。独立的写操作会被当作读写事务执行，而非快照的独立读取操作则会被当作只读事务执行。</p>
<p>一个只读事务是不需要锁机制的，通过选取系统的时间戳来执行，不会阻塞后续到达的写操作。而快照读操作同样不需要锁机制。这两个都可以在任意足够新的副本上执行。</p>
<h4 id="paxos-leader-leases">Paxos Leader Leases</h4>
<p>Spanner的Paxos实现中通过时间化的租约，来确保长时间的leader角色（默认10s）。</p>
<p>一个潜在的leader可以发起请求，请求时间化的租约投票，在收到一定数量的投票后，就可以确保自己拥有租约。另外，当一个副本成功完成一个写操作，会隐式延长自己的租约。而租约快要到期时，则会显式请求延长租约。leader的租约有一个时间区间，起点是收到指定数量投票的那一刻，终点则是由于租约过期而失去一定数量投票的那一刻。注意，每个Paxos
leader的租约时间区间和其他leader的时间区间是完全隔离的。</p>
<p>而Paxos
leader的退位则可以通过将slave从投票集合中释放的方式来实现，一个leader必须等到TT.after(smax)是真才能发起退位。</p>
<h4 id="assigning-timestamps-to-rw-transactions">Assigning Timestamps to
RW Transactions</h4>
<p>事务读写会采用两阶段锁协议，获得所有的锁之后，就可以给事务分配时间戳，这个时间戳是Paxos写操作的，代表了事务提交的时间。在每个Paxos组内，会以单调递增的方式分配时间戳，这个比较好实现。而对于跨越多个leader的情况，一个leader只能分配属于自己租约区间的时间戳。一旦时间戳s被分配，上面提到的smax会变成s。</p>
<p>另外，Spanner也实现了外部一致性：如果一个事务T2在事务T1提交以后开始执行，那么事务T2的时间戳一定大于事务T1的时间戳。简单来说，写进去的数据能够立即被读到，在被修改之前，读到的数据都是一样的。</p>
<h4 id="serving-reads-at-a-timestamp">Serving Reads at a Timestamp</h4>
<p>上面提到的特性，可以使得spanner可以正确地确定副本是否足够新，每个副本会记录一个安全时间值Tsafe，表示副本最近更新后的最大时间，当读操作的时间戳t小于或等于Tsafe的时候，读操作就可以在这个副本上读取。</p>
<h4 id="assigning-timestamps-to-ro-transactions">Assigning Timestamps to
RO Transactions</h4>
<p>只读事务会分成两个阶段执行：分配时间戳sread，然后按照sread的快照读去执行事务操作。在事务开始后的任意时刻，可以分配sread=TT.now().latese。由于Tsafe的存在，或者smax的变化，sread时刻的读操作有可能被阻塞。因为Spanner最好是分配一个可以保持外部一致性的最大时间戳。</p>
<h3 id="details">Details</h3>
<h4 id="read-write-transactions">Read-Write Transactions</h4>
<p>Spanner的读写事务，客户端对位于合适位置的组内leader副本发起读操作时，会先获取读锁，然后读取最新的数据。当一个客户端完成了所有的读操作后，会在客户端缓存所有的写操作，开始两阶段提交。客户端选择一个协调组，并且发送提交信息给所有参与的协调者leader，同时发送信息给所有缓冲的写操作。</p>
<p>每个参与其中的、非协调者leader会先获取写锁，然后选择一个合适的时间戳，并通过Paxos将准备提交记录写入日志。最后，这些leader会将自己的准备时间戳告诉协调者。</p>
<p>此时，扮演协调者的leader也会先获取写锁，然后选择一个事务时间戳，这个时间戳s必须大于或等于从前面获取到的准备时间戳信息，并且应该大于TT.now().latest。这样，这个leader，就会通过Paxos写入一个提交记录到日志，然后开始commit
wait，即该leader会一直等待到TT.after(s)为true，最后发送一个提交时间戳给客户端和所有参与的leader。</p>
<p>每个参与的领导者会通过Paxos把事务结果写入日志。所有的参与者会在同一个时间戳进行提交，释放锁。</p>
<h4 id="read-only-transactions">Read-Only Transactions</h4>
<p>分配只读事务的时间戳存在三种方案：</p>
<ul>
<li>事务开始时，根据一个表达式确定事务参与者，然后这些参与者的Paxos组之间协调，根据各自的LastTS()进行协商选出一个合适的时间戳；</li>
<li>对于在单个Paxos组上的读取，直接获取该Paxos组的最后提交的写操作的时间戳；</li>
<li>TT.now().latest；</li>
</ul>
<p>通过选择一个合适的时间戳，然后在相应的节点确认不会发生读写冲突、不会有复制协议的落后的情况下，可以处理这个读请求了。</p>
<h4 id="schema-change-transactions">Schema-Change Transactions</h4>
<p>TrueTime允许Spanner支持原子模式变更。模式变更事务通常是一个标准事务的、非阻塞的变种。它会显式地分配注册一个未来的时间戳，由于读写操作都会依赖于模式，因此当它们的时间戳小于t时，读写操作就会执行到时刻t；大于t时，读写操作必须阻塞，在模式变更事务后进行等待。</p>
<h2 id="总结">总结</h2>
<p>Spanner的理论最大亮点还是trueTime，相当于用基于原子钟的时间戳当做版本号，提高数据库的并发效率。Spanner实现的是Multi-Paxos，会有一个long-live的leader，但Spanner对Paxos的实现提及不多。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/22/Object-Storage-on-CRAQ%E2%80%94%E2%80%94MIT6-824/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/22/Object-Storage-on-CRAQ%E2%80%94%E2%80%94MIT6-824/" itemprop="url">Object Storage on CRAQ——MIT6.824</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-22T02:03:03+08:00">
                2020-05-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="object-storage-on-craq">Object Storage on CRAQ</h1>
<h2 id="abstract">Abstract</h2>
<p>该论文描述了一种CRAQ(Chain Replication with Apportioned
Queries)的对象存储设计，通过链式备份，能够在保证读取吞吐率的同时维持强一致性。</p>
<h2 id="introduction">Introduction</h2>
<p>对象存储是许多在线服务所需要的，其数据会以一个实体单元来呈现。对象存储支持两种基本原语：读和写。后续，有人开始提出用链式备份的方法来做对象存储，基本思路是将所有存储对象的节点组织在一条链中，其中尾部提供读取请求，而头部则处理所有的写入请求。然后在客户端得到确认之前，写操作会沿着链向后传播。</p>
<p>但这种思路会有不少局限，比如因为所有的读取都会走到同一个节点。该论文就提出了一种CRAQ的设计，实现了一个能够提供强一致性，并且写入低延迟和高吞吐的对象存储。</p>
<p>主要的设计如下：</p>
<ol type="1">
<li>CARQ所有节点都会处理读请求；</li>
<li>除了强一致性，CARQ也能为了低延迟对读操作支持最终一致性；</li>
<li>利用负载均衡特性，提出了一种广域的系统设计，用于跨地理分布的集群来构建CRAQ链，同时保留强大的局部性；</li>
</ol>
<h2 id="basic-system-model">Basic System Model</h2>
<p>这一章介绍链式复制模型的主要概念。</p>
<h3 id="interface-and-consistency-model">Interface and Consistency
Model</h3>
<p>一个对象存储系统主要提供两个基本原语：</p>
<ul>
<li>write(objID, V);</li>
<li>V &lt;—— read(objID);</li>
</ul>
<p>另外，论文提及了系统实现的两种一致性类型。</p>
<ul>
<li>强一致性：对于一个对象的读写操作会以某个顺序执行，并且读取对象时会看到最近的写入值；</li>
<li>最终一致性：对于不同的节点的读取可能会返回过时的数据；</li>
</ul>
<h3 id="chain-replication">Chain Replication</h3>
<p>Chain
Replication（CR）是一种在多节点之间备份数据，提供强一致性存储接口的方法。</p>
<p>简单来说就是，节点组成一个链表，所有的写请求由链表头部接收，然后向后传导，直到到达尾部节点（此时视为committed）。然后尾部节点将会将响应返回到头部，由头部响应成功（因为实际实现使用的是TCP）。</p>
<p>读请求则是由尾部节点接收。</p>
<p><img
src="https://pic.downk.cc/item/5eaf0238c2a9a83be5078e18.png" /></p>
<h3 id="chain-replication-with-apportioned-queries">Chain Replication
with Apportioned Queries</h3>
<p>对于读取请求比较多的场景，CARQ会通过本地读取来尝试提高读取吞吐量。具体设计如下：</p>
<ol type="1">
<li>CARQ的节点会存储对象的多个版本，并且会标示每个版本是dirty还是clean；</li>
<li>当一个节点得到新版本的写入，会追加到版本列表中；
<ol type="1">
<li>如果节点不是尾节点，则标示该版本是dirty的；</li>
<li>如果是尾节点，则直接标示为clean，然后通过链条去答应通知前面的节点；</li>
</ol></li>
<li>前面的节点收到响应后，得知某个版本的节点可以修改为clean；</li>
<li>如果一个节点得到了对象的读取请求；
<ol type="1">
<li>如果对象最后一个节点是clean的，则马上响应；</li>
<li>否则，节点会联系尾节点，询问尾部节点最后一个committed版本。</li>
</ol></li>
</ol>
<p>具体效果如图所示：</p>
<p><img
src="https://pic.downk.cc/item/5eafce3cc2a9a83be58fe0d0.png" /></p>
<h3 id="consistency-models-on-craq">Consistency Models on CRAQ</h3>
<p>CRAQ提供了三种一致性模型：</p>
<ul>
<li>强一致性（默认的）：如上述所示；</li>
<li>最终一致性：允许读取时返回本地已知的最新的对象版本；</li>
<li>最大界限的最终一致性：允许读取请求返回最新的写入对象，即便该对象还没有commit。但会提供一个限制，比如基于特定时间内存的写入，或者某个绝对的版本；</li>
</ul>
<h3 id="failure-recovery-in-craq">Failure Recovery in CRAQ</h3>
<p>双向链表的模式，即一个节点可以知道其后继节点和前驱节点，保证在节点失败时，由其周围的节点去接手。</p>
<h2 id="scaling-craq">Scaling CRAQ</h2>
<p>在本节中，我们讨论应用程序如何在CRAQ中指定单个数据中心内和多个数据中心内的部署方案</p>
<h3 id="chain-placement-strategies">Chain Placement Strategies</h3>
<p>一个分布式应用需要面临很多问题，比如对象的大多数写入可能位于同一个数据中心，一些对象只与数据中心的子集有关，重要的对象可能需要不同的副本策略。</p>
<p>CARQ提供了更加灵活的链式配置策略，对于对象来说，使用的是链表ID和key
ID结合的两层命名结构，另外就是配置的策略：</p>
<ul>
<li>Implicit Datacenters &amp; Global Chain Size: {num_datacenters,
chain_size}</li>
</ul>
<p>简单来说，就是定一个存储链的数据中心数量，通过对数据中心ID作一致性哈希来明确标识唯一的数据中心；</p>
<ul>
<li>Explicit Datacenters &amp; Global Chain Size: {chain_size, dc1, dc2,
..., dcN}</li>
</ul>
<p>这个方法是每个数据中心都适用相同大小的链表去存储备份，链表头部位于dc1的节点，链表尾部则在dc2的其中一个节点，以此类推；</p>
<ul>
<li>Explicit Datacenter Chain Sizes: {dc1, chain_size1, ..., dcN,
chain_sizeN}</li>
</ul>
<p>与上面的方法类似，但每个数据中心的链表大小不同；</p>
<h3 id="craq-across-multiple-datacenters">CRAQ Across Multiple
Datacenters</h3>
<p>CRAQ本地读取的方法降低了延迟，client也可以灵活选择距离更近的节点。</p>
<p>另一方面，通过链优化，应用程序可以选择组成链的数据中心顺序来最大程度降低写入延迟，确保单个链在每个方向上仅仅需要跨越数据中心的网络边界一次。随着节点增加，很可能写延迟也会明显增加，但相比主备的方法，流水线的写操作可以极大地写入吞吐量。</p>
<h3 id="zookeeper-coordination-service">ZooKeeper Coordination
Service</h3>
<p>CARQ使用zookeeper来追溯成员身份，并存储链元数据。另外就是当添加或者删除节点时，可以确保CARQ节点能够收到通知。</p>
<p>由于不了解数据中心原始的拓扑结构，因此Zookeeper节点之间的协调消息会在广域网上多次传输。为了消除跨数据中心ZooKeeper冗余的通讯，一个方法是可以构建一个Zookeeper实例的层次结构：每个数据中心可以包含其自己的本地ZooKeeper实例（由多个节点组成），并具有一个参与全局ZooKeeper实例的代表。另一个方法是，修改ZooKeeper本身以使节点知道网络拓扑。</p>
<h2 id="extensions">Extensions</h2>
<p>本章主要讲述了CARQ的一些拓展点</p>
<h3 id="mini-transactions-on-craq">Mini-Transactions on CRAQ</h3>
<p>对于某些应用来说，简单的对象存储读写可能比较局限。有些应用可能需要支持批量操作，有些可能需要有权限控制。因此CARQ提供了拓展功能来支持事务操作。</p>
<h4 id="single-key-operations">Single-Key Operations</h4>
<p>CRAQ支持几种单key操作：</p>
<ul>
<li>Prepend/Append: 在一个对象的当前值上追加data；</li>
<li>Increment/Decrement: 递增或者递减一个key的对象；</li>
<li>Test-and-Set: 只有在当前版本与指定版本匹配时才会更新对象；</li>
</ul>
<p>对于前面两种操作来说，可以直接对链表的头节点进行apply，而不用管它的节点是clean还是dirty，应用完之后向后传播就行。</p>
<p>而对于Test-and-Set操作来说，CARQ并不会锁住对象，而是版本不匹配的时候直接返回。</p>
<h4 id="single-chain-operations">Single-Chain Operations</h4>
<p>Sinfonia最近提出的mini-transactions可以支持对单个链的多个key进行事务操作。它使用了乐观的两阶段提交协议，在prepare阶段会尝试在每个指定的内存地址上获取一个锁。如果可以锁定所有的地址，则协议提交。否则会释放所有的锁并进行充实。在CRAQ中，由于可以指定多个对象存储在同一个链表中，因此这里的两阶段提交减少到单个的交互，即使用单个头部节点则可以接受访问。</p>
<h4 id="multi-chain-operations">Multi-Chain Operations</h4>
<p>对于多链参与多对象更新，优化的两阶段协议提交只需要用多个链表头部节点实现即可，链表锁住所有参与事务的keys，直到满足提交条件。</p>
<p>当然这个方法没办法pipeline实现，在一定程度上会影响吞吐量。</p>
<h3 id="lowering-write-latency-with-multicast">Lowering Write Latency
with Multicast</h3>
<p>CARQ使用多播协议来提高写入性能，由于链的成员资格在节点成员资格改变时是相对文婷的，因此可以为每个链创建一个多播组。然后，不是在整个链上串行传播完整的写入，而是将真实值多播到整个链表，然后紧紧在链上传播少量的元数据信息，以确保所有的副本都在尾部之前收到写操作。</p>
<p>如果存在节点由于某种原因未接收到多播，则该节点可以在接收到写入提交消息之后，然后进一步传播提交消息之前，从其前任中获取对象。</p>
<p>另外，当尾部节点接收到传播的写请求时，可以将多播确认消息发送到多播组，而不是将其沿链向后传播。这样既减少了节点对象在写入后重新进入清洁状态所花费的时间，又减少了客户端感知的写入延迟。如果链中的某个节点未收到确认，则当下一个读取操作要求它查询尾部时，它将重新进入clean。</p>
<h2 id="management-and-implementation">Management and
Implementation</h2>
<h3 id="integrating-zookeeper">Integrating ZooKeeper</h3>
<p>CRAQ使用zookeeper的文件结构来维持数据中心中节点列表的成员资格。</p>
<p>在初始化时，一个CRAQ节点会创建一个临时文件(/nodes/dc_name/node_id)，dc_name就是数据中心的唯一名称，no
de_id就是数据中节点的唯一ID。文件内容则是包含了节点的ip地址和端口号。</p>
<p>CRAQ可以查询/nodes/dc_name，来判断数据中的成员资格，通过添加一个watch到/nodes/dc_name，就可以被通知到节点的添加或者删除。</p>
<p>/chains/chain_id则是在CRAQ节点收到创建新链表的请求时，会创建一个文件，chain_id是一个160位的唯一标识符，文件内容时链表的配置策略。而节点通过监控链表文件，从而保证在链表元数据改变时得到通知。</p>
<h3 id="chain-node-functionality">Chain Node Functionality</h3>
<p>节点在加入系统时会生成一个随机标识符每个数据中心内会使用该标识符作为one-hop
DHT。节点之间或者节点与客户端之间的RPC通信都是通过TCP连接进行的。每个节点及其链的前任，后继和尾部维护着一组连接的TCP连接。请求通过这些连接进行管道传输和循环轮询。</p>
<p>对于跨多个数据中心的链，一个数据中心的最后一个节点保持与其后继数据中心的第一个节点的连接。当外部数据中心中的节点列表发生更改时，订阅更改的节点可以从其本地ZooKeeper中接收通知。</p>
<h3 id="handling-memberships-changes">Handling Memberships Changes</h3>
<p>对于正常的写传播，CRAQ节点遵循前面的协议。在恢复过程中，有时需要第二种传播方式，即反向传播。例如链表节点可能会在完成向后传播到头部节点之前失败。由于这些可能的故障状况，当新节点加入系统时，新节点会从其前任节点接收传播消息，并从其后继节点接收反向传播消息，以确保其正确性。新节点拒绝客户端对特定对象的读取请求，直到其与后继对象达成协议为止。</p>
<p>无论是节点添加或者删除，变更的节点对应的后继者或者前驱节点都需要传播足够的信息以确保链表的一致性。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/04/Golang%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/04/Golang%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/" itemprop="url">Golang内存模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-04T22:36:02+08:00">
                2020-04-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="golang内存模型">Golang内存模型</h1>
<blockquote>
<p>参考自：https://golang.org/ref/mem</p>
</blockquote>
<p>Golang的内存模型描述了这样的一种场景：在一个goroutine中对一个变量的读取能保证是由不同gorountine写入相同变量所产生的。</p>
<h2 id="happens-before">Happens Before</h2>
<p>在单个goroutine中，只有在满足不改变语言规范所定义的行为时，编译器才能对单个goroutine所执行的读写进行重新排序。但由于重新排序，一个goroutine所观察到的执行顺序可能与另一个goroutine察觉到的执行顺序不同。</p>
<p>为了指定读写要求，在go程序中定义了一个叫Happens
Before的偏序关系——如果事件e1发生在事件e2之前，那么我们说e2发生在e1之后。同样，如果e1不在e2之前发生并且在e2之后也没有发生，那么我们说e1和e2同时发生。</p>
<p>在单个goroutine中，Happens Before的顺序就是程序所表现出来的顺序。</p>
<p>为了保证对变量的读取R可以读取到由特定的对变量的写入W，即W是R可以观察到的唯一写入，必须要满足以下两个条件：</p>
<ol type="1">
<li>W发生到R之前；</li>
<li>任何对变量的其他写入要么发生在w之前，要么发生在r之后；</li>
</ol>
<p>变量的初始化为零值，其实也是内存模型中的零值写入。</p>
<h2 id="synchronization">Synchronization</h2>
<h3 id="初始化">初始化</h3>
<p>程序的初始化是在单个goroutine中进行的，但goroutine可以创建其他goroutine，这是并发的。</p>
<p>如果一个package引入了另一个package，即被引入的package会先初始化。</p>
<p>main.main的开始必须要在所有init函数完成之后。</p>
<h3 id="goroutine的创建">Goroutine的创建</h3>
<p>以下面的为例子，f()打印出hello world可能会在hello()结束后才打印。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">hello</span><span class="params">()</span></span> &#123;</span><br><span class="line">	a = <span class="string">&quot;hello, world&quot;</span></span><br><span class="line">	<span class="keyword">go</span> f()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="goroutine的销毁">Goroutine的销毁</h3>
<p>无法保证goroutine的退出在程序中的任何其他事件发生之前发生。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">hello</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; a = <span class="string">&quot;hello&quot;</span> &#125;()</span><br><span class="line">	<span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对a的赋值很可能在下面的print中看不到，因为缺乏同步。</p>
<h3 id="channel的同步">Channel的同步</h3>
<p>通道通信是goroutine之间同步的主要方法。channel的发送必定发生在该channel接受完成之前。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> c = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">10</span>)</span><br><span class="line"><span class="keyword">var</span> a <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line">	a = <span class="string">&quot;hello, world&quot;</span></span><br><span class="line">	c &lt;- <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> f()</span><br><span class="line">	&lt;-c</span><br><span class="line">	<span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样就能保证打印出hello, world。</p>
<p>另外，channel的关闭会发生在返回零值的接收之前，这样用close(c)替代c&lt;-0也可以产生相同的保证行为。</p>
<p>而对于缺乏buffer的channel，其接收会发生在该channel的发送完成之前，例如这样也可以保证打印出正确的hello
world，这里的发送和接收顺序与上面的例子相反。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> c = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line"><span class="keyword">var</span> a <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line">	a = <span class="string">&quot;hello, world&quot;</span></span><br><span class="line">	&lt;-c</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> f()</span><br><span class="line">	c &lt;- <span class="number">0</span></span><br><span class="line">	<span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但如果channel是带有buffer，就无法保证打印出hello world了。</p>
<p>在容量为C的通道上的第k个接收发生在该通道的第k +
C个发送完成之前，因为不从channel接收数据就无法继续写入。</p>
<p>该规则将前一个规则推广到缓冲通道。
它允许通过缓冲的通道对计数信号量进行建模：channel中的项目数量对应于活动使用的数量，channel的容量对应于同时使用的最大数量，发送一个项目获取信号量，接收项目则会释放信号量。通过这种操作就可以限制其并发。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> limit = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> _, w := <span class="keyword">range</span> work &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(w <span class="keyword">func</span>()</span></span>) &#123;</span><br><span class="line">			limit &lt;- <span class="number">1</span></span><br><span class="line">			w() <span class="comment">// 不处理完成，无法释放该信号量</span></span><br><span class="line">			&lt;-limit</span><br><span class="line">		&#125;(w)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">select</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="locks">Locks</h3>
<p>sync包里实现了两种锁相关的数据类型：sync.Mutex和sync.RWMutex。通过锁的使用，我们可以在goroutine中保证同步。这样的一个程序就可以顺利打印出hello
world。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> l sync.Mutex</span><br><span class="line"><span class="keyword">var</span> a <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line">	a = <span class="string">&quot;hello, world&quot;</span></span><br><span class="line">	l.Unlock()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	l.Lock()</span><br><span class="line">	<span class="keyword">go</span> f()</span><br><span class="line">	l.Lock()</span><br><span class="line">	<span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="once">Once</h3>
<p>sync包还提供了一种初始化的安全机制，通过使用Once数据类型，多个线程都可以执行once.Do(f)，但只有一个会运行f()，其他的调用将会block直接f()返回。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="type">string</span></span><br><span class="line"><span class="keyword">var</span> once sync.Once</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">setup</span><span class="params">()</span></span> &#123;</span><br><span class="line">	a = <span class="string">&quot;hello, world&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doprint</span><span class="params">()</span></span> &#123;</span><br><span class="line">	once.Do(setup)</span><br><span class="line">	<span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">twoprint</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> doprint()</span><br><span class="line">	<span class="keyword">go</span> doprint()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这种机制下，a的赋值将会在打印之前执行。</p>
<h3 id="incorrect-synchronization">Incorrect synchronization</h3>
<p>需要注意的是读取R可能会观察到与R同时发生的写入W所写入的值，但这并不意味着在R之后的读取会观察到在W之前所发生的写入。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a, b <span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line">	a = <span class="number">1</span></span><br><span class="line">	b = <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">g</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="built_in">print</span>(b)</span><br><span class="line">	<span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> f()</span><br><span class="line">	g()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里可能发生的情况是g()打印出了2和0，也就是即便g()已经读取了f()里面对b的写入，但这不意味着g()里面的a能够读取到f()中在b写入之前的a。</p>
<p>同理，类似的错误也会发生在同步的使用：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="type">string</span></span><br><span class="line"><span class="keyword">var</span> done <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">setup</span><span class="params">()</span></span> &#123;</span><br><span class="line">	a = <span class="string">&quot;hello, world&quot;</span></span><br><span class="line">	done = <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doprint</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> !done &#123;</span><br><span class="line">		once.Do(setup)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">twoprint</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> doprint()</span><br><span class="line">	<span class="keyword">go</span> doprint()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里并不意味着能够观察到done设置为true，就隐式地说明a已经被初始化。</p>
<p>另一种典型错误则是忙等，这种情况下并不意味着done被设置为true后，能够表示a已经被初始化，可以跳出for循环。真实情况是，此时print(a)，a可能还是空字符串。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="type">string</span></span><br><span class="line"><span class="keyword">var</span> done <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">setup</span><span class="params">()</span></span> &#123;</span><br><span class="line">	a = <span class="string">&quot;hello, world&quot;</span></span><br><span class="line">	done = <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> setup()</span><br><span class="line">	<span class="keyword">for</span> !done &#123;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>应对这些问题也很简单，使用显式地同步。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/20/decltype-in-c-11/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/20/decltype-in-c-11/" itemprop="url">decltype in c++11</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-20T01:59:14+08:00">
                2019-12-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="decltype">decltype</h1>
<p>decltype是c++11引入的类型推导标记符，与auto类似。基本语法比较简单，就是给一个表达式，返回表达式的类型：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">decltype</span> ( expression )</span><br></pre></td></tr></table></figure>
<p>这里只会查询表达式的返回类型，并不会对表达式进行求值。</p>
<p>decltype的判断规则是比较复杂的，主要分为以下几类：</p>
<ul>
<li>如果参数是无括号的标识表达式或无括号的类成员访问表达式，decltype会返回以该表达式命名的实体类型。但如果参数是一个重载函数，则会编译错误；</li>
<li>若参数是其他类型为 <code>T</code> 的任何表达式
<ul>
<li>表达式的值类型为临时值/亡值，则会返回T&amp;&amp;；</li>
<li>表达式的值类型为左值，则会参会T&amp;；</li>
<li>纯右值，则会返回T；</li>
</ul></li>
</ul>
<p>需要注意的是，如果对象的名字带有括号，则它被当做通常的左值表达式，从而
decltype(x) 和 decltype((x)) 通常是不同的类型。</p>
<p>举个简单的例子：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">A</span> &#123; <span class="type">double</span> x; &#125;;</span><br><span class="line"><span class="type">const</span> A* a;</span><br><span class="line"><span class="type">int</span> i=<span class="number">10</span>;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">decltype</span>(a-&gt;x) y;       <span class="comment">// y 的类型是 double（其声明类型）</span></span><br><span class="line"><span class="keyword">decltype</span>((a-&gt;x)) z = y; <span class="comment">// z 的类型是 const double&amp;（被当作左值表达式）</span></span><br><span class="line"><span class="keyword">decltype</span>((i))b = i;   	<span class="comment">// b 的类型是 int&amp;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者用在无名函数的类型推导上</span></span><br><span class="line"><span class="keyword">auto</span> f = [](<span class="type">int</span> a, <span class="type">int</span> b) -&gt; <span class="type">int</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> a * b;</span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">decltype</span>(f) g = f; </span><br><span class="line">i = <span class="built_in">f</span>(<span class="number">2</span>, <span class="number">2</span>);</span><br><span class="line">j = <span class="built_in">g</span>(<span class="number">3</span>, <span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<p>在日常编程中，用到decltype的情况还是比较少的，我们一般用在模版中，结合auto和尾返回类型，我们可以写出语言级别支持的简洁代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">foo</span><span class="params">(T t, U u)</span> -&gt; <span class="title">decltype</span><span class="params">(t + u)</span> </span>&#123; <span class="keyword">return</span> t + u; &#125;</span><br></pre></td></tr></table></figure>
<p>另外，要判断是否为左值，可以考虑使用c++11标准库提供的模版类来做检查：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">is_lvalue_reference&lt;<span class="keyword">decltype</span>(++i)&gt;::value;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/15/Scaling-Distributed-Machine-Learning-with-the-Parameter-Server%E2%80%94%E2%80%94MIT6-824/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/15/Scaling-Distributed-Machine-Learning-with-the-Parameter-Server%E2%80%94%E2%80%94MIT6-824/" itemprop="url">Scaling Distributed Machine Learning with the Parameter Server——MIT6.824</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-15T01:32:15+08:00">
                2019-12-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1
id="scaling-distributed-machine-learning-with-the-parameter-server">Scaling
Distributed Machine Learning with the Parameter Server</h1>
<blockquote>
<p>这篇论文提出了一种用于解决分布式机器学习问题的参数服务器框架。通过将数据和工作负载均匀地分布在所有工作节点上，服务器节点则用来维护全局共享的参数（即一些向量和矩阵）。这个框架能够很好地管理节点之间的异步数据通信，并保持了灵活的一致性、弹性可伸缩性和容错能力。</p>
<p>这是它的开源实现：<a target="_blank" rel="noopener" href="https://github.com/dmlc/parameter_server"
class="uri">https://github.com/dmlc/parameter_server</a></p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>分布式的优化和推理正成为解决大规模机器学习问题的先决条件，因为数据的增长和模型复杂，很难通过单机去快速解决这些问题。因此，如此大量的计算工作和数据都需要仔细的系统设计，</p>
<p>而这些复杂的模型需要在所有工作节点中进行全局共享，由于需要经常访问共享参数，因此这会带来三个挑战：</p>
<ul>
<li>访问参数需要大量的网络带宽；</li>
<li>许多机器学习算法都是顺序执行的，如果同步和机器延迟成本很高，对性能影响很大；</li>
<li>大规模的容错能力；因为机器学习任务通常在云环境中执行，而云环境不够稳定可靠；</li>
</ul>
<h3 id="contributions">Contributions</h3>
<p>参数服务器（Parameter
Server）在学术界和工业界已经有了一定的影响力。本文主要描述其第三代开源实现。其注重于分布式推理的实现，提供了5个关键功能：</p>
<ol type="1">
<li>高效的通信：使用了不会阻塞计算的异步通信模型；</li>
<li>灵活的一致性模型：较为宽松的一致性降低了同步成本和延迟；</li>
<li>弹性可伸缩行：主要是在运行时添加新节点，无需重启；</li>
<li>容错性和耐用性：秒级恢复故障机器，不会中断计算，并使用向量明确网络分区和故障行为；</li>
<li>计算更简单：全局共享的参数是向量和矩阵的形式；</li>
</ol>
<h2 id="machine-learning">Machine Learning</h2>
<p>该论文因为要在非常大型的训练数据中证明参数服务器的有效性，因此介绍了两种广泛使用的机器学习技术。</p>
<h3 id="risk-minimization">Risk Minimization</h3>
<p>risk
minimization是机器学习中最直观的一个问题，大概意思就是对预测误差的衡量，即通过risk
minimization的模型来预测自变量x的值y。训练数据量与模型大小的有着重要的联系，详细的模型可能提高了准确性，却导致过拟合，反之则可能是欠拟合。为了解决这个问题，则通过正则化来实现在模型复杂度和训练误差之间取得平衡，即最小化训练数据预测误差损失和惩罚模型复杂度的正则器。</p>
<p>虽然这两个对于机器学习算法的性能有着很重要的影响，但不是评估参数服务器的关键，因此这里采用了比较简单的算法，一种叫次梯度的分布式下降算法（
<em>distributed subgradient descent</em>）</p>
<p>在参数服务器中，训练数据分配到所有的worker，共同学习参数向量w。算法在每次迭代的时候，每个worker会独立地使用自己的训练数据来计算Δwi，这就是subgradient，参数向量w的移动方向，然后使用所有的subgradient来表示最终w的梯度。为了快速收敛，需要设计有效的学习率。算法如下所示</p>
<figure>
<img src="https://puui.qpic.cn/fans_admin/0/3_500685383_1571329244934/0"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><img
src="https://puui.qpic.cn/fans_admin/0/3_1389210464_1571329354280/0" /></p>
<p>由于计算梯度的成本比较高，如果w的维度很高的话，计算将无法执行，因此每个worker都需要知道其训练数据所依赖的w的坐标范围，从而减少计算量。</p>
<p>论文的实验结果是，随着worker的增长，单机所需内存也在下降。如下图，对于100个worker，每个worker只需要使用参数的7.8％。拥有10,000名工人，这一比例降低到0.15％。</p>
<p><img
src="https://puui.qpic.cn/fans_admin/0/3_775863512_1571329775763/0" /></p>
<h3 id="generative-models">Generative Models</h3>
<p>另一类主要的机器学习算法就是使用非监督算法来捕获数据的基础结构，具体不表，也是通过学习部分参数，然后进行聚合，但可能有点不同的是，有些算法不是使用的梯度下降，而是其它的比较方法。</p>
<h2 id="architecture">Architecture</h2>
<p>参数服务器可以同时运行多种算法，其将节点分为server
group和好几个worker group。如下图所示，server
group中的server节点负责维护全局共享的部分参数，而这些节点则通过相互通信完成参数迁移和复制，同时通过维护诸如节点状态和参数分配等原数据的一致性视图。</p>
<p>每个worker都运行一个应用程序，存储着部分的训练数据，worker之间是不能通讯的，只能与server节点交流，从而更新和检索参数。每个worker都有一个叫task
scheduler的节点，负责为worker节点分配任务和监视进度。当有workers新增或移除节点·时，task
scheduler负责重新分配未完成的任务。</p>
<p>参数服务器支持独立的参数名称空间，也允许多个worker
group共享同一个名称空间。</p>
<p><img
src="https://puui.qpic.cn/fans_admin/0/3_775863512_1571331119626/0" /></p>
<h3 id="keyvalue-vectors">(Key,Value) Vectors</h3>
<p>节点之间的共享模型可以表示为一组键值对，并且假设所有的key都是有序的，例如损失函数最小化问题中，键值对是特征ID及其权重，对于LDA，则是单词ID和主题ID以及计数的组合。</p>
<h3 id="range-push-and-pull">Range Push and Pull</h3>
<p>参数服务器中，worker与server的节点之间发送数据是通过推拉操作完成的，并且支持基于范围的推拉。worker将计算好的梯度push到server，然后worker从server读取新的参数。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w.push(R, dest) <span class="comment">// 将key范围中w的所有现存项全部发往目的，这里的目的可以是特定节点，也可以是节点组</span></span><br><span class="line">w.pull(R, dest) <span class="comment">// 从目的位置读取key范围中w的所有现存项</span></span><br></pre></td></tr></table></figure>
<h3 id="user-defined-functions-on-the-server">User-Defined Functions on
the Server</h3>
<p>除了从worker聚合数据之外，server节点还可以执行用户自定义的功能，这里的好处是因为server节点往往具有共享参数更加完整更加新的的信息。</p>
<h3 id="asynchronous-tasks-and-dependency">Asynchronous Tasks and
Dependency</h3>
<p>task是通过远程调用发出的，worker向server发出的消息是pull或者push其中一种，也可以是由调度程序发给任何节点的用户自定义功能。另外task可能包含任意数量的子task。</p>
<p>task是异步执行的，发出task之后，caller可以马上执行进一步的计算，caller仅在收到callee答复才能标记任务完成。默认情况下，callee并行执行任务，如果要实现序列化，则可以在task之间执行一个依赖关系。如下图就指示了三个迭代例子，其中10和11是独立的，但12依赖于11，因此callee在10中完成计算局部梯度之后可以立即开始11，但12则需要等到11的计算完成，返回数据之后才能开始。</p>
<p><img
src="https://puui.qpic.cn/fans_admin/0/3_1218999906_1571418637302/0" /></p>
<h3 id="flexible-consistency">Flexible Consistency</h3>
<p>独立的任务虽然可以通过并行化CPU的使用，磁盘和网络带宽的方式提高系统效率，但也可能带来节点间数据不一致的问题，从而降低算法收敛速度，因此需要在系统效率和算法收敛速度之间进行取舍，但这里的权衡取舍又会依赖于以下几种因素：</p>
<ul>
<li>算法对数据不一致的敏感度；</li>
<li>训练数据的特征相关性；</li>
<li>硬件组件的容量差异；</li>
</ul>
<p>参数服务器为算法设计人员提供了定义一致性模型的灵活性，下图就是通过任务依赖关系实现的三种不同模型：</p>
<figure>
<img src="https://pic.superbed.cn/item/5da9f4df451253d1784d57cd.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>Sequential</strong>：顺序执行所有任务，当前一个任务执行完成，才能启动下一个任务；</p>
<p><strong>Eventual</strong>：所有任务同时执行，这只有在对延时敏感度很robust的算法中才会被使用；</p>
<p><strong>Bounded
Delay</strong>：就是前两种模型的折衷，即使用一个最大延时t，在t时刻之前完成前一个任务才能启动下一个任务。t=0就是Eventual，t=∞即Sequential；</p>
<p>另外，tasks之间的依赖关系可能是动态的，即可以根据系统情况来改变最大延时以平衡系统效率和优化算法的收敛性。</p>
<h3 id="user-defined-filters">User-defined Filters</h3>
<p>作为调度程序控制流的一个拓展，参数服务器支持用户自定义filter，以选择性地在节点之间同步各个键值对，从而更加细粒度地控制数据。这里的关键是，要明确优化算法本身拥有的跟参数有关的信息是什么。例如有些filter只会push自上次同步依赖变化超过阈值的item，有些则利用filterpush仅仅可能影响server权重的梯度。</p>
<h2 id="implementation">Implementation</h2>
<p>参数服务器使用一致性哈希来存储参数，并使用链式复制来备份内容，同时对基于key范围的通信进行了优化。</p>
<h3 id="vector-clock">Vector Clock</h3>
<p>参数服务器会将每个键值对与矢量时钟关联起来，该时钟会记录每个节点在该键值对上的时间，矢量时钟的一个好处就是可以用来跟踪聚合状态或者是拒绝重复发送数据。但矢量时钟的最初版需要O(mn)的空间来处理n个节点和m个参数，这样的成本太高了。</p>
<p>但由于参数服务器可以进行基于范围的通信模式，这样就会使得许多参数具有相同的时间戳，这样就可以将矢量时钟进行压缩。</p>
<p>一开始，所有的节点都共享一个range vector
clock，覆盖了整个参数键空间，其最初的时间戳为0。每个range
key都可以抽取子range，并最多创建3个新的矢量时钟，参考下面的算法，这样就可以大大降低参数数量：</p>
<p><img
src="https://puui.qpic.cn/fans_admin/0/3_1221609656_1571498105511/0" /></p>
<h3 id="messages">Messages</h3>
<p>节点可以将消息发送给耽搁节点或者是节点组，一条消息由key范围R中的键值对列表和相关范围的矢量时钟组成，这是参数服务器的基本通信格式，不仅用于共享参数，也会应用于任务。而对于任务，键值对则可能表示为（taskID，参数/返回值）。</p>
<blockquote>
<p>参数服务器基本通信格式：[vc(R), (k1,v1), ..., (kp,vp)] kj ∈ R and j ∈
{1,...p}</p>
</blockquote>
<p>由于机器学习问题往往需要高带宽，因此需要进行消息压缩：</p>
<ol type="1">
<li>如果迭代之间的训练数据保持不变，则可以要求接收节点缓存key列表，以后发送节点只需要发送该key的hash值即可。</li>
<li>由于键值对的value本身可能包含许多零项，另外用户定义的过滤器也可以将部分值归零，因此可以只发送非零的键值对即可。</li>
</ol>
<h3 id="consistent-hashing">Consistent Hashing</h3>
<p>参数服务器将key的分区方式是通过将key和服务器节点ID插入到哈希环中，如下：</p>
<p><img
src="https://puui.qpic.cn/fans_admin/0/3_1221609656_1571499394673/0" /></p>
<p>每个服务器节点管理一定的key范围，每个服务器节点都管理者它按逆时针方向到下一个节点之间的key
range，这就是该key
range的主节点。同样，每个节点都复制了按逆时针方向的k个节点的key
range。另外为了改善平衡和提高恢复效率，物理服务器通过多个"虚拟服务器"在环中表示。例如k=2时，S1就会复制S2和S3管理的key
range，这时S1就是这两个key range的slave</p>
<h3 id="replication-and-consistency">Replication and Consistency</h3>
<p>Worker仅与该key
range的master进行通信，在主server节点的修改和时间戳都需要复制到slave服务器。下面的左图就是这样的一个情况，</p>
<p><img
src="https://puui.qpic.cn/fans_admin/0/3_1221609656_1571501296060/0" /></p>
<p>Worker1会push x到server1，server1执行完用户自定义函数后同步到slave
server2，同步完成后，任务才算结束。</p>
<p>但简单的同步复制可能会使网络流量增加k倍，这对很多依赖于高网络带宽的机器学习应用是很致命的。因此参数服务器框架做了一个重要的优化：聚合后的复制，即servers先聚合从workers接收到的数据后再复制到slaves。如上右图所示，对于n个workers来说，复制带宽将会降低n倍。</p>
<h3 id="server-management">Server Management</h3>
<p>为了实现容错和动态扩展，参数服务器还必须支持添加和删除节点，为了方便起见，将会引入虚拟服务器。server
节点加入后，将会发生：</p>
<ol type="1">
<li>server管理器为新节点分配一个key
range以用作master节点。这可能会导致另一个key
range分裂或者从某个终止节点中删除；</li>
<li>新加入的节点会获取k个key range，自身成为这些key range的slave；</li>
<li>server管理器广播节点更改，接收方server将移除不属于自己管理的key
range的数据，并将未完成的任务重新提交给新节点；</li>
</ol>
<h3 id="worker-management">Worker Management</h3>
<p>添加新的worker节点与添加server节点类似，但更简单：</p>
<ol type="1">
<li>task调度器为新节点分配数据范围；</li>
<li>该节点从网络文件系统或者现有的工作程序中加载训练数据，接下来则是从server节点pull共享参数；</li>
<li>task调度器广播修改，这可能会使部分workers释放部分训练数据；</li>
</ol>
<p>当worker节点挂掉后，参数服务器提供了选项，用户可以自行控制恢复程序，这是因为：</p>
<ul>
<li>如果训练数据量巨大，则恢复worker节点可能比恢复server节点的成本更高；</li>
<li>在优化过程中丢失少量训练数据通常只会对模型造成少许影响；</li>
</ul>
<p>因此，算法设计者可能更喜欢继续操作而不替换失败的工作程序。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/07/Resilient-Distributed-Datasets-A-Fault-Tolerant-Abstraction-for-In-Memory-Cluster-Computing%E2%80%94%E2%80%94MIT6-824/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/07/Resilient-Distributed-Datasets-A-Fault-Tolerant-Abstraction-for-In-Memory-Cluster-Computing%E2%80%94%E2%80%94MIT6-824/" itemprop="url">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing——MIT6.824</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-07T23:54:18+08:00">
                2019-12-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1
id="resilient-distributed-datasets-a-fault-tolerant-abstraction-for-in-memory-cluster-computing">Resilient
Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster
Computing</h1>
<h2 id="abstract">Abstract</h2>
<p>本文介绍了弹性的分布式数据集，这是一种分布式的内存抽象形式，它可以让程序员以一种容错的方式在大型集群中进行内存计算。</p>
<h2 id="introduction">Introduction</h2>
<p>尽管想MapReduce之类的框架已经提供了关于访问集群的计算资源的抽象，但仍然缺乏对于分布式内存的抽象，这使得它们在处理需要重用多个计算中中间结果的应用程序上不够高效。像一些机器学习算法、图算法，交互式数据挖掘都需要对数据子集做临时的查询，但那些框架的做法往往是将其写入到外部的存储系统里，这里IO、序列化之类的开销非常大。</p>
<p>本文提出了一种弹性的分布式数据集的新抽象。其可以将中间结果明确地保存在内存中，控制其分区进行优化放置，并使用一组丰富的运算符进行操作。</p>
<p>Apache Spark应运而生。</p>
<h2 id="resilient-distributed-datasets-rdds">Resilient Distributed
Datasets (RDDs)</h2>
<h3 id="rdd-abstraction">RDD Abstraction</h3>
<p>所谓的弹性的分布式数据集，这里的弹性指的是在任何时候都可以进行重算，让用户不会感知到某部分内容曾经丢失过，这是Spark的核心抽象，是一种只读的、分区的数据记录集合。RDD的产生，要么通过从确定存储中获取，要么就是通过其它的RDD进行转换获取，这里的转换包括map、filter和join。</p>
<p>RDD应该有足够的信息，去记录自身是如何从其它数据集派生而来的。用户可以控制RDD的持久化和分区，比如指示重用的RDD和存储策略，也可以命令RDD的元素进行分区。分区依照特定规则将具有相同属性的数据记录放在一起，每个分区相当于一个数据集片段。</p>
<h3 id="spark-programming-interface">Spark Programming Interface</h3>
<p>Spark会使用集成API的方式暴露RDD，其中每个数据集标示为一个对象，并使用对象上的方法进行调用转换。</p>
<p>首先是会对稳定存储中的数据通过转换的方式定义一个或多个RDD，然后在操作中使用这些RDD，比如是返回数据给应用程序，还是导出到存储系统。此外，还可以对RDD进行持久化来指示哪些RDD是需要重用的，默认将持久性RDD保存在内存中，在RAM不够的话，将会将其溢出到磁盘，当然还有很多种持久化策略。</p>
<h3 id="advantages-of-the-rdd-model">Advantages of the RDD Model</h3>
<p>RDD与分布式共享内存最大的区别就是，RDD只能通过粗粒度的转换得来，而DSM则可以读取/写入到每一个内存位置。这样RDD在处理容错时，就不会产生额外的有关checkpoint的开销，如果有分区丢失，RDD可以在不同的节点并行地重建，而不需要回滚整个系统。</p>
<p>由于RDD的不可变特性，系统可以通过运行较慢的备份副本来缓解慢速节点，而DSM在这种情况会因为多副本访问相同内存位置，而产生干扰更新。</p>
<h3 id="applications-not-suitable-for-rdds">Applications Not Suitable
for RDDs</h3>
<p>RDD更适用于在批处理应用程序中对全集数据执行相同的操作，在这种情况下，RDD能够很好地记录每一步的转换，并且能够在分区丢失时快速恢复。</p>
<p>而对于那些需要对共享状态进行异步更新的应用，RDD则不适合。</p>
<h2 id="spark-programming-interface-1">Spark Programming Interface</h2>
<p>为了使用Spark，开发人员编写了一个驱动程序，用以连接到一组worker，并通过一个或多个RDD来调用action，同时该驱动程序上的Spark代码还可以跟踪RDD的lineage（血统？）。</p>
<p><img
src="https://puui.qpic.cn/fans_admin/0/3_467752339_1574789500166/0" /></p>
<p>这些worker是一个长期活跃的进程，在内存中存着RDD分区。</p>
<h3 id="rdd-operations-in-spark">RDD Operations in Spark</h3>
<p>下表列出了Spark中可用的RDD转换和可用操作：</p>
<p><img
src="https://pic1.superbed.cn/item/5de5470ef1f6f81c50404c93.png" /></p>
<h2 id="representing-rdds">Representing RDDs</h2>
<p>论文中提到使用了大约14000行Scala代码实现了Spark，这个系统在Mesos集群上运行。每个Spark程序都作为一个单独的Mesos应用程序，具有独立的驱动程序和worker程序，并且这些应用程序之间的资源共享由Mesos处理。</p>
<p>论文中提到RDD的表示是一种基于图的表示。因此对于RDD的表示，则是通过暴露5个接口方法来实现的。</p>
<p><img
src="https://pic.superbed.cn/item/5de7e86ff1f6f81c50a2a07f.png" /></p>
<ul>
<li>Partions：数据集的原子结构；</li>
<li>preferredLocations：能更快访问分区的系列节点；</li>
<li>dependencies：记录父子RDD的记录；</li>
<li>iterator：用于从父RDD计算子RDD；</li>
<li>patitioner：数据分区的元信息；</li>
</ul>
<p>至于如何表示RDD的关系，由于RDD在物理上是分区的，散列在集群不同机器的内存上的，文中将其定义为窄依赖（Narrow
Dependency）和宽依赖（Wide Dependency）两种。</p>
<ul>
<li>宽依赖：父RDD中的分区可能被子RDD中的多个分区所依赖；</li>
<li>窄依赖：父RDD的每个分区至多被子RDD中的一个分区所依赖；像map/filter这些操作都属于窄依赖；</li>
</ul>
<p><img
src="https://pic2.superbed.cn/item/5de7ea33f1f6f81c50a2e1cc.png" /></p>
<p>这两种依赖的差别在于：窄依赖可以pipeline执行，在失败时只需要重新执行对应的父RDD即可；而宽依赖则需要shuffle，并且如果出现故障恢复则需要重算所有父RDD；</p>
<h3 id="job-scheduling">Job Scheduling</h3>
<p>每当用户在RDD执行action的时候，调度器就会检查RDD的谱系图，以构建要执行的DAG（有向无环图）。如下图所示：</p>
<p><img
src="https://pic.superbed.cn/item/5de7edaaf1f6f81c50a37d20.png" /></p>
<p>每个stage内部都包含尽可能多的具有窄依赖的操作。这些stage的边界是宽依赖所必需执行的shuffle操作，另外任何已经计算出的分区都可以使父RDD的计算短路。调度程序会集群上启动任务以计算每个阶段中缺少的分区，直到它计算出目标RDD。</p>
<p>调度器会根据数据局部性的原则来执行delay scheduling算法：</p>
<ul>
<li>如果任务需要的数据分区在某节点的内存中，则将任务发送到节点上执行；</li>
<li>否则，如果该分区有指定的位置，则直接发送给它；</li>
</ul>
<p>对于宽依赖，Spark会在存有父分区的节点上暂存shuffle的中间记录，以便做容灾处理，就像mapreduce存下map的输出一样。</p>
<p>如果任务失败，只要stage的父stage还是可用的，就可以将task调度到另一个节点上重新运行即可。如果父stage也失效了，就会重新提交一个计算父stage数据的Task来并行计算丢失的分区。但论文也提到了Spark没有考虑调度器本身的高可用。</p>
<h3 id="interpreter-integration">Interpreter Integration</h3>
<p>Scala包含了交互shell，可以让用户从解释器中交互地运行Spark以查询大数据集。</p>
<p>Scala解释器通常会为用户输入的每一行编译一个类，并将其加载到JVM中通过调用一个函数来进行操作。该类会包含一个单例对象，对象则包含该行上的变量或者函数，并以初始化的方式运行该行代码。</p>
<p>另外，Spark的解释器还做了两处修改：</p>
<ol type="1">
<li>类传递：为了让工作节点能够获取在每一行上创建的类的字节码，解释器会通过HTTP为这些类提供服务；</li>
<li>修改代码的生成：因为每行代码的单例对象都是通过对应的静态方法访问，这意味着无法引用上一行定义的变量。因此需要修改代码的生成，以便直接引用每行对象的实例，如下图：</li>
</ol>
<p><img
src="https://puui.qpic.cn/fans_admin/0/3_118841988_1575731978815/0" /></p>
<h3 id="memory-management">Memory Management</h3>
<p>Spark提供了三种对持久化RDD的存储策略：</p>
<ul>
<li>未序列化Java对象存在内存；</li>
<li>序列化的数据存于内存；</li>
<li>磁盘存储；</li>
</ul>
<p>第一种性能最好，因为可以直接访问在Java虚拟机内存里的RDD对象；第二种性能会降低，在空间有限的情况下可以让用户选择比Java对象图更高效的内存表示方式；第三种则是针对RDD太大无法保留在内存中，但每次使用都需要重新计算开销很大时，这个方法会很有用；</p>
<p>为了管理可用的有限内存，Spark在RDD级别使用了LRU逐出策略。当计算了一个新的RDD分区但没有足够存储空间时，就会通过LRU的方式逐出一个分区。除非是该RDD便是新分区对应的RDD，在这种情况下，Spark会将旧的分区保留在内存，避免同一个RDD的分区被循环地调进调出。</p>
<h3 id="support-for-checkpointing">Support for Checkpointing</h3>
<p>虽然lineage机制可以满足失败后RDD的重建恢复，但对于具有很长链条的RDD来说，恢复时间会很长。特别是包含了宽依赖的长lineage的RDD，因此能设置检查点的操作就会非常有用。Spark当前提供了为RDD设置检查点操作的API，可以用一个REPLICATE标志来持久化，用户自行决定使用方式。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/05/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E2%80%94%E2%80%94AOF%E6%8C%81%E4%B9%85%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/05/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E2%80%94%E2%80%94AOF%E6%8C%81%E4%B9%85%E5%8C%96/" itemprop="url">redis设计与实现——AOF持久化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-05T00:54:49+08:00">
                2019-11-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="aof持久化">AOF持久化</h1>
<p>RDB持久化是通过保存数据库中的键值对来记录数据库状态的，而AOF则是通过保存redis服务器所执行的命令来完成记录的。</p>
<p>例如执行命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SET msg &quot;hello&quot;</span><br><span class="line">RPUSH numbers 128 256 512</span><br></pre></td></tr></table></figure>
<p>那么RDB的持久化就是保存msg和numbers的键值对，而AOF则是保存SET和RPUSH的命令。</p>
<h2 id="aof持久化的实现">AOF持久化的实现</h2>
<p>AOF的持久化功能分为命令追加、文件写入、文件同步三个步骤。</p>
<h3 id="命令追加">命令追加</h3>
<p>打开AOF持久化功能后，服务器在执行完一个写命令后，会以redis的协议格式将被执行的命令写到服务器状态的缓冲区，则redisServer结构的aof_buf字段。在大量写请求情况下，利用缓冲区缓存一部分命令，尔后再根据某种策略写入磁盘，减少IO。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">redisServer</span> &#123;</span></span><br><span class="line">  sds aof_buf;      <span class="comment">/* AOF buffer, written before entering the event loop */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="aof文件的写入与同步">AOF文件的写入与同步</h3>
<p>Redis的服务器进程中有一个事件循环，正如注释所说的，每次结束事件循环前都会调用flushAppendOnlyFile()函数，该函数则根据配置选项决定如何写入AOF文件。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">beforeSleep</span><span class="params">(<span class="keyword">struct</span> aeEventLoop *eventLoop)</span>  &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  flushAppendOnlyFile(<span class="number">0</span>);</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __linux__</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> redis_fsync fdatasync</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> redis_fsync fsync</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">aof_background_fsync</span><span class="params">(<span class="type">int</span> fd)</span> &#123;</span><br><span class="line">    bioCreateBackgroundJob(BIO_AOF_FSYNC,(<span class="type">void</span>*)(<span class="type">long</span>)fd,<span class="literal">NULL</span>,<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">flushAppendOnlyFile</span><span class="params">(<span class="type">int</span> force)</span> &#123;</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">  try_fsync:</span><br><span class="line">    <span class="keyword">if</span> (server.aof_no_fsync_on_rewrite &amp;&amp; hasActiveChildProcess())</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (server.aof_fsync == AOF_FSYNC_ALWAYS) &#123;</span><br><span class="line">        latencyStartMonitor(latency); <span class="comment">//监控</span></span><br><span class="line">        redis_fsync(server.aof_fd); <span class="comment">/* 同步到磁盘 */</span></span><br><span class="line">        latencyEndMonitor(latency);</span><br><span class="line">        latencyAddSampleIfNeeded(<span class="string">&quot;aof-fsync-always&quot;</span>,latency);</span><br><span class="line">        server.aof_fsync_offset = server.aof_current_size;</span><br><span class="line">        server.aof_last_fsync = server.unixtime;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> ((server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp;</span><br><span class="line">                server.unixtime &gt; server.aof_last_fsync)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!sync_in_progress) &#123;</span><br><span class="line">            aof_background_fsync(server.aof_fd); <span class="comment">// 在额外的线程中开启一个任务去执行fsync()</span></span><br><span class="line">            server.aof_fsync_offset = server.aof_current_size;</span><br><span class="line">        &#125;</span><br><span class="line">        server.aof_last_fsync = server.unixtime;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>force：如果持久化策略为everysec，就有一定的可能延迟flush，因为后台进程可能还在进行fsync()，而如果force设成1，则无论什么情况都会进行写入。</li>
</ul>
<p>另外由于在Linux中用户调用write函数时，操作系统会先将写入数据保存在一个内存缓冲区中，redis支持服务器配置appendfsync选项来定义上面的函数行为：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Append only defines */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> AOF_FSYNC_NO 0</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> AOF_FSYNC_ALWAYS 1</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> AOF_FSYNC_EVERYSEC 2</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CONFIG_DEFAULT_AOF_FSYNC AOF_FSYNC_EVERYSEC <span class="comment">//默认</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li>AOF_FSYNC_ALWAYS：将aof_buf缓冲区的所有内容写入并同步到AOF文件；</li>
<li>AOF_FSYNC_EVERYSEC：将aof_buf缓冲区的所有内容写入AOF文件，如果上次同步AOF文件的时间距离现在超过1秒，则再次进行同步；</li>
<li>AOF_FSYNC_NO：写入文件但不同步；</li>
</ul>
<h2 id="aof文件的载入与数据还原">AOF文件的载入与数据还原</h2>
<p>由于AOF文件包含了重建数据库的所有写命令，因此只需要重读执行一遍，就可以恢复服务器状态了。其实现函数为loadAppendOnlyFile()</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">loadAppendOnlyFile</span><span class="params">(<span class="type">char</span> *filename)</span> &#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">client</span> *<span class="title">fakeClient</span>;</span> <span class="comment">// 创建一个伪客户端</span></span><br><span class="line">    FILE *fp = fopen(filename,<span class="string">&quot;r&quot;</span>);</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">redis_stat</span> <span class="title">sb</span>;</span></span><br><span class="line">    <span class="type">int</span> old_aof_state = server.aof_state;</span><br><span class="line">    <span class="type">long</span> loops = <span class="number">0</span>;</span><br><span class="line">    <span class="type">off_t</span> valid_up_to = <span class="number">0</span>; <span class="comment">/* Offset of latest well-formed command loaded. */</span></span><br><span class="line">    <span class="type">off_t</span> valid_before_multi = <span class="number">0</span>; <span class="comment">/* Offset before MULTI command loaded. */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (fp == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        serverLog(LL_WARNING,<span class="string">&quot;Fatal error: can&#x27;t open the append log file for reading: %s&quot;</span>,strerror(errno));</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 特殊处理aof文件长度为0的情况 */</span></span><br><span class="line">    <span class="keyword">if</span> (fp &amp;&amp; redis_fstat(fileno(fp),&amp;sb) != <span class="number">-1</span> &amp;&amp; sb.st_size == <span class="number">0</span>) &#123;</span><br><span class="line">        server.aof_current_size = <span class="number">0</span>;</span><br><span class="line">        server.aof_fsync_offset = server.aof_current_size;</span><br><span class="line">        fclose(fp);</span><br><span class="line">        <span class="keyword">return</span> C_ERR;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 参数关系aof，避免有新纪录写入同一个文件 */</span></span><br><span class="line">    server.aof_state = AOF_OFF;</span><br><span class="line"></span><br><span class="line">    fakeClient = createAOFClient();</span><br><span class="line">    startLoadingFile(fp, filename); <span class="comment">// 做全局状态的标记，表示正在加载文件</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 如果有RDB前缀，则需要加载RDB文件 */</span></span><br><span class="line">    <span class="type">char</span> sig[<span class="number">5</span>]; <span class="comment">/* &quot;REDIS&quot; */</span></span><br><span class="line">    <span class="keyword">if</span> (fread(sig,<span class="number">1</span>,<span class="number">5</span>,fp) != <span class="number">5</span> || <span class="built_in">memcmp</span>(sig,<span class="string">&quot;REDIS&quot;</span>,<span class="number">5</span>) != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 读入AOF文件，一个一个命令执行. */</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// ... 读取cmd</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (cmd == server.multiCommand) valid_before_multi = valid_up_to;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 在fake客户端上下文里执行命令 */</span></span><br><span class="line">        fakeClient-&gt;cmd = cmd;</span><br><span class="line">        <span class="keyword">if</span> (fakeClient-&gt;flags &amp; CLIENT_MULTI &amp;&amp;</span><br><span class="line">            fakeClient-&gt;cmd-&gt;proc != execCommand)</span><br><span class="line">        &#123;</span><br><span class="line">            queueMultiCommand(fakeClient);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            cmd-&gt;proc(fakeClient);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 该客户端不作回应 */</span></span><br><span class="line">        serverAssert(fakeClient-&gt;bufpos == <span class="number">0</span> &amp;&amp;</span><br><span class="line">                     listLength(fakeClient-&gt;reply) == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 客户端不受blocked */</span></span><br><span class="line">        serverAssert((fakeClient-&gt;flags &amp; CLIENT_BLOCKED) == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ....</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol type="1">
<li>由代码可见，首先是创建一个不带网络连接，不做回应不受blocked的客户端，因为执行命令只能在客户端上下文执行；</li>
<li>从AOF文件中分析并读出写命令；</li>
<li>用伪客户端执行该命令，知道所有命令处理完毕；</li>
</ol>
<h2 id="aof重写">AOF重写</h2>
<p>为了解决AOF文件体积膨胀的问题，Redis提供了AOF文件重写的功能，即Redis服务器会创建一个新的AOF文件来替代现有的AOF文件，并去除任何浪费空间的冗余命令。</p>
<h3 id="aof文件重写的实现">AOF文件重写的实现</h3>
<p>事实上，AOF文件重写并不会对老的AOF文件进行任何读取、分析或者写入操作，而是通过直接读取当前数据库的状态实现的。aof的重写是通过函数rewriteAppendOnlyFileRio实现的</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">rewriteAppendOnlyFileRio</span><span class="params">(rio *aof)</span> &#123;</span><br><span class="line">    dictIterator *di = <span class="literal">NULL</span>;</span><br><span class="line">    dictEntry *de;</span><br><span class="line">    <span class="type">size_t</span> processed = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> j;</span><br><span class="line">		</span><br><span class="line">  	<span class="comment">// 遍历数据库</span></span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; server.dbnum; j++) &#123;</span><br><span class="line">        <span class="type">char</span> selectcmd[] = <span class="string">&quot;*2\r\n$6\r\nSELECT\r\n&quot;</span>; <span class="comment">// 写入select命令</span></span><br><span class="line">        redisDb *db = server.db+j;</span><br><span class="line">        dict *d = db-&gt;dict;</span><br><span class="line">        <span class="keyword">if</span> (dictSize(d) == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">        di = dictGetSafeIterator(d);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 写入select命令，指定数据库号码 */</span></span><br><span class="line">        <span class="keyword">if</span> (rioWrite(aof,selectcmd,<span class="keyword">sizeof</span>(selectcmd)<span class="number">-1</span>) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">        <span class="keyword">if</span> (rioWriteBulkLongLong(aof,j) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* I遍历数据库中的每个key value */</span></span><br><span class="line">        <span class="keyword">while</span>((de = dictNext(di)) != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            sds keystr;</span><br><span class="line">            robj key, *o;</span><br><span class="line">            <span class="type">long</span> <span class="type">long</span> expiretime;</span><br><span class="line"></span><br><span class="line">            keystr = dictGetKey(de);</span><br><span class="line">            o = dictGetVal(de);</span><br><span class="line">            initStaticStringObject(key,keystr);</span><br><span class="line"></span><br><span class="line">            expiretime = getExpire(db,&amp;key);</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* 根据key的类型进行重写*/</span></span><br><span class="line">            <span class="keyword">if</span> (o-&gt;type == OBJ_STRING) &#123;</span><br><span class="line">                <span class="comment">/* Emit a SET command */</span></span><br><span class="line">                <span class="type">char</span> cmd[]=<span class="string">&quot;*3\r\n$3\r\nSET\r\n&quot;</span>;</span><br><span class="line">                <span class="keyword">if</span> (rioWrite(aof,cmd,<span class="keyword">sizeof</span>(cmd)<span class="number">-1</span>) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">                <span class="comment">/* Key and value */</span></span><br><span class="line">                <span class="keyword">if</span> (rioWriteBulkObject(aof,&amp;key) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">                <span class="keyword">if</span> (rioWriteBulkObject(aof,o) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (o-&gt;type == OBJ_LIST) &#123;</span><br><span class="line">                <span class="keyword">if</span> (rewriteListObject(aof,&amp;key,o) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (o-&gt;type == OBJ_SET) &#123;</span><br><span class="line">                <span class="keyword">if</span> (rewriteSetObject(aof,&amp;key,o) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (o-&gt;type == OBJ_ZSET) &#123;</span><br><span class="line">                <span class="keyword">if</span> (rewriteSortedSetObject(aof,&amp;key,o) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (o-&gt;type == OBJ_HASH) &#123;</span><br><span class="line">                <span class="keyword">if</span> (rewriteHashObject(aof,&amp;key,o) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (o-&gt;type == OBJ_STREAM) &#123;</span><br><span class="line">                <span class="keyword">if</span> (rewriteStreamObject(aof,&amp;key,o) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (o-&gt;type == OBJ_MODULE) &#123;</span><br><span class="line">                <span class="keyword">if</span> (rewriteModuleObject(aof,&amp;key,o) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                serverPanic(<span class="string">&quot;Unknown object type&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* 如果key带有过期时间，需要保存过期时间 */</span></span><br><span class="line">            <span class="keyword">if</span> (expiretime != <span class="number">-1</span>) &#123;</span><br><span class="line">                <span class="type">char</span> cmd[]=<span class="string">&quot;*3\r\n$9\r\nPEXPIREAT\r\n&quot;</span>;</span><br><span class="line">                <span class="keyword">if</span> (rioWrite(aof,cmd,<span class="keyword">sizeof</span>(cmd)<span class="number">-1</span>) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">                <span class="keyword">if</span> (rioWriteBulkObject(aof,&amp;key) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">                <span class="keyword">if</span> (rioWriteBulkLongLong(aof,expiretime) == <span class="number">0</span>) <span class="keyword">goto</span> werr;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* 从父进程中读取diff的内容 */</span></span><br><span class="line">            <span class="keyword">if</span> (aof-&gt;processed_bytes &gt; processed+AOF_READ_DIFF_INTERVAL_BYTES) &#123;</span><br><span class="line">                processed = aof-&gt;processed_bytes;</span><br><span class="line">                aofReadDiffFromParent();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        dictReleaseIterator(di);</span><br><span class="line">        di = <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> C_OK;</span><br><span class="line"></span><br><span class="line">werr:</span><br><span class="line">    <span class="keyword">if</span> (di) dictReleaseIterator(di);</span><br><span class="line">    <span class="keyword">return</span> C_ERR;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另外，以写入集合键为例，可以看到为了避免在执行命令时导致客户端输入缓冲区溢出，重写快速链表、哈希表、集合和有序集合这种带有多个元素的key时，会先检查key包含的元素数量。如果超过了AOF_REWRITE_ITEMS_PER_CMD，则会使用多条命令进行重写。默认是64。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> AOF_REWRITE_ITEMS_PER_CMD 64</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">rewriteListObject</span><span class="params">(rio *r, robj *key, robj *o)</span> &#123;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> count = <span class="number">0</span>, items = listTypeLength(o);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (o-&gt;encoding == OBJ_ENCODING_QUICKLIST) &#123;</span><br><span class="line">        <span class="comment">//........</span></span><br><span class="line">        <span class="keyword">while</span> (quicklistNext(li,&amp;entry)) &#123;</span><br><span class="line">            <span class="keyword">if</span> (count == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="type">int</span> cmd_items = (items &gt; AOF_REWRITE_ITEMS_PER_CMD) ?</span><br><span class="line">                    AOF_REWRITE_ITEMS_PER_CMD : items; <span class="comment">// 判断key元素是否超过AOF_REWRITE_ITEMS_PER_CMD</span></span><br><span class="line">                <span class="keyword">if</span> (rioWriteBulkCount(r,<span class="string">&#x27;*&#x27;</span>,<span class="number">2</span>+cmd_items) == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">if</span> (rioWriteBulkString(r,<span class="string">&quot;RPUSH&quot;</span>,<span class="number">5</span>) == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">if</span> (rioWriteBulkObject(r,key) == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 写入value，省略</span></span><br><span class="line">          </span><br><span class="line">            <span class="keyword">if</span> (++count == AOF_REWRITE_ITEMS_PER_CMD) count = <span class="number">0</span>; <span class="comment">// 如果超过了则使用多条RPUSH命令重写</span></span><br><span class="line">            items--;</span><br><span class="line">        &#125;</span><br><span class="line">        quicklistReleaseIterator(li);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="aof后台重写">AOF后台重写</h3>
<p>为了避免函数会阻塞服务器处理客户端的请求，Redis将AOF重写放到子进程中执行，同时为了避免在子进程执行AOF重写期间，由于服务器进程在处理新的请求，从而使得现有数据库状态发生改变，Redis设置了一个AOF重写缓冲区，在服务器创建完子进程后开始使用，当Redis执行完一个写命令之后，会同时将写命令发送到AOF缓冲区和AOF重写缓冲区。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">bgrewriteaofCommand</span><span class="params">(client *c)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (server.aof_child_pid != <span class="number">-1</span>) &#123;</span><br><span class="line">        addReplyError(c,<span class="string">&quot;Background append only file rewriting already in progress&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (hasActiveChildProcess()) &#123;</span><br><span class="line">        server.aof_rewrite_scheduled = <span class="number">1</span>;</span><br><span class="line">        addReplyStatus(c,<span class="string">&quot;Background append only file rewriting scheduled&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (rewriteAppendOnlyFileBackground() == C_OK) &#123;</span><br><span class="line">        addReplyStatus(c,<span class="string">&quot;Background append only file rewriting started&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        addReplyError(c,<span class="string">&quot;Can&#x27;t execute an AOF background rewriting. &quot;</span></span><br><span class="line">                        <span class="string">&quot;Please check the server logs for more information.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先判断是否已经存在相关bgrewrite子进程，倘若有会在这些命令完成后执行。否则会fork出子进程。在子进程完成aof重写后，会发一个信号给父进程，父进程会调用backgroundRewriteDoneHandler()将aof重写缓冲区中的所有内容写入到新的aof文件中，然后进行原子性地覆盖旧的aof文件。重写缓冲区的内容是通过aofRewriteBufferWrite写入到新的aof文件中的。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ssize_t</span> <span class="title function_">aofRewriteBufferWrite</span><span class="params">(<span class="type">int</span> fd)</span> &#123;</span><br><span class="line">    listNode *ln;</span><br><span class="line">    listIter li;</span><br><span class="line">    <span class="type">ssize_t</span> count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    listRewind(server.aof_rewrite_buf_blocks,&amp;li);</span><br><span class="line">  	<span class="comment">// 逐个地将aof_rewrite_buf_blocks缓冲区中的内容重写到aof文件</span></span><br><span class="line">    <span class="keyword">while</span>((ln = listNext(&amp;li))) &#123;</span><br><span class="line">        aofrwblock *block = listNodeValue(ln);</span><br><span class="line">        <span class="type">ssize_t</span> nwritten;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (block-&gt;used) &#123;</span><br><span class="line">            nwritten = write(fd,block-&gt;buf,block-&gt;used);</span><br><span class="line">            <span class="keyword">if</span> (nwritten != (<span class="type">ssize_t</span>)block-&gt;used) &#123;</span><br><span class="line">                <span class="keyword">if</span> (nwritten == <span class="number">0</span>) errno = EIO;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            count += nwritten;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/">&lt;i class&#x3D;&quot;fa fa-angle-left&quot;&gt;&lt;&#x2F;i&gt;</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/5/">&lt;i class&#x3D;&quot;fa fa-angle-right&quot;&gt;&lt;&#x2F;i&gt;</a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="" />
          <p class="site-author-name" itemprop="name"></p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">273</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">29</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LucienXian</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
