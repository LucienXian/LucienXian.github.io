<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="LucienXian's Blog" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2">






<meta name="description" content="LucienXian&apos;s Garden">
<meta property="og:type" content="website">
<meta property="og:title" content="LucienXian&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="LucienXian&#39;s Blog">
<meta property="og:description" content="LucienXian&apos;s Garden">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LucienXian&#39;s Blog">
<meta name="twitter:description" content="LucienXian&apos;s Garden">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/">





  <title>LucienXian's Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LucienXian's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-/tags"></i> <br>
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/08/In-Search-of-an-Understandable-Consensus-Algorithm-二-——MIT6-824/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LucienXian">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/08/In-Search-of-an-Understandable-Consensus-Algorithm-二-——MIT6-824/" itemprop="url">In Search of an Understandable Consensus Algorithm<二>——MIT6.824</二></a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-08T20:51:24+08:00">
                2019-04-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="In-Search-of-an-Understandable-Consensus-Algorithm-lt-二-gt"><a href="#In-Search-of-an-Understandable-Consensus-Algorithm-lt-二-gt" class="headerlink" title="In Search of an Understandable Consensus Algorithm&lt;二&gt;"></a>In Search of an Understandable Consensus Algorithm&lt;二&gt;</h1><h2 id="Cluster-membership-changes"><a href="#Cluster-membership-changes" class="headerlink" title="Cluster membership changes"></a>Cluster membership changes</h2><p>上一篇<a href="http://www.lucienxian.top/2019/03/27/In-Search-of-an-Understandable-Consensus-Algorithm-%E4%B8%80-%E2%80%94%E2%80%94MIT6-824/" target="_blank" rel="noopener">博文</a>中，我们都假设集群配置是固定的。但在实践中往往需要更改配置，可能需要更换服务器或者更改备份配置。为了使配置变更机制更加安全，在过渡期间不存在任意一个时间点会存在两个leader，但任何从旧配置切换到新配置的方法都是不够安全的，在切换期间可能会存在分裂成两个集群，如图：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_two_disjoint_majorities.png" alt="img"></p>
<p>为了确保安全，配置更改可以使用两阶段的方法。在raft中，集群首先切换到过渡配置，即为<strong>joint consensus</strong>。一旦commit了joint consensus，系统就会切换到新配置。</p>
<ul>
<li>日志会被复制到两种配置中的所有服务器；</li>
<li>两种配置中的任何服务器就可以成为leader；</li>
<li>选举等协议需要新旧两种配置的大多数票；</li>
</ul>
<p>我们使用复制的日志中特殊条目来存储和传送集群配置，下图就是配置更改过程：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_Timeline_Conf_change.png" alt="img"></p>
<p>当leader收到请求，从Cold配置更改为Cnew时，它会将联合共识即$C_{old, new}$存储为日志。如果leader crash了，新的leader会在$C_{old}$和$C_{old, new}$中选择。</p>
<p>更改配置后还有三个问题需要解决；</p>
<ul>
<li>新服务器可能一开始不会存储任何日志；raft的解决方法是在更改配置之前引入一个额外的阶段，在该阶段新的服务器以非投票成员的身份加入集群，leader会将日志复制到它们，但不参与投票；</li>
<li>集群leader可能并不属于新配置；在这种情况下，leader在提交了日志$C_{new}$之后就会返回到follower阶段；</li>
<li>删除的服务器可能会破坏集群；这些服务器不再接受心跳，因此会超时用新的term发送RequestVote RPC请求选举，并且重复这个过程。为了避免这个问题，服务器会在当前leader存在时，忽略掉RequestVote RPC，不会更新term或者授予票数；</li>
</ul>
<h2 id="Log-compaction"><a href="#Log-compaction" class="headerlink" title="Log compaction"></a>Log compaction</h2><p>日志会在服务器运行期间无限增长，如果我们不及时丢弃过期的日志，那么对着日志的增长，它会占据更多的内存空间并需要更多时间来重新执行日志。</p>
<p>snapshot是最简单的压缩方法，下图就是raft的快照方式：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_snapshot.png" alt="img"></p>
<p>每个服务器独立获取快照，快照内容仅仅覆盖了已提交的条目。快照除了包括状态集信息之外，还包含了少量的元数据信息，如上图就包含了最近索引和term。包含了这些信息，可以帮助支持快照后第一个日志条目的AppendEntries一致性检查。</p>
<p>虽然服务器独立生成快照，但一般情况下，如果有一个落后非常多的follower或者新的服务器加入集群，leader会通过InstallSnapshot RPC往其它服务器发送快照。</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_InstallSnapshot_RPC.png" alt="img"></p>
<p>如果snapshot中包含了follower未包含的日志新内容，该follower会丢弃整个日志，并用snapshot替代。如果接收者收到的snapshot是当前日志的前缀部分，则该快照后面的条目保留，其余删除。</p>
<p>如果是由leader生成snapshot再转发到各个follower，这种做法会浪费网络带宽并降低生成快照的速度。另外还有两个问题会影响性能：</p>
<ul>
<li>服务器必须决定何时进行快照。一个简单的策略是在日志达到固定大小（以字节为单位）时拍摄快照，此大小设置为远大于快照的预期大小，则用于快照的磁盘带宽开销将很小</li>
<li>写快照可能需要很长时间，我们不希望这会延迟正常操作。解决方案是写时拷贝</li>
</ul>
<h2 id="Client-interaction"><a href="#Client-interaction" class="headerlink" title="Client interaction"></a>Client interaction</h2><p>本节主要描述raft客户端与raft的交互。</p>
<p>raft将所有的客户端请求发送到leader，如果客户端联系的不是leader，那么服务器会拒绝这一请求，并提供最新的leader地址。</p>
<p>我们对Raft的目标是实现可线性化的语义（即每个操作似乎在其调用和响应之间的某个时刻只执行一次）。但如果leader在提交日志条目之后但在响应客户端之前发生了冲突，则客户端将使用新的leader重试该命令，从而变成了二次执行。解决方案是客户端为每个命令分配唯一的序列号，如果它收到一个序列号已经执行的命令，它会立即响应而不重新执行请求。</p>
<p>只读操作可能会因为leader的重新选举而返回过时的数据，raft需要在不使用日志的情况下确保自己不返回过期的数据，这里采取两个措施：</p>
<ul>
<li>首先，leader必须拥有关于提交的日志的最新信息。虽然leader拥有所有提交了的日志，但leader不知道这是什么，Raft通过让每个leader在其任期开始时将空白的无操作日志条目输入到日志中来处理此问题。</li>
<li>其次，leader必须在处理只读请求之前检查它是否已被废除；这个可以通过与大多数集群交换心跳来解决；</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/06/特征选择与稀疏学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LucienXian">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/06/特征选择与稀疏学习/" itemprop="url">特征选择与稀疏学习</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-06T22:20:06+08:00">
                2019-04-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="特征选择与稀疏学习"><a href="#特征选择与稀疏学习" class="headerlink" title="特征选择与稀疏学习"></a>特征选择与稀疏学习</h1><h2 id="子集搜索与评价"><a href="#子集搜索与评价" class="headerlink" title="子集搜索与评价"></a>子集搜索与评价</h2><p>对一个学习任务来说，有些属性很关键，而从给定的特征集合中选择出相关特征子集的过程，就叫”特征选择”(feature selection)。</p>
<p>除了无用特征，还有一类冗余特征，它的信息是从其它特征推断出来的。大部分时候这些特征是不起作用，但有时也会起到中间特征的作用，使得学习更加方便。</p>
<p>提取特征的一个可行做法是先产生一个候选子集，评估好坏，再根据评估结果去产生下一个候选子集，依次迭代。</p>
<ol>
<li>子集搜索</li>
</ol>
<p>这第一个环节就是”子集搜索”，给定特征集合${a_1, a_2, …, a_d}$。对于前向搜索，对这个d个特征子集进行评价，假设${a_2}$最优，接着从剩下的d-1个特征选一个特征，假设此时两特征集合${a_2, a_4}$最优，并且由于${a_2}$效果更好，则选择${a_2, a_4}$。依次进行，直到最优的候选子集不如上一轮选定集合，则停止生成候选子集。而对于后向搜索，则是每次减去一个无关特征。</p>
<p>这种贪心的策略可能会遇到这样一种情况，第三轮选了${a_2,a_4,a_5}$，而第四轮却可能是${a_2,a_4,a_6,a_8}$更好。这是不可避免的。</p>
<ol start="2">
<li>子集评价</li>
</ol>
<p>给定数据集D，假设D中第i类样本所占的比例为$p_i(i=1,2,..,|y|)$，另外对于属性子集A，假定根据其取值将D划分为V个子集:${D^1, D^2, ,,., D^V}$，每个子集中的样本在属性A上取值相同，则计算属性子集A的信息增益：<br>$$<br>Gain(A) = Ent(D) - \sum_{v=1}^V \frac{|D^v|}{|D|}Ent(D^v) \<br>Ent(D) = - \sum_{k=1}^{|y|} p_k log_2p_k<br>$$<br>Gain(A)越大，意味着特征子集A对数据集D的划分与样本标记信息对于D的真实划分，差异越小，则越有助于分类。</p>
<p>常见的特征选择方法有：过滤式、包裹式、嵌入式</p>
<h2 id="过滤式选择"><a href="#过滤式选择" class="headerlink" title="过滤式选择"></a>过滤式选择</h2><p>过滤式方法先对数据集进行特征选择——“过滤”，然后再训练学习器。Relief是一种过滤式特征选择方法，其设计了一个”相关统计量”来度量特征的重要性，该统计量是一个向量，每个分量对应一个初始特征，特征子集的重要性由子集中每个特征所对应的相关统计量分量之和所决定。</p>
<p>Relief的关键是如何确定相关统计量。假设样本为${(x_1,y_1), (x_2, y_2),…, (x_m,y_m)}$。对于每个样本$x_i$，该算法先在$x_i$的同类样本中寻找最近邻$x_{i,nh}$，再从异样样本中寻找其最近邻$x_{i,nm}$。相关统计量对应属性j的分量为：<br>$$<br>\delta^j = \sum_i -diff(x_i^j, x_{i,nh}^j)^2 + \sum_{l\neq k}(x_i^j, x_{i,nm}^j)^2<br>$$<br>如果属性j为离散型，则$diff(x_a^j, x_b^j)^2$的值域为[0, 1]。若是连续型，则是$|x_a^j-x_b^j|$。</p>
<p>由上式可以看出，若$x_i$与同类样本更近，则属性j对于区分同类与异类的样本是有益的。</p>
<p>上述Relief算法是为二分类问题准备的，其扩展变形Relief-F则能够处理多分类问题：<br>$$<br>\delta^j = \sum_i -diff(x_i^j, x_{i,nh}^j)^2 + \sum_{l\neq k}(p_l \times (x_i^j, x_{i,nm}^j)^2)<br>$$<br>其中$p_l$为第l类样本在数据集D中所占的比例。</p>
<h2 id="包裹式选择"><a href="#包裹式选择" class="headerlink" title="包裹式选择"></a>包裹式选择</h2><p>包裹式特征选择直接把最终将要使用的学习器性能最为特征子集的最终评价标准，因为是为了目的学习器选择特征子集，因此往往比过滤式选择性能更好。</p>
<p>LVW是其中的代表，算法描述为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">输入： 数据集D</span><br><span class="line">			特征集A</span><br><span class="line">			学习算法O</span><br><span class="line">			停止条件控制参数T</span><br><span class="line">过程：</span><br><span class="line">1. E = inf</span><br><span class="line">2. d = |A|</span><br><span class="line">3. A* = A</span><br><span class="line">4. t = O</span><br><span class="line">5. while t &lt; T do</span><br><span class="line">		随机生成特征子集A&apos;</span><br><span class="line">		d&apos; = |A&apos;|</span><br><span class="line">		E&apos; = CrossValidation(O(D^A&apos;))</span><br><span class="line">		if (E&apos;&lt;E) or ((E&apos;=E)and(d&apos;&lt;d)) then</span><br><span class="line">			t = 0</span><br><span class="line">			E = E&apos;</span><br><span class="line">			d = d&apos;</span><br><span class="line">			A* = A&apos;</span><br><span class="line">		else</span><br><span class="line">			t = t+1</span><br><span class="line">		endif</span><br><span class="line">	endwhile</span><br><span class="line">输出A&apos;</span><br></pre></td></tr></table></figure>
<p>由于特征搜索时使用了随机策略，因此每次特征子集评价都需要训练学习器，因此开销很大，我们设置停止条件控制参数。</p>
<h2 id="嵌入式选择与L1正则化"><a href="#嵌入式选择与L1正则化" class="headerlink" title="嵌入式选择与L1正则化"></a>嵌入式选择与L1正则化</h2><p>嵌入式特征选择是将特征选择与学习器训练过程融合为一体，给定数据集$D = {(x_1,y_1),(x_2, y_2),…,(x_m,y_m)}$，考虑简单的线性回归模型，以平方差为损失函数：<br>$$<br>min_w \sum_{i=1}^m(y_i-w^Tx_i)^2<br>$$<br>为了避免过拟合，加入范数正则化：<br>$$<br>min_w \sum_{i=1}^m(y_i-w^Tx_i)^2 + \lambda||w||^2_2—-L_2范数 \<br>min_w \sum_{i=1}^m(y_i-w^Tx_i)^2 + \lambda||w||_1—-L_1范数<br>$$<br>L1范数相对于L2范数更容易带来稀疏解，即它求得的w具有更少的非零分量。假设x只有两个属性，同理解w也只有两个分量，因此我们画出等值线：</p>
<p><img src="https://upload.wikimedia.org/wikipedia/en/f/fd/L1_and_L2_balls.jpg" alt="img"></p>
<p>可以看到的是，由于上面w的解必须要在误差项与正则化项之间折中，因此即有图中的误差项等值线与正则化项等值线相交，采用L1范数时，相交点一般在坐标轴上，则w1或者w2为0。这意味着采用L1范数正则化的结果是得到了对应w的非零分量的特征。</p>
<p>其特征选择过程与学习器训练融为一体，同时完成。</p>
<h2 id="稀疏表示与字典学习"><a href="#稀疏表示与字典学习" class="headerlink" title="稀疏表示与字典学习"></a>稀疏表示与字典学习</h2><p>假设数据集D是一个矩阵，行对应每个样本，列则对应特征，特征选择考虑的是如何使得矩阵变得稀疏，即某些特征与学习任务无关，我们可以去掉这些咧从而提高学习速度。</p>
<p>但考虑另一种稀疏性，即D对应的矩阵中存在很多零元素。但样本具有这样的稀疏表达形式时，学习任务会得到许多好处，例如线性支持向量机能使大多数问题变得线性可分，同时也不会带来存储上的负担。</p>
<p>若提供的数据集是稠密的，我们需要学习出一个”字典”，从而使得稠密数据转化为”恰当稀疏”的数据。</p>
<p>给定数据集${x_1,x_2,…,x_m}$，字典学习的最简单形式为：<br>$$<br>min_{B,\alpha_i} || x_i-B\alpha_i ||^2_2 + \lambda \sum_{i=1}^m || \alpha_i ||_1<br>$$<br>其中B为字典矩阵，$\alpha_i$则是样本$x_i$的稀疏表示。该式的第一项是希望$\alpha_i$能够尽可能重构样本，而第二项则是希望$\alpha_i$尽可能稀疏。</p>
<h2 id="压缩感知"><a href="#压缩感知" class="headerlink" title="压缩感知"></a>压缩感知</h2><p>在现实任务中，我们常希望能够通过部分信息来恢复全部信息，假定有长度为m的离散信号x，采样后得到长度为n的信号y，其中n&lt;&lt;m：<br>$$<br>y = \phi x<br>$$<br>其中$\phi \in R^{n \times m}$表示对信号x的测量矩阵，而由于n&lt;&lt;m，因此上式是一个欠定方程。</p>
<p>现在假设存在某个线性变换$\psi \in R^{n \times m}$，使得y表示为：<br>$$<br>y = \phi \psi s = As<br>$$<br>若能恢复出s，我们也可以最后恢复出x。虽然这个问题仍然是欠定的，但如果s具有稀疏性，我们就可以解决这个问题了。这里A的作用则类似于字典，能够将信号转换为稀疏表示。</p>
<p>压缩感知分为”感知测量”和”重构恢复”两个阶段，前者关注如何对原始信号进行处理以获得稀疏样本表示，后者则是基于稀疏性从少量观察中恢复原信号。</p>
<p>对于大小为nXm的矩阵A，若存在常数$\delta_k \in (0, 1)$使得对任意常量s和A的所有子矩阵$A_k \in R^{n\times k}$有：<br>$$<br>(1-\delta_k)||s||_2^2 \leq || A_ks ||_2^2 \leq (1+\delta_k)||s||_2^2<br>$$<br>则称A满足k限定等距性，此时可通过下面的优化问题从y中恢复出稀疏信号s：<br>$$<br>min_s || s ||_0 \<br>s.t. \ \ y = As<br>$$<br>但该式涉及到L0范数最小化，这是一个NP难的问题，但由于L1范数最小化在一定条件下与L0范数最小化问题同解，因此有：<br>$$<br>min_s || s ||_1 \<br>s.t. \ \ y = As<br>$$</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/30/降纬与度量学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LucienXian">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/30/降纬与度量学习/" itemprop="url">降纬与度量学习</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-30T11:10:06+08:00">
                2019-03-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="降纬与度量学习"><a href="#降纬与度量学习" class="headerlink" title="降纬与度量学习"></a>降纬与度量学习</h1><h2 id="k近邻学习"><a href="#k近邻学习" class="headerlink" title="k近邻学习"></a>k近邻学习</h2><p>k近邻学习是一种常见的监督学习方法，给定测试样本，然后基于某种距离度量找出训练样本中与测试样本距离最近的k个样本。在预测结果时，既可以通过投票法选择k个样本中出现最多的类标记，也可以在回归任务中使用平均法计算输出标记的平均值，还可以基于距离远近进行加权平均或者加权投票。</p>
<p>给定测试样本x，若其最近邻样本为z，则该分类器的出错概率就是x与z类标记不同的概率：<br>$$<br>P(err) = 1 - \sum_{c \in y} P(c|x)P(c|z)<br>$$</p>
<h2 id="低维嵌入"><a href="#低维嵌入" class="headerlink" title="低维嵌入"></a>低维嵌入</h2><p>假设测试样本x附近任意小的$\sigma$距离范围内总能找到一个训练样本，即需要实现足够大的密度采样。然而这种情况在现实生活中却不容易实现，以$\sigma=0.001$为例，单个属性就需要1000个样本点平均分布在归一化后的属性取值范围内。但假如属性维度数目达到了20，样本就指数增长到(10^3)^20，这就是出现了所谓的维数灾难(curse of dimensionality)。</p>
<p>缓解这个问题的一个重要途径是实现降维，之所能降维，是因为往往与学习任务相关的属性仅仅是某个低维分布。若要求原始空间样本中样本之间的距离在低维空间得以保持，则要实现”多维缩放”(MDS——Multiple Dimensional Scaling)。</p>
<p>假设m个样本在原始空间的距离矩阵为$D\in R^{m X m}$，其第i行h列的元素$dist_{ij}$为样本$x_i$到$x_j$的距离。而我们的目标是获得样本在$d’$维空间的表示$Z\in R^{d’Xm}$，d’比d小，且任意两个样本在d’维空间中的欧式距离应该与原始空间相等或者近似于。</p>
<p>令$B=Z^TZ \in R^{mXm}$，且$b_{ij}=z_i^Tz_j$，则有：<br>$$<br>dist_{ij}^2 = b_{ii} + b_{jj} - 2b_{ij}<br>$$<br>令降维后的样本Z被中心化，即$\sum_{i=1}^mz_i=0$，矩阵B的行与列之和为0，则有：<br>$$<br>\sum_{i=1}^m dist_{ij}^2 = tr(B) + mb_{jj} \<br>\sum_{j=1}^m dist_{ij}^2 = tr(B) + mb_{ii} \<br>\sum_{i=1}^m\sum_{j=1}^m dist_{ij}^2 = 2m \ tr(B)<br>$$<br>其中，tr为矩阵的trace，$tr(B) = \sum_{i=1}^m || z_i ||^2$：<br>$$<br>dist_{i.}^2 = \frac{1}{m}\sum_{j=1}^m dist_{ij}^2 \<br>dist_{.j}^2 = \frac{1}{m}\sum_{i=1}^m dist_{ij}^2 \<br>dist_{..}^2 = \frac{1}{m^2}\sum_{i=1}^m\sum_{j=1}^m dist_{ij}^2<br>$$<br>根据上式，可得：<br>$$<br>b_{ij} = -\frac{1}{2}(dist_{ij}^2-dist_{i.}^2-dist_{.j}^2+dist_{..}^2)<br>$$<br>由此可见，我们可以通过降维前后保持不变的距离矩阵D求取内积矩阵B。对矩阵B做特征值分解，取A为d‘个最大特征值所构成的对角矩阵，V为相应的特征向量矩阵。<br>$$<br>Z = A^{1/2}V^T \in R^{d’Xm}<br>$$<br>一般来说，想要获得低维子空间，最简单是对原始高维空间进行线性变换，这就是线性降维方法。</p>
<h2 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h2><p>主成分分析(Principal Component Analysis，简称PCA)是最常用的一种降维方法。简单来说，就是用一个超平面来对所有样本进行适当的表达，这个超平面应该具有的性质：</p>
<ul>
<li>样本点到这个超平面的距离都足够近；</li>
<li>样本点在这个超平面的投影尽可能分开；</li>
</ul>
<p>假设样本进行了中心化，即$\sum_ix_i=0​$，再假定投影变换后的新坐标系为${w_1,w_2,…,w_d}​$，其中$w_i​$是标准正交基。假设降维之后样本点$x_i​$在低维空间下的投影是$z_i = {z_{i1},z_{i2},…,z_{id’}}​$。其中，$z_{ij}=w_j^Tx_i​$，重构回来的投影带点为$x_i=\sum_{j=1}^{d’}z_{ij}w_j​$。</p>
<p>考虑整个数据集，原样本点与重构后的投影点之间的距离：<br>$$<br>\sum_{i=1}^m||\sum_{j=1}^{d’}z_{ij}w_j - x_i||^2_2 = \sum_{i=1}^mz_i^Tz_i-2\sum_{i=1}^mz_i^TW^Tx_i+const \varpropto - tr(W^T(\sum_{i=1}^mx_ix_i^T)W)<br>$$<br>根据上面的属性要求，我们需要最小化上式：<br>$$<br>min \  -tr(W^TXX^TW)<br>$$<br>而为了使得所有样本点的投影尽可能分散，则最大化投影后样本点的方差 $\sum_i W^Tx_ix_iW$：<br>$$<br>max \ tr(W^TXX^TW)<br>$$<br>可见，两个优化目标等价，对其使用拉格朗日乘子法，得：<br>$$<br>XX^Tw_i = \lambda_iw_i<br>$$<br>然后对协方差矩阵$XX^T$进行特征值分解，将求得的特征值进行排序，再取前n个特征值对应的特征向量构成$W^*=(w_1,w_2,…,w_n)$。</p>
<h2 id="核化线性降维"><a href="#核化线性降维" class="headerlink" title="核化线性降维"></a>核化线性降维</h2><p>在现实任务中，需要实现非线性映射才能找到恰当的低维嵌入。非线性将维的一种常用方法是基于核技巧对线性将维方法进行”核化”。</p>
<p>假设我们将在高维特征空间中把数据投影到$W=(w_1,w_2,..,w_d)$确定的超平面上，根据上面的式子有：<br>$$<br>(\sum_{i=1}^mz_iz_i^T)w_j = \lambda_jw_j<br>$$<br>其中$z_i$是样本点$x_i$在高维特征空间中的像，因此有:<br>$$<br>w_j = \frac{1}{\lambda_j}(\sum_{i=1}^mz_iz_i^T)w_j = \sum_{i=1}^m z_i \frac{z_i^Tw_j}{\lambda_j} = \sum_{i=1}^m z_i \alpha_i^j<br>$$<br>假定$z_i = \phi(x_i)$，即原始属性空间中的样本点通过映射$\phi$产生。</p>
<p>因此前面的式子可以变换为<br>$$<br>(\sum_{i=1}^m \phi(x_i)\phi(x_i)^T) w_j= \lambda_jw_j \<br>w_j = \sum_{i=1}^m \phi(x_i) \alpha_i^j<br>$$<br>由于我们不知道$\phi$的具体形式，因此引入核函数：<br>$$<br>k(x_i, x_j) = \phi(x_i)\phi(x_i)^T<br>$$<br>将上面的式子化简后，得到：<br>$$<br>K \alpha^j = \lambda_j\alpha^j<br>$$<br>这里又变成了特征值分解的问题，取K最大的d’个特征值对应的特征向量即可。</p>
<h2 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h2><p>“流形”是在局部与欧氏空间同胚的空间，它在局部具有欧氏空间的性质，能用欧式距离来进行距离计算。若低维流形嵌入到高维空间中，其局部仍然具有欧氏空间的性质，因此可以在局部建立降维映射关系，并设法将局部关系推广到全局。</p>
<h3 id="等度量映射"><a href="#等度量映射" class="headerlink" title="等度量映射"></a>等度量映射</h3><p>等度量映射(Isomap)的一个出发点：低维流形嵌入到高维空间之后，直接在高维空间中计算直线距离具有误导性，可能会丢失某些信息。以下图为例：</p>
<p><img src="http://blog.pluskid.org/wp-content/uploads/2010/05/isomap-graph.png" alt="img"></p>
<p>如果使用传统的欧氏距离来作为距离尺度，显然会抛弃“数据的内部特征”，即假设一只虫子从一点到另一点，如果它不能脱离图中的曲面行走，那么红色曲线才是距离最短的路径。</p>
<p>如上图，低维嵌入流形上两点间的距离是”测地线”距离，要求得这个距离，可以对每个点基于欧氏距离找出其近邻点，然后就能建立一个近邻连接图。这样计算两点之间的测地线距离的问题，就变成了临接图上两点之间的最短路径问题。</p>
<p>构建近邻图也有两种做法：一种是指定近邻点个书，例如欧氏距离最近的k个点为近邻点；另一种则是指定距离阈值$\epsilon$，小于这个距离的点则认为是近邻点。</p>
<h3 id="局部线性嵌入"><a href="#局部线性嵌入" class="headerlink" title="局部线性嵌入"></a>局部线性嵌入</h3><p>与Isomap不同的是，局部线性嵌入LLE试图保持领域内样本之间的线性关系，如图：</p>
<p><img src="http://science.sciencemag.org/content/sci/290/5500/2323/F2.large.jpg?width=800&amp;height=600&amp;carousel=1" alt="img"></p>
<p>假设样本点可以通过它的领域样本线性重构：<br>$$<br>x_i = w_{ij}x_j+w_{ik}x_k+w_{il}x_;<br>$$<br>LLE希望上式的关系在低维空间中得以保持。</p>
<p>算法步骤；</p>
<ol>
<li>LLE首先为每个样本找到其近邻下标集合$Q_i$，然后计算出样本点对$x_i$进行线性重构的系数$w_i$：</li>
</ol>
<p>$$<br>min \sum_{i=1}^m || x_i - \sum_{j \in Q_i} w_{ij}x_j||^2_2 \<br>\sum_{j \in Q_i} w_{ij} = 1<br>$$</p>
<p>令$C_{jk} = (x_i-x_j)^T(x_i-x_j)$，$w_{ij}$有闭式解：<br>$$<br>w_{ij} = \frac{\sum_{k\in Q_i} C_{jk}^{-1}}{\sum_{l,s \in Q_i} C_{ls}^{-1}}<br>$$<br>LLE在低维空间中保持$w_i$不变，因此低维空间坐标$z_i$可通过以下求解：<br>$$<br>min \sum_{i=1}^m || z_i - \sum_{j \in Q_i} w_{ij}z_j||^2_2 \<br>M = (1-W)^T(1-W)<br>$$<br>则上式可以重写为：<br>$$<br>min \ tr(ZMZ^T) \<br>ZZ^T = 1<br>$$<br>然后对改式通过特征值分解，M最小的k个特征值组成的矩阵即为$Z^T$.</p>
<h2 id="度量学习"><a href="#度量学习" class="headerlink" title="度量学习"></a>度量学习</h2><p>在机器学习中，对高维数据进行降维的目的是找到一个合适的低维空间，而由于每个空间对应了在样本属性定义的一个距离度量。因此寻找合适的空间就是寻找一个合适的距离度量。</p>
<p>对两个d维的样本$x_i, x_j$，引入属性权重后的平方欧氏距离为：<br>$$<br>dist_{wed}^2(x_i,x_j) = ||x_i-x_j||^2_2 = w_1\cdot dist_{ij,1}^2 + w_2\cdot dist_{ij,2}^2+…+w_d\cdot dist_{ij,d}^2 \<br>=(x_i-x_j)^TW(x_i-x_j)<br>$$<br>其中W=diag(w)是一个对角矩阵。</p>
<p>由于W的非对角矩阵为0，因此坐标轴是正交的，即属性之间无关，但现实生活中属性往往是相关的，因此可以将W替换为一个普通的半正定对称矩阵M。由此可得到马氏距离：<br>$$<br>dist_{mat}^2(x_i,x_j) =(x_i-x_j)^TM(x_i-x_j)= ||x_i-x_j||^2_M<br>$$<br>度量学习必须对M进行学习，而因为M是半正定对称矩阵，因此一定存在正交基P使得$M=PP^T$。</p>
<p>对M学习需要设置合适优化目标，不同度量学习方法针对不同的目标获得合适半正定对称距离度量矩阵M。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/27/In-Search-of-an-Understandable-Consensus-Algorithm-一-——MIT6-824/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LucienXian">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/27/In-Search-of-an-Understandable-Consensus-Algorithm-一-——MIT6-824/" itemprop="url">In Search of an Understandable Consensus Algorithm<一>——MIT6.824</一></a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-27T20:33:49+08:00">
                2019-03-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="In-Search-of-an-Understandable-Consensus-Algorithm-lt-一-gt"><a href="#In-Search-of-an-Understandable-Consensus-Algorithm-lt-一-gt" class="headerlink" title="In Search of an Understandable Consensus Algorithm&lt;一&gt;"></a>In Search of an Understandable Consensus Algorithm&lt;一&gt;</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Raft是用于管理复制日志的一致性算法，但由于与paxos结构不同，raft更加容易被理解。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>共识算法可以使得一组机器作为一个工作组，在某些成员故障时仍然能很好地运行。</p>
<p>raft算法有几点创新点：</p>
<ul>
<li>Strong leader：例如所有日志都只能从该leader流向其它服务器；</li>
<li>Leader election：Raft使用随机的定时器来选举leader；</li>
<li>Membership changes：raft更改集群中服务器集的机制，使用了一种新的共识算法，两种不同配置的机器允许在转换期间重叠；</li>
</ul>
<h2 id="Replicated-state-machines"><a href="#Replicated-state-machines" class="headerlink" title="Replicated state machines"></a>Replicated state machines</h2><p>共识算法通常出现在复制状态机的上下文中，通过复制日志实现，如下图，每个服务器都存储着一些列命令的日志，状态机按顺序执行，由于状态机时确定性的，因此每个都计算出相同的状态和输出序列。</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/Replicated_state_machine_arch.png" alt="img"></p>
<p>保障复制日志的一致性是一致性算法的工作。服务器的共识模块从客户端接受命令并将其添加到日志中。正确复制命令后，每个服务器的状态机按日志顺序处理它们，并将输出返回给客户端。</p>
<p>生产系统的共识算法具备以下特点：</p>
<ul>
<li>safety：永远不返回不正确的结果，包括网络延迟，分区和数据包丢失，重复和重新排序；</li>
<li>只要大多数服务器都可以运行并且可以与客户和客户进行通信，它们就可以正常运行（可用）；</li>
<li>不依赖于时间来确保日志的一致性；</li>
<li>在通常情况下，只要大多数群集响应了RPC，命令就可以完成；</li>
</ul>
<h2 id="The-Raft-consensus-algorithm"><a href="#The-Raft-consensus-algorithm" class="headerlink" title="The Raft consensus algorithm"></a>The Raft consensus algorithm</h2><p>下图简洁地总结了raft算法：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_sum.png" alt="img"></p>
<p>raft通过选举一个leader来实现共识，然后让该leader负责管理复制的日志。leader可能会与服务器断开连接，这时需要选出新的leader。</p>
<h3 id="raft-basic"><a href="#raft-basic" class="headerlink" title="raft basic"></a>raft basic</h3><p>raft集群中包含多个服务器，在任意时间内，每个服务器都处于以下三种状态之一：leader、follower、candidate。一般情况下，只有一个leader，其它都是follower。follower不会自发请求，而是响应leader和candidate的请求，leader处理所有来自client的请求（即便client私自联系了follower，也会被重定向到leader）。以下是状态转换图：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_server_states.png" alt="img"></p>
<p>raft将时间划分为任意长度，如下图：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_terms.png" alt="img"></p>
<p>term是一个逻辑时钟，采用连续的整数编号。每个term都以选举开始，如果有candidate成为了leader，那么它将成为在剩下的term时间内成为leader。raft保障在一个term内最多只有一个leader。</p>
<p>不同的服务器可以在不同的时间观察term之间的转换，每个服务器都有一个当前的term编号，并且随着时间单调递增。服务器间通信时交换当前term。如果一个服务器的当前term小于另一个服务器的当前term，则它将其当前term更新为更大的值。 如果候选人或领导者发现其term已过期，则会立即变成到follower的状态。 如果服务器收到带有过期term的请求，它将拒绝该请求。</p>
<p>Raft服务器使用远程过程调用（RPC）进行通信。RequestVote RPCs由candidate在选举期间启动，Append-Entries RPCs由leader发起，用来复制日志条目并提供心跳形式。</p>
<h3 id="Leader-election"><a href="#Leader-election" class="headerlink" title="Leader election"></a>Leader election</h3><p>raft使用心跳机制出发leader选举，leader向所有follower定期发送heartbeat(log entry为空的appendEntries RPC)。如果follower在选举超时的一定时间内没有收到任何联系，则会假定没有leader并开始重新选举。</p>
<p>在开始选举时，follower会增加当前的term，并切换到candidate状态，然后它会给自己投上一票，并向所有其它server发送RequestVote RPC。candidate接下来会遇到以下三种情况：</p>
<ul>
<li>它赢得了选举；</li>
<li>有其他服务器成为了leader；</li>
<li>一段时间内没有选出leader；</li>
</ul>
<p>如果candidate在相同的期限内收到来自完整集群中大多数服务器的投票，则candidate将赢得选举。每个服务器将按照first-come-first-served的规则对给定期限内的一个候选人进行投票。一旦赢得选举，它会向所有其它服务器发送heartbeat，以确定自己的身份并阻止后续选举。</p>
<p>在等待投票时，candidate可能会从另外的服务器上收到声称自己的是leader的AppendEntries RPC，这时会比较term，如果当前term小于RPC的term，则会视为合法，并返回follower状态。否则会拒绝RPC并保持candidate状态。</p>
<p>第三种情况是由于出现了许多的candidate，使得投票分割，以便没有candidate获得多数票。这样每个candidate会超时并开始一个新的选举，增加其term。但是，如果不采取额外措施，分割票数可能会无限期重复。</p>
<p>raft使用随机选举超时的机制来避免分割投票，从固定的范围内随机选择时间(150-300ms)选择一个时间作为选举超时，使得在大多数情况下只有一台服务器会超时，它会赢得选举并在其他服务器超时之前发送heartbeat。同理，这样可以解决分割投票的问题，每个candidate在重新选举时重启并选择随机选举超时，这减少了新选举时另一次分割投票的可能性。</p>
<h3 id="Log-replication"><a href="#Log-replication" class="headerlink" title="Log replication"></a>Log replication</h3><p>在leader选举完毕之后，就开始为client请求提供服务，client把这些命令提供给状态机，leader则把命令作为新的条目添加到日志中，并通过<strong>AppendEntries RPC</strong>并行地发送到每个其它的服务器以复制条目。如果发送失败/包丢失/follower崩溃，leader会无限重试。</p>
<p>日志的组织结构如下，每个条目都有一个term编号：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_logs_entries.png" alt="img"></p>
<p>Raft保证提交的条目是持久的，并最终由所有可用的状态机执行。一旦创建条目的领导者将其复制到大多数服务器上（例如，上图中的条目7），就会提交日志条目。并且还会提交leader日志中的所有前面的日志。</p>
<p>Log Matching属性：</p>
<ul>
<li>如果不同日志中的两个条目具有相同的index和term，则它们存储相同的命令。</li>
<li>如果不同日志中的两个条目具有相同的index和term，则所有前面的条目中的日志相同。</li>
</ul>
<p>第一个属性是基于leader在给定的term中最多创建一个具有给定日志索引的条目，并永远不会更改其在日志中的位置；第二个属性由AppendEntries执行的简单一致性检查保证。发送AppendEntries RPC时，leader在其日志中加入紧接在新条目之前的条目的索引和term。如果follower找不到相同索引和term的条目，则拒绝新日志条目。</p>
<p>正常情况下，leader和follower保持着一致的日志，但也有可能出现日志不一致的情况，比如旧leader可能不提交日志，如下：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_log_eorr_scenarios.png" alt="img"></p>
<p>为了解决这种情况。raft会让leader通过强制follower的日志复制自己的日志来覆盖处理。</p>
<p>要使得follower的日志与leader保持一致，leader必须找到共同的最新日志条目，在该店之后删除follower日志中的所有条目，然后往follower发送这之后的所有在leader上存在的日志。所有这些操作都是在响应AppendEntries RPC执行的一致性检查时发生的。leader为每个follower维护一个nextIndex，这是leader将发送给follower的下一个日志条目的索引。leader选举出来后，所有的nextIndex会被初始化到其日志中最后一个之后的索引（上图中的11）。如果不一致，RPC将会失败，拒绝后，leader会减少nextIndex，知道RPC成功。</p>
<blockquote>
<p>当然也可以做优化，减少AppendEntries RPC，则follower可以发送冲突条目的term和它为该term存储的第一个索引。这样就是一个term一次RPC。</p>
</blockquote>
<p>该机制使得leader在选举出来后，无需采取额外的操作恢复日志，而是正常运行，并且由于RPC自动收敛日志。Leader Append-Only，leader永远不会覆盖或者删除自己的日志。</p>
<h3 id="Safety"><a href="#Safety" class="headerlink" title="Safety"></a>Safety</h3><p>当leader提交多个日志时，follower可能崩溃了，这时新的leader会用新的日志条目覆盖原来的那些日志，导致不同的状态机可能执行不同的命令序列。</p>
<h4 id="Election-restriction"><a href="#Election-restriction" class="headerlink" title="Election restriction"></a>Election restriction</h4><p>在基于leader的一致性算法中，leader最终会存储所有提交的日志条目，raft通过保证先前term的所有已提交的日志条目从其选举时出现在每个新leader身上，这意味着日志只会从了leader流向follower，leader之间不会覆盖日志。</p>
<p>如果candidate的日志中没有与大多机器的日志保持着最新，raft会使用投票来阻止candidate赢得选举。RequestVote RPC实现了这一限制：RPC包含有关候选人日志的信息，如果其自己的日志比候选者的日志更新，则选民拒绝其投票。</p>
<p>通过比较日志中最后一个条目的索引和术语，Raft确定两个日志中哪一个更新。如果日志包含具有不同term的最后一个条目，则具有较晚term的日志为新的。如果日志以相同的term结束，则索引更大的日志是新的。</p>
<h4 id="Committing-entries-from-previous-terms"><a href="#Committing-entries-from-previous-terms" class="headerlink" title="Committing entries from previous terms"></a>Committing entries from previous terms</h4><p>一个leader不能立马对之前term的log entry是否复制到大多数server来判断其是否已被提交。下图就是这样一个例子：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_log_time_seq.png" alt="img"></p>
<p>在c中，term2的日志已经在大多数server中了，但如果此时leader S1 crash的话，在d这种情况下，term2的日志会被新leader S5给重写。</p>
<p>为了消除这种情况，raft不会通过副本数来commit之前的log entries。只有当前term的log entries才会通过计算副本数被commit。</p>
<h4 id="Safety-argument"><a href="#Safety-argument" class="headerlink" title="Safety argument"></a>Safety argument</h4><p>现在来证明Leader Completeness Property。</p>
<p>假设leader在term T 提交了一个当前term的log entry，但是这个log entry在随后的term没有被leader保存。term U是大于term T的最小的term，并且term U的leader没有包含这个log entry。</p>
<ol>
<li>在选举时leader U的日志中一定没有提交该条目（leader永远不会删除或覆盖条目）</li>
<li>leaderT复制了大多数机器的条目，leaderU从集群的大多数群体中获得了投票。因此，至少一个服务器（“voter”）接受了来自leaderT的条目并投票给了leaderU；这个voter就是矛盾的关键；</li>
<li>voter必须在给leader U投票之前收到了被leader T提交的entry。否则它会拒绝来自leader T的AppendEntries请求，因为它当前的term比T的高；</li>
<li>当voter投票给leader U的时候，它仍然保存着这个entry，这中间的所有leader都会包含了这个条目；</li>
<li>voter将票投给了leader U，所以leader U的log必须和voter至少是一样新的。这就导致了两个矛盾；</li>
</ol>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/raft_leader_completeness.png" alt="img"></p>
<h3 id="Follower-and-candidate-crashes"><a href="#Follower-and-candidate-crashes" class="headerlink" title="Follower and candidate crashes"></a>Follower and candidate crashes</h3><p>相对leader失败，follower和candidate的crash更容易被处理，而且都是通过重试来完成，这是因为raft的RPC都是幂等的。</p>
<h3 id="Timing-and-availability"><a href="#Timing-and-availability" class="headerlink" title="Timing and availability"></a>Timing and availability</h3><p>我们对raft的一个要求是安全性不能取决于时间安排，而可用性(系统及时对客户端作出响应的能力)则必然取决于时间。选举leader就体现了时间的重要性，只要系统满足以下的时间要求，就能保持稳定的leader：<br>$$<br>broadcastTime &lt;&lt; electionTimeout &lt;&lt; MTBF<br>$$</p>
<ul>
<li>broadcastTime：每个服务器发送RPC并接受响应的平均时间；</li>
<li>electionTimeout：选举超时；</li>
<li>MTBF：单个服务器的平均故障间隔时间；</li>
</ul>
<p>broadcastTime和MTBF都是底层系统的属性，而选举超时则是我们设计的。broadcastTime可能在0.5ms到20ms之间，选举超时可能介于10毫秒到500毫秒之间。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/24/The-Design-for-Practical-System-for-FT-Virtual-Machines——MIT6-824/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LucienXian">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/24/The-Design-for-Practical-System-for-FT-Virtual-Machines——MIT6-824/" itemprop="url">The Design  for Practical System for FT Virtual Machines——MIT6.824</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-24T11:16:13+08:00">
                2019-03-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="The-Design-of-a-Practical-System-for-Practical-System-for-Fault-Tolerant-Virtual-Machines"><a href="#The-Design-of-a-Practical-System-for-Practical-System-for-Fault-Tolerant-Virtual-Machines" class="headerlink" title="The Design of a Practical System for Practical System for Fault-Tolerant Virtual Machines"></a>The Design of a Practical System for Practical System for Fault-Tolerant Virtual Machines</h1><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>一个容错虚拟机分布式系统的设计</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>对于分布式系统而言，有很多通用的容错方法：</p>
<ul>
<li>主备服务器：在主服务器挂掉了，由备份服务器接管工作。需要大量带宽在主备间传输状态；</li>
<li>状态机方法：让两台机器初始化为相同状态，然后接受相同的输入，使得两台机器保持同步。保持两台机器同步的额外信息数量远少于改变主服务器的状态量；然而可能存在一些不确定的操作（如读取时钟），因此必须同步这些不确定操作的结果；</li>
</ul>
<p>primary和backup之间传递deterministic operation + non-deterministic operation’s result；</p>
<h2 id="BASIC-FT-DESIGN"><a href="#BASIC-FT-DESIGN" class="headerlink" title="BASIC FT DESIGN"></a>BASIC FT DESIGN</h2><p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/Basic_FT_Conf.png" alt="img"></p>
<p>上图展示了容错虚拟机的基本配置。primary VM和backup VM运行在不同的物理机上，并保持同步（backup会稍有迟延），并且它们使用共享磁盘空间。primary VM将接收到的输入通过Logging channel传送到backup VM。虽然两者都执行相同的输入，但只有primary VM会输出返回给client，因为backup VM会被hypervisor终止掉。backup会通过ack应答来保证没有数据丢失。primary VM和backup VM之间会通过 heartbeat 进行 fail 检测。</p>
<h3 id="Deterministic-Replay-Implementation"><a href="#Deterministic-Replay-Implementation" class="headerlink" title="Deterministic Replay Implementation"></a>Deterministic Replay Implementation</h3><p>正如上文提到过的，让两台机器处于相同的初始状态，然后以相同的顺序提供相同的输入，这样两台机器就能经历相同的状态序列并产生相同的输出。</p>
<p>但由于存在非确定性的事件(虚拟中断)或者操作(读取处理器时钟技术器)，这样会影响VM的状态。</p>
<p>这里的挑战在于：</p>
<ul>
<li>需要捕捉全部的输入和非确定性操作，以此保证backup是确定性；</li>
<li>需要将所有的输入和非确定性操作应用到backup中；</li>
<li>需要保证系统高效；</li>
</ul>
<p>设计方案：将所有的输入和非确定性操作记录到日志文件，并且对于非确定性操作，还必须要把相关的状态信息记录到日志文件中。</p>
<h3 id="FT-Protocol"><a href="#FT-Protocol" class="headerlink" title="FT Protocol"></a>FT Protocol</h3><p>FT协议是用于logging channel的协议</p>
<ul>
<li>输出要求：</li>
</ul>
<blockquote>
<p>如果primary宕机了，backup会接管它的工作，并且backup会执行与primary一致的输出</p>
</blockquote>
<ul>
<li>输出规则：</li>
</ul>
<blockquote>
<p>在backup VM收到并应答所有的日志之前，primary都不会把输出发送给外部</p>
</blockquote>
<p>并且，基于这个输出规则来说，primary VM不会停止执行，它只是延迟发送输出。</p>
<p>FT协议的流程如下图：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/FT_Protocol.png" alt="img"></p>
<p>但这里存在一个小问题，如果 primary 宕机了，backup 不能判断它是在发送了 output 之前还是之后宕机的，因此 backup 会再发送一次 output，但可以通过以下方式解决：</p>
<ul>
<li>诸如TCP等网络协议能够检查丢失或者重复的数据包；</li>
</ul>
<h3 id="Detecting-and-Responding-to-Failure"><a href="#Detecting-and-Responding-to-Failure" class="headerlink" title="Detecting and Responding to Failure"></a>Detecting and Responding to Failure</h3><p>如果是backup宕机，primary会停止发送日志。如果primary宕机，情况复杂一点，backup会接替它的工作，在执行完接收到的日志记录之后，成为primary真正对外输出。</p>
<p>存在一些方法检测宕机，比如通过UDP heartbeat来检测primary与backup之间是否正常通信。另外，还会监控logging channel的日志流量。</p>
<p>但这些方法仍然无法解决split-brain问题，即primary和backup同时宕机。为了解决这个问题，该设计使用了共享存储，提供了一个原子操作test-and-set，primary和backup无法同时在该区域操作。</p>
<h2 id="PRACTICAL-IMPLEMENTATION-OF-FT"><a href="#PRACTICAL-IMPLEMENTATION-OF-FT" class="headerlink" title="PRACTICAL IMPLEMENTATION OF FT"></a>PRACTICAL IMPLEMENTATION OF FT</h2><h3 id="Starting-and-Restarting-FT-VMs"><a href="#Starting-and-Restarting-FT-VMs" class="headerlink" title="Starting and Restarting FT VMs"></a>Starting and Restarting FT VMs</h3><p>在设计系统时，需要考虑如何启动/重启一个与primary状态一致的backup？</p>
<p>VMware VMotion能够使得一个运行中的VM从一个server迁移到另一个server，并且只需要很短的中断。这里做了一些改动，并不是进行迁移，而是在远程主机上克隆一个，并使得源VM进去logging mode，目标VM进入replay mode。</p>
<p>除此之外，由于VM都运行在同一个集群，访问同一个存储区域，因此在选择哪个server作为backup时，是由primary同志集群服务实现的。</p>
<h3 id="Managing-the-Logging-Channel"><a href="#Managing-the-Logging-Channel" class="headerlink" title="Managing the Logging Channel"></a>Managing the Logging Channel</h3><p>存在几种实现方法，管理logging channel的流量。</p>
<p>如下图所示，hypervisor维持了一个很大的log buffer，存着primary和backup的日志。primary往buffer写入日志，而backup则从中读取日志。这两者的操作类似于一个队列，backup遇到的空buffer，影响不大。但如果primary遇到满的buffer，会停止写入并停止对外输出。</p>
<p>因此我们需要一种机制来降低primary的速度，在logging channel增加额外的信息来通知primary，降低server上CPU的使用限制。</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/FT_Logging_Buffer_Channel.png" alt="img"></p>
<h3 id="Operation-on-FT-VMs"><a href="#Operation-on-FT-VMs" class="headerlink" title="Operation on FT VMs"></a>Operation on FT VMs</h3><p>另一个需要关注的实际问题是如何应对primary的多种控制操作。一般来说，大多VM操作只会在primary初始化，然后将必要的信息发送给backup。唯一一个在primary和backup独立的操作是VMotion，请注意，VMware FT确保两个VM都不会移动到另一个VM所在的服务器，因为这种情况不再提供容错功能。</p>
<p>对于primary来说，VMotion会导致backup与primary断开连接，然后重连。</p>
<p>对于backup来说，由于backup同时还在重放primary的操作和完成IO（VMotion需要停顿IO），所以VMotion会比较复杂。VMware的方法是当backup VM位于VMotion的最终切换点时，它通过日志记录通道请求primary VM暂时停顿其所有IO。 然后，backup VM的IO将在单个执行点自然停顿，因为它重放primary VM执行静止操作。</p>
<h3 id="Implementation-Issues-for-Disk-IOs"><a href="#Implementation-Issues-for-Disk-IOs" class="headerlink" title="Implementation Issues for Disk IOs"></a>Implementation Issues for Disk IOs</h3><ul>
<li>磁盘操作是非阻塞的、可以并行操作，这样会导致non-determinism；</li>
</ul>
<p>解决方法：检测IO races，并强制这些操作串行</p>
<ul>
<li>磁盘操作很可能与其它应用或者OS在访问同一块内存时产生竞争，因为磁盘操作是通过DMA实现的，会导致non-determinism；</li>
</ul>
<p>解决方法；设置页保护，但修改MMU的页保护代价太高了。因此这里是用了bounce buffer的设计，这是一块与访问内存等大的buffer。读操作将内存读入buffer，待IO完成了再写回内存；写操作则是将内容写入buffer，稍后写入磁盘。</p>
<ul>
<li>当backup接管失效的primary，成为新的primary后，无法确定磁盘IO是否已经完成；</li>
</ul>
<p>解决方法：发送一个error，表明所有IO都失败了，然后重新执行磁盘IO操作，无论是否已经成功</p>
<h3 id="Implementation-Issues-for-Network-IO"><a href="#Implementation-Issues-for-Network-IO" class="headerlink" title="Implementation Issues for Network IO"></a>Implementation Issues for Network IO</h3><p>系统设计了关于网络的性能优化。</p>
<p>由于这些优化很多都基于异步的执行，而这些操作可能回导致non-determinism，因此一个重要的问题是如何禁止这些异步的网络优化。</p>
<p>我们采取两个办法来提高VM的网络性能：</p>
<ul>
<li>实现集群优化，减少VM的traps和中断；</li>
<li>降低发送packets的延迟，减少发送日志消息和等待ack的时间，方法是避免线程切换；</li>
</ul>
<h2 id="DESIGN-ALTERNATIVES"><a href="#DESIGN-ALTERNATIVES" class="headerlink" title="DESIGN ALTERNATIVES"></a>DESIGN ALTERNATIVES</h2><h3 id="Shared-vs-Non-shared-Disk"><a href="#Shared-vs-Non-shared-Disk" class="headerlink" title="Shared vs Non-shared Disk"></a>Shared vs Non-shared Disk</h3><p>存在一个可替代的设计方法，那就是primary和backup拥有独立的虚拟磁盘(non-shared)，保证磁盘内容的同步，这样disk就变成了VM内部的状态。如下图：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/FT_Non_Shared_Disk_conf.png" alt="img"></p>
<p>这种设计的一大缺点就是为了保证容错，必须要确保虚拟磁盘以某些方法同步。在面对split-brain问题时，需要使用一个第三方服务器（primary和backup都能访问的）</p>
<h3 id="Executing-Disk-Reads-on-the-Backup-VM"><a href="#Executing-Disk-Reads-on-the-Backup-VM" class="headerlink" title="Executing Disk Reads on the Backup VM"></a>Executing Disk Reads on the Backup VM</h3><p>在我们的设计中，磁盘的读入不是直接输入backup的，而是通过logging channel获取相关读取信息的。</p>
<p>这种设计方案可以减少logging channel的流量，但面临更多的小问题：</p>
<ul>
<li>因为backup要执行读取，这样会降低backup VM的执行速度；</li>
<li>要处理好失败的磁盘读取操作，如果backup失败，primary成功，需要重试；如果反过来，primary需要通过logging channel告知backup不需要做备份；</li>
<li>在shared disk的情况下，如果primary在读完磁盘之后想马上执行写入到相同位置，则必须要等待backup也读取完毕；</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/22/Ensemble-Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LucienXian">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/22/Ensemble-Learning/" itemprop="url">Ensemble Learning</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-22T21:38:20+08:00">
                2019-03-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h1><h2 id="个体与集成"><a href="#个体与集成" class="headerlink" title="个体与集成"></a>个体与集成</h2><p>集成学习通过构建并结合多个学习器来完成学习任务，以下图为例，集成学习时先产生一组个体学习器，然后通过某种策略将其结合起来。如果其中的个体学习器是同种类型的，则是同质集成，否则叫异质的，</p>
<p><img src="https://www.researchgate.net/publication/276549421/figure/fig1/AS:339851649011717@1458038355897/Ensemble-learning.png" alt="img"></p>
<p>集成学习的结果是通过投票法产生的，为了使得集成学习的效果比单一学习器更好，应该要保证个体学习器具备一定的准确性，同时要有多样性，则学习器之间具有差异。</p>
<p>假设存在二分类问题和真实函数f，如果基分类器的错误率为$\epsilon$，则对于每个分类器hi有：<br>$$<br>P(h_i(x) \ne f(x)) = \epsilon<br>$$<br>如果基分类器的错误率相互独立，那么集成学习的错误率有：<br>$$<br>P(h_i(x) \ne f(x)) = \sum_{k=0}^{[T/2]} C_T^k (1-\epsilon)^k \epsilon^{T-k} \<br>\leq exp(-1/2T(1-2\epsilon)^2)<br>$$<br>可以看到随着个体学习器数目的增加，集成的错误率降指数下降。</p>
<p>但往往基学习器的误差不是相互独立的，而且一般准确性很高的话，要增加多样性就必须牺牲准确性，</p>
<p>目前集成学习中，个体学习强依赖的代表是Boosting，而非强依赖的代表是Bagging和Random Forest。</p>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>Boosting是将弱学习器提升为强学习器的算法：先从初始训练集中训练出一个基学习器，然后根据该学习器的表现对训练样本的分布进行调整，根据调整后的样本分布来训练下一个基学习器。</p>
<p>Boost的代表是AdaBoost。</p>
<p>AdaBoost有多种推导方式，我们这里采用基学习器的线性组合：<br>$$<br>H(x) = \sum_{t=1}^T\alpha_th_t(x)<br>$$<br>AdaBoost的算法如下：</p>
<p>给定一个训练数据集D={(x1,y1), (x2,y2)…(xN,yN)}，yi属于标记集合{-1,+1}。</p>
<ol>
<li>$D_1(x) = 1/m$，每一个训练样本最开始时都被赋予相同的权值：1/N；</li>
<li>进行多轮迭代，假设迭代T次。for t = 1, 2, .. ,T</li>
</ol>
<ul>
<li>$h_t = \xi(D, D_t);$基于分布$D_t$从数据集中训练出分类器$h_t$；</li>
<li>$\epsilon_{t} = P_{x-D_t}(h_t(x)\ne f(x));$计算分类器的错误率；</li>
<li>如果错误率比随机猜测还要差，那么意味着当前的基学习器不满足基本条件，放弃该学习器；</li>
<li>$\alpha_t = 1/2 ln(\frac{1-\epsilon_t}{\epsilon_t})$；确定该分类器的权重；</li>
<li>$D_{t+1}(x) = \frac{D_t(x) exp(-\alpha_tf(x)h_t(x))}{Z_t}$；更新样本的权重，其中Z是一个规范化因子，以确保$D_{t+1}$是一个分布；每个样本的新权值是变大还是变小，取决于它是被分错还是被分正确；</li>
</ul>
<ol start="3">
<li>输出$H(x)=sign(\sum_{t=1}^T \alpha_th_t(x))$；</li>
</ol>
<p>若H(x)能令指数损失函数最小化，可以求偏导：<br>$$<br>\frac {\alpha l_{exp}(H|D)} {\alpha H(x)} = -e^{-H(x)} P(f(x)=1|x) + e^{H(x)}P(f(x)=-1|x)<br>$$<br>令上式为0，可求解：<br>$$<br>H(x) = 1/2 ln \frac{P(f(x)=1|x)}{P(f(x)=-1|x)}<br>$$<br>依赖这个式子，我们可以求得分类器权重的更新公式。</p>
<p>对于无法重新赋权的训练样本，可以通过重新采样的方法来处理。如上所述，如果初始设置的学习轮数还没到T，可能导致只包含少量基学习器而性能不佳的情况。重采样可以在抛弃不满足基本条件的基学习器之后，根据当前分布重新对样本进行采样，再基于采样结果训练出基学习器，使得学习过程可以在T轮完成。</p>
<p>Boosting主要关注降低偏差，可以基于泛化能力较弱的学习器构建出强的集成。</p>
<h2 id="Bagging与随机森林"><a href="#Bagging与随机森林" class="headerlink" title="Bagging与随机森林"></a>Bagging与随机森林</h2><p>为了得到泛化能力强的集成，集成中的个体学习器应该尽可能独立，一种可能的做法是进行随机取样，根据不同的样本训练得到相对独立的基学习器。但这种做法又可能因为数据量不够而导致学习器的准确性不够高。</p>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p>bagging是一种并行式的集成学习方法。给定m个样本的数据集，我们每次随机从中抽出一个样本放入采样集中，抽出的样本需要重新放回去。经过m次抽取，我们得到一个m个样本的数据集。其中采样集中有可能存在重复的数据。</p>
<p>采样了T个含有m个训练样本的数据集，然后基于每个数据集训练出一个基学习器，然后将这些基学习器进行组合，对于分类任务使用简单投票法，而对于回归任务则是使用简单平均法。</p>
<p>优点：</p>
<ul>
<li>Bagging可以应用于多分类、回归等任务；</li>
<li>由于每个基学习器只用了六成的数据，因此可以用剩下的数据坐泛化能力的”包外预计”；</li>
</ul>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>随机森林是Bagging的一个扩展变形，在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性的选择。</p>
<p>传统决策树在当前节点从d个属性中选择一个最优属性，而在RF中，则是先从该节点的属性集合中随机选择一个包含k个属性的子集，然后再从中选择一个最优属性。</p>
<p>一般情况下，推荐$k=log_2d$。</p>
<p>随机森林的泛化误差比Bagging更小。</p>
<h2 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h2><p>学习器结合的优点：</p>
<ul>
<li>减小因为单学习器可能带来的误选而导致泛化能力不佳的风险；</li>
<li>多次运行进行结合，避免陷入局部最小点；</li>
<li>某些学习任务的真实假设可能并不在单学习器当前学习算法所考虑的假设空间中；</li>
</ul>
<h3 id="平均法"><a href="#平均法" class="headerlink" title="平均法"></a>平均法</h3><p>加权平均法：<br>$$<br>H(x) = \sum_{i=1}^Tw_ih_i(w)<br>$$<br>其中，$w_i \ge 0, \sum_{i=1}^Tw_i=1$；简单平均法，则是令$w_i=1/T$的特例。</p>
<p>一般而言，在个体学习器性能相差较大时宜使用加权平均法，而在个体学习器性能相近时则使用简单平均法。</p>
<h3 id="投票法"><a href="#投票法" class="headerlink" title="投票法"></a>投票法</h3><p>投票法有几种，假设$h_i^j(x)$是分类器$h_i$在类别标记$c_j$上的输出。</p>
<ul>
<li>绝对多数投票法</li>
</ul>
<p>$$<br>H(x)=\left{<br>\begin{array}{rcl}<br>c_j       &amp;      &amp; {if \sum_{i=1}^T h_i^j(x) \ge 0.5\sum_{k=1}^T \sum_{i=1}^T h_i^k(x)}\<br>reject     &amp;      &amp; {otherwise}<br>\end{array} \right.<br>$$</p>
<p>对于可靠性的学习任务中，这个机制提供了拒绝预测的选项</p>
<ul>
<li>相对多数投票法</li>
</ul>
<p>$$<br>H(x) = c_{arg max <em>j } \sum</em>{i=1}^Th_i^j(x)<br>$$</p>
<p>若同时有多个类别获得了最高票，则随机选一个。</p>
<ul>
<li>加权投票法</li>
</ul>
<p>$$<br>H(x) = c_{arg max <em>j } \sum</em>{i=1}^T w_ih_i^j(x)<br>$$</p>
<p>一般情况下，对于不同的学习器可能会产生不同类型的值，比如类标记和类概率。在这种情况下，类概率输出转化为类标记输出（例如将类概率最大的设置为1，其它为0），然后再投票。</p>
<h3 id="学习法"><a href="#学习法" class="headerlink" title="学习法"></a>学习法</h3><p>当训练数据很多时，我们可以使用另一种更为强大的结合策略——通过另一个学习器进行结合。</p>
<p>Stacking是这类策略的代表，其先从初始数据集训练出初级学习器，然后”生成”一个新的数据集用于训练次级学习器。</p>
<p>为了避免过拟合，一般是采用交叉验证的方式，即用训练初级学习器未使用的样本来产生次级学习器的训练样本。以k折交叉验证为例，初始训练集D被随机划分为k个大小相似的集合$D_1,..,D_k$。令$D_j$和$\overline D_j = D-D_j$分别表示在第j折的测试集和训练集。</p>
<p>算法的具体过程如下：</p>
<ul>
<li>给定T个初级学习算法，初级学习器$h_t^{(j)}$通过在$\overline D_j$上使用第t个学习算法而得；</li>
<li>对$D_j$中每个样本$x_i$，计算$z_{it}=h_t^{(j)}(x_i)$，则由样本产生的次级训练样例为$z_i=(z_{i1},…,z_{iT})$，标记部分为$y_i$；</li>
<li>交叉验证结束之后，由初级学习器产生的次级训练集$D’ = {(z_i,y_i)}^m_{i=1}$，并由此训练次级学习器；</li>
</ul>
<p>次级学习器的输入属性表示和次级学习算法对stacking集成的泛化性能由很大的影响。</p>
<h2 id="多样性"><a href="#多样性" class="headerlink" title="多样性"></a>多样性</h2><h3 id="误差——分歧分解"><a href="#误差——分歧分解" class="headerlink" title="误差——分歧分解"></a>误差——分歧分解</h3><p>为了使得泛化能力提高，个体学习器应该”好而不同”。因此我们来做一点理论分析：</p>
<p>假设对于数据x，定义学习器h得分歧为：<br>$$<br>A(h_i|x) = (h_i(x)-H(x))^2\<br>则集成的分歧为：\overline A(h_i|x) = \sum_{i=1}^Tw_i(h_i(x)-H(x))^2<br>$$<br>而个体学习器和集成学习器的平方误差为：<br>$$<br>E(h_i|x) = (f(x)-h_i(x))^2 \<br>\overline E(h|x) = \sum_{i=1}^T w_i E(h_i|x) \<br>E(H|x) = (f(x)-H(x))^2<br>$$<br>则可以根据上式求得：<br>$$<br>\overline A(h|x) = \overline E(h|x) -E(H|x)<br>$$<br>因此可以求得$E = \overline E - \overline A$，即个体学习器准确性越高，多样性越好，则集成效果越好。</p>
<h3 id="多样性度量"><a href="#多样性度量" class="headerlink" title="多样性度量"></a>多样性度量</h3><p>多样性度量其实就是度量集成个体分类器的多样性，比较典型的做法是考虑个体分类器的两两相似/不相似性，以两分类为例：</p>
<table>
<thead>
<tr>
<th></th>
<th>Hi = +1</th>
<th>Hi = -1</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hj = +1</td>
<td>a</td>
<td>c</td>
</tr>
<tr>
<td>Hj = -1</td>
<td>b</td>
<td>d</td>
</tr>
</tbody>
</table>
<p>其中，a表示两个分类器都预测为正类的样本数目，a+b+c+d=m。以下是一些常见的多样性度量：</p>
<ul>
<li>不合度量</li>
</ul>
<p>$$<br>dis_{ij} = \frac{b+c}{m}<br>$$</p>
<ul>
<li>相关系数</li>
</ul>
<p>$$<br>p_{ij} = \frac{ad-bc}{\sqrt{(a+b)(a+c)(c+d)(b+d)}}<br>$$</p>
<p>该系数的值域为[-1,1]，若两分类器无关，则值为0.若为正相关，则值为正，否则为负；</p>
<ul>
<li>Q-统计量</li>
</ul>
<p>$$<br>Q_{ij} = \frac{ad-bc}{ad+bc}<br>$$</p>
<p>其与上面相关系数符号相同；</p>
<ul>
<li>k-统计量</li>
</ul>
<p>$$<br>k = \frac{p1-p2}{1-p2}<br>$$</p>
<p>其中，p1是两个分类器取得一致的概率；p2是两个分类器偶然达成一致的概率：<br>$$<br>p1 = \frac{a+d}{m} \<br>p2 = \frac{(a+b)(a+c)+(c+d)(b+d)}{m^2}<br>$$<br>若分类器在数据集上完全一致，则k=1；若它们仅仅是偶然性达成一致，则k=0；k通常为非负值，仅仅在分类器达成一致的概率比偶然性的情况下还低时取负值。</p>
<h3 id="多样性增强"><a href="#多样性增强" class="headerlink" title="多样性增强"></a>多样性增强</h3><p>要生成多样性大的个体学习器，比较直接的方法是在学习过程引入随机性。</p>
<ul>
<li>数据样本扰动</li>
</ul>
<p>基于采样法，对训练样本稍加变化。但有些稳定学习器对数据样本的扰动并不敏感。</p>
<ul>
<li>输入属性扰动</li>
</ul>
<p>该方法一般是从初始属性集中抽出若干个属性子集，这样做不但能增加多样性，还能减少训练时间。但对于属性较少的样本不适宜。</p>
<ul>
<li>输出表示扰动</li>
</ul>
<p>此类做法的基本思路是对输出表示进行操纵以增强多样性，可以对训练样本的类标记做少许改动，也可以对输出表示进行转化，还可以将原任务拆解成多个子任务。</p>
<ul>
<li>算法参数扰动</li>
</ul>
<p>对基学习算法的一些参数进行设置，比较常见的是神经网络的参数设置。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/18/GFS-MIT6-824/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LucienXian">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/18/GFS-MIT6-824/" itemprop="url">GFS--MIT6.824</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-18T12:03:39+08:00">
                2019-03-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="The-Google-File-System"><a href="#The-Google-File-System" class="headerlink" title="The Google File System"></a><strong>The Google File System</strong></h1><blockquote>
<p><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf" target="_blank" rel="noopener">论文《The Google File System》</a></p>
</blockquote>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>Google File System (GFS)是谷歌提出的一种快速处理数据的文件系统，与传统的分布式文件系统一样，对于性能，可扩展性，可靠性和可用性都有一定的需求。但通过与传统的分布式文件系统相比较，Google认为：</p>
<ul>
<li>组件故障是常态的而非例外；</li>
<li>传统标准意义的文件很大；</li>
<li>大多数文件在发生变更时，是通过添加新的数据，而不是覆盖原有数据；</li>
<li>通过提高我们的灵活性，共同设计应用程序和文件系统API有益于整个系统；</li>
</ul>
<h2 id="DESIGN-OVERVIEW"><a href="#DESIGN-OVERVIEW" class="headerlink" title="DESIGN OVERVIEW"></a>DESIGN OVERVIEW</h2><h3 id="Assumptions"><a href="#Assumptions" class="headerlink" title="Assumptions"></a>Assumptions</h3><p>为了设计符合需求的文件系统，有一些细节需要明确的。</p>
<ul>
<li>该系统的组成部分容易出故障；</li>
<li>系统需存储大量的文件；</li>
<li>在读取时产生workload，主要出现在大型的流式读取和小的随机读取；</li>
<li>在写入时产生workload，主要出现在顺序的追加写入；</li>
<li>系统必须为同时附加到同一文件的多个客户端有效地实现明确定义的语义，需要使用原子写入；</li>
<li>高带宽比低延迟更重要；</li>
</ul>
<h3 id="Interface"><a href="#Interface" class="headerlink" title="Interface"></a>Interface</h3><p>GFS提供了熟悉的文件系统接口，但它没有实现POSIX等标准API。</p>
<p>此外，GFS还实现了快照和记录追加操作，Record append允许多个客户端同时将数据追加到同一文件，同时保证每个客户端追加的原子性。</p>
<h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><p>一个GFS集群包含了一个master服务器和多个被client访问的chunk服务器，每个chunk服务器都是跑着用户级进程的Linux主机。文件被分成固定大小的块存储在chunkserver上，拥有一个唯一的、由master分配的64位ID。为了可靠性，每个chunkserver都做了多重备份，如三备份。</p>
<p>master存储着所有的文件元数据信息，并且与chunkserver通过心跳机制进行沟通。</p>
<p>client和chunkserver都不对文件进行缓存，而是有Linux本身的文件、内存机制进行管理，因为文件太大了。</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/GFS_Architecture.png" alt="img"></p>
<h3 id="Single-Master"><a href="#Single-Master" class="headerlink" title="Single Master"></a>Single Master</h3><p>单个master对于我们的设计非常有帮助，为了不使master成为系统的瓶颈，我们需要减少master的IO。因此client不会直接通过master会读写数据，而是向master发送(file name, chunk index)请求，master返回(chunk handle, chunk locations)，这样client就可以通过这个handle和byte range向最近的chunk server获取数据。</p>
<p>对于相同的chunk的读取，client不会再向master做请求，而是到了cache的信息过期了，或者相关文件重新被打开了，才会去与master交互。</p>
<h3 id="Chunk-Size"><a href="#Chunk-Size" class="headerlink" title="Chunk Size"></a>Chunk Size</h3><p>chunk size是关键的设计参数，在这里选定了64MB大小，比一般的文件系统的block略大。</p>
<p>优点：</p>
<ul>
<li>减少了与master交互，因为只需要一次初始的请求得知chunk的位置即可；</li>
<li>client能对chunk做尽可能多的操作，减少了通过TCP连接时的网络负载；</li>
<li>减少了存在master的元数据信息大小，使得其可以存放在内存；</li>
</ul>
<p>缺点：</p>
<ul>
<li>对于一个小文件，可能只有一个chunk，这很可能因为client都访问同一个文件，造成hot spot的问题；</li>
</ul>
<h3 id="Metedata"><a href="#Metedata" class="headerlink" title="Metedata"></a>Metedata</h3><p>master会保存三种元数据类型：文件和块的命名空间，文件到块的映射，块的位置，所有这些元数据都在master的内存中。</p>
<h4 id="In-Memory-Data-Structures"><a href="#In-Memory-Data-Structures" class="headerlink" title="In-Memory Data Structures"></a><em>In-Memory Data Structures</em></h4><p>把元数据存储在内存中，提高了master的操作速度，并使得master定期扫描元数据状态变得更加方便。另外，虽然这种方式受制于机器内存，但由于每个文件都会有少数的块是部分满的，对于64MB大小的chunk size，我们会采用64个字节去存储元信息。因此可以用来存储这些小于64个字节的元数据信息。除此之外，必要地增加内存也不是很麻烦的事情。</p>
<h4 id="Chunk-Locations"><a href="#Chunk-Locations" class="headerlink" title="Chunk Locations"></a><em>Chunk Locations</em></h4><p>master不会拥有chunkserver中关于某个块位置的持久化记录，而是在启动后定期轮询chunkserver（或者有新的GFS chunkserver加入时），获取该信息。因为GFS chunkserver很容易出现宕机，重启等行为，这样GFS master在每次发生这些事件的时候，都要修改持久化存储里面的位置信息的数据。</p>
<h4 id="Operation-Log"><a href="#Operation-Log" class="headerlink" title="Operation Log"></a><em>Operation Log</em></h4><p>操作日志包含关键元数据更改的历史记录。 它是GFS的核心。它不仅是元数据的唯一持久记录，而且还充当定义并发操作顺序的逻辑时间线。</p>
<p>在存储时，只有当操作日志被写入到本地master和远程时，master才会对client返回成功。并且，为了提高IO吞吐，master会对日志记录进行批处理。</p>
<p>关于操作日志，master只有在操作日志达到一定大小时才会进行checkpoint，并且checkpoint以B树的结构在内存中存在，之后则可以通过加载最新的checkpoint来重放这之后的操作日志。因为build checkpoint需要一定的时间，所以master会新开一个线程做checkpoint，从而避免影响到来的请求。</p>
<h3 id="Consistency-Model"><a href="#Consistency-Model" class="headerlink" title="Consistency Model"></a>Consistency Model</h3><h4 id="Guarantees-by-GFS"><a href="#Guarantees-by-GFS" class="headerlink" title="Guarantees by GFS"></a><em>Guarantees by GFS</em></h4><p>文件命名空间的修改，比如创建文件，都是由master进行的院子操作，master的操作日志定义了一个全局的执行顺序。</p>
<p>数据修改后，文件区域的状态取决于修改类型，如下图：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/GFS_file_region_state_after_mut.png" alt="img"></p>
<ul>
<li>consistent: 所有的client都能看到相同的数据；</li>
<li>defined: 在文件被修改后，该区域时consistent的并且client能够看到其修改了什么；</li>
</ul>
<h4 id="Implications-for-Applications"><a href="#Implications-for-Applications" class="headerlink" title="Implications for Applications"></a><em>Implications for Applications</em></h4><p>事实上，应用在修改文件时往往是追加而不是覆盖，典型的，一个writer创建文件后从头到尾追加。追加文件的操作相对于随机写，其效率更高，并且更容易应对应用失败，只需要使用checkpoint重启增量写即可，还可以避免reader读到不完整的数据。</p>
<p>除此之外，还会经常出现的场景是，多个writers并发地追加到一个文件，以作归并输出。readers通过辨识writer留下的检验信息，可以认出并去除额外的对齐和记录碎片，还可以用唯一的ID去除重复的记录。</p>
<h2 id="SYSTEM-INTERACTIONS"><a href="#SYSTEM-INTERACTIONS" class="headerlink" title="SYSTEM INTERACTIONS"></a>SYSTEM INTERACTIONS</h2><blockquote>
<p>所有的操作都应该尽量减少与master的交互</p>
</blockquote>
<h3 id="Leases-and-Mutation-Order"><a href="#Leases-and-Mutation-Order" class="headerlink" title="Leases and Mutation Order"></a>Leases and Mutation Order</h3><p>由于master对于后续的数据流操作是不作控制的，因此需要一种机制保证，多副本以相同的操作顺序写入。GFS会从chunk选定一个chunk server，发送lease，称作primary。由这个primary chunkServer控制写入的顺序。</p>
<p>lease的初始超时为60秒，这些lease是搭载在HeartBeat信息上的，当master与primary失去连接，也可以在旧lease过期重新选择primary。</p>
<p>下图为该控制流程：</p>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/GFS_F2.png" alt="img"></p>
<ol>
<li>client向master请求当前lease是哪个chunk，和所有的相关副本。如果还没有lease，master则分配一个；</li>
<li>master返回primary的id和其副本的所在位置给client。client会缓存这些信息，只有当无法连上primary或者其不再持有lease，才会重新联系master；</li>
<li>client将这些数据信息推送到所有副本，每个chunkserver都会将数据存放在内部的LRU缓存中；</li>
<li>一旦所有副本都确认收到数据，client会向primary发送写请求，包含之前写的数据的信息。primary会给此次的请求分配一个序列号，保证多客户端并发时能得到唯一的操作顺序；</li>
<li>primary向所有副本转发写请求，副本以primary的序列号去修改数据；</li>
<li>副本写成功后向primary确认；</li>
<li>Primary返回给client。任何副本发生任何错误都会返回给client</li>
</ol>
<h3 id="Data-Flow"><a href="#Data-Flow" class="headerlink" title="Data Flow"></a>Data Flow</h3><p>为了尽可能避免网络瓶颈和链路延迟，每台机器都将数据转发到尚未接收到它的网络拓扑中的“最近”的机器，可以通过IP地址估算距离。</p>
<p>在没有网络拥塞的情况下，将B字节传输到R副本的理想经过时间是<strong>B / T + RL</strong>，其中T是网络吞吐量，L是在两台机器之间传输字节的延迟。</p>
<h3 id="Atomic-Record-Appends"><a href="#Atomic-Record-Appends" class="headerlink" title="Atomic Record Appends"></a>Atomic Record Appends</h3><p>GFS提供了一个名为record append的原子追加操作，客户端仅指定数据，GFS选择偏移量，然后以原子方式将其附加到文件至少一次，并将该偏移量返回给客户端。</p>
<p>记录追加与上面的流程有一个额外的逻辑：客户端将数据推送到文件最后一个块的所有副本之后，将其请求发送给primary。primary检查是否将记录附加到当前块将会导致块的大小超过限制（64 MB）。如果是，会把当前的chunk的剩余空间pad起来，然后告诉其他的副本也这么干，最后告诉client这个chunk满了，写入下个chunk。</p>
<p>如果任何副本上的记录追加失败，则客户端将重试该操作。因此，同一块的副本可能包含不同的数据，但副本必须要与primary对齐，使得下次再追加时，无论哪个副本成为了primary，都能保证所有的操作都从同样的偏移开始追加。</p>
<h3 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h3><p>我们采用写时拷贝的方法来完成快照操作：</p>
<ol>
<li>client向master请求snapshot操作；</li>
<li>master取消该snapshot涉及到的chunk的所有lease；</li>
<li>master将该操作持久化到磁盘；</li>
<li>复制相关chunk的元数据信息到内存中；</li>
</ol>
<p>当client要写入相关snapshot的chunk C时：</p>
<ol>
<li>client向master请求当前的primary；</li>
<li>master注意到该chunk的引用计数大于1，然后推迟回复客户端请求，选择一个新的块句柄C’。然后它要求每个具有C的当前副本的块服务器创建一个名为C’的新块；</li>
<li>master授予其中一个副本在新块C’上的lease并回复客户端；</li>
</ol>
<h2 id="MASTER-OPERATION"><a href="#MASTER-OPERATION" class="headerlink" title="MASTER OPERATION"></a>MASTER OPERATION</h2><blockquote>
<p>The master executes all namespace operations.</p>
</blockquote>
<h3 id="Namespace-Management-and-Locking"><a href="#Namespace-Management-and-Locking" class="headerlink" title="Namespace Management and Locking"></a>Namespace Management and Locking</h3><p>由于很多master操作会花费很多时间，为了避免master阻塞，允许多种master操作同时running，我们使用锁保证序列化。</p>
<p> GFS逻辑上将namespace表示为<strong>完整路径名映射到元数据的查找表</strong>，并且通过前缀压缩保证了其在内存中的使用，namespace树中的每个节点都有一个读写锁。</p>
<p>每个master操作前都会获取一组锁，如果设计了路径<strong>/d1/d2/…/dn/leaf</strong>，那么就会获得一组关于/d1, /d1/d2, …,<br>/d1/d2/…/dn， /d1/d2/…/dn/leaf的锁。</p>
<p>举个例子，当/home/user被快照到/save/user的时候，/home/user/foo的创建是被禁止的。因为快照操作获取/home和/save上的读锁，以及/home/user和/save/user上的写锁。文件创建需要/home和/home/user上的读锁，以及/home/user /foo上的写锁。其中，/home/user的锁产生冲突。</p>
<p>这种方案的一个好处是保障其可以在同一个文件目录并发执行多个文件创建。</p>
<h3 id="Replica-Placement"><a href="#Replica-Placement" class="headerlink" title="Replica Placement"></a>Replica Placement</h3><p>在GFS集群中，通常有数百个chunk server分布在许多rack上。副本的放置策略有两个目的：最大化数据可靠行和可用性，并最大化网络带宽的利用率。我们必须把chunk的副本分发到不同的rack，这样即使整个rack故障了，这些副本仍然可以存活可用。而且这样在读取的时候也可以利用多个rack的聚合带宽。</p>
<h3 id="Creation-Re-replication-Rebalancing"><a href="#Creation-Re-replication-Rebalancing" class="headerlink" title="Creation, Re-replication, Rebalancing"></a>Creation, Re-replication, Rebalancing</h3><blockquote>
<p>Chunk replicas are created for three reasons: chunk creation, re-replication, and rebalancing.</p>
</blockquote>
<ol>
<li>创建chunk</li>
</ol>
<p>当chunk server要创建一个chunk时，会考虑以下几种因素：</p>
<ul>
<li>希望chunk server低于平均磁盘空间利用率；</li>
<li>限制每个chunk server最近创建的数量，因为创建chunk往往意味着后续会有大量写入；</li>
<li>希望在rack上分散chunk的副本；</li>
</ul>
<ol start="2">
<li>重复复制</li>
</ol>
<p>一旦可用副本的数量低于用户指定的目标，主服务器就会重新复制一个数据块。需要重新复制的每个块根据几个因素进行优先级排序，一个是它与复制目标的距离（比如优先复制丢失了更多副本的块），另外就是优先重新复制活动文件的块，而不是属于最近删除的文件的块。最后，为了最大限度地减少故障对运行应用程序的影响，我们提高了阻止客户端进度的任何块的优先级。</p>
<ol start="3">
<li>重新平衡</li>
</ol>
<p>master会定期重新平衡副本，通过检查当前的副本分发并移动副本来获得更好的磁盘空间和负载平衡。同样，对于新加入的的chunk server，master会逐渐填满，而不是用大量的写入流量将其打挂。</p>
<h3 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h3><p>文件会删除后，GFS不会立即GC，而且在常规GC时，也只是做了lazy delete。</p>
<h4 id="Mechanism"><a href="#Mechanism" class="headerlink" title="Mechanism"></a><em>Mechanism</em></h4><p>当应用程序删除文件时，master会立即记录删除，并将文件重命名为包含删除时间戳的隐藏名称。在master定期扫描文件系统的期间，如果发现其存在已经超过一定间隔（三天），它将删除此类隐藏文件。在此之前，我们可以通过重命名的方式取消删除。从命名空间中删除隐藏文件时，将删除其内存中的元数据。在与master定期交换的HeartBeat消息中，每个chunkserver报告它具有的块的子集，并且主服务器回复主服务器元数据中不再存在的所有块的标识。这样chunkserver就可以自由删除了。</p>
<h4 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a><em>Discussion</em></h4><p>这种回收方法有许多优势：</p>
<ul>
<li>不用担心副本删除信息的丢失，因为heartbeat消息携带了相关信息，可以重试；</li>
<li>GC被放在master的后台活动中，和定期命名空间扫描等活动一起，使得cost均摊，master可以更加迅速回应其它紧急请求；</li>
<li>GC的延迟提供了防止意外、不可逆删除的保障；</li>
</ul>
<h3 id="Stale-Replica-Detection"><a href="#Stale-Replica-Detection" class="headerlink" title="Stale Replica Detection"></a>Stale Replica Detection</h3><p>当chunkserver失败并且此时错过了chunk的写入变化时，chunk副本很可能会变得过时。</p>
<p>每当master给chunk授予lease时，它会增加chunk的版本号并作持久化，然后其他副本也会做对应更新，这些操作会在返回给客户端之前完成。当失败的chunkserver重启后，其版本号还是落后的，它会向master汇报版本号和chunk。</p>
<p>master在其常规垃圾回收中会删除过时的副本，并且当有客户端作请求时，它会认为落后副本不存在。</p>
<h2 id="FAULT-TOLERANCE-AND-DIAGNOSIS"><a href="#FAULT-TOLERANCE-AND-DIAGNOSIS" class="headerlink" title="FAULT TOLERANCE AND DIAGNOSIS"></a>FAULT TOLERANCE AND DIAGNOSIS</h2><blockquote>
<p>One of our greatest challenges in designing the system is dealing with frequent component failures.</p>
</blockquote>
<h3 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h3><p>我们通过两种简单而有效的策略保持整个系统的高可用性：快速恢复和复制。</p>
<h4 id="Fast-Recovery"><a href="#Fast-Recovery" class="headerlink" title="Fast Recovery"></a><em>Fast Recovery</em></h4><p>无论是正常终止还是异常终止，master和chunkserver都被设计为可以在几秒内快速恢复。</p>
<h4 id="Chunk-Replication"><a href="#Chunk-Replication" class="headerlink" title="Chunk Replication"></a><em>Chunk Replication</em></h4><p>每个chunk都被复制在不同rack的多个chunkserver上，client可以指定其复制级别（默认为3），master则根据需要克隆现有的副本。</p>
<h4 id="Master-Replication"><a href="#Master-Replication" class="headerlink" title="Master Replication"></a><em>Master Replication</em></h4><p>master的操作日志和checkpoint会在多台计算机上进行复制，只有在其日志记录在本地和所有主副本上刷新到磁盘后，才会认为状态变化已提交。其中，一个master进程仍然在复制所有的修改变化和后台活动。</p>
<p>当master失败时可以立即重启，而当master所在机器故障时，则在其他位置使用复制的操作日志启动新的主进程。</p>
<p>新启动的“shadow” masters只提供读服务，因为可能在挂掉的一瞬间，有些日志记录到primary master上，而没有记录到secondary master上。</p>
<h3 id="Data-Integrity"><a href="#Data-Integrity" class="headerlink" title="Data Integrity"></a>Data Integrity</h3><p>每个chunkserver都使用校验和来检测存储数据是否损坏。</p>
<p>一个chunk被分成64kb大小的块，每个块都有32位的校验和被存在内存和持久化到日志。</p>
<p>对于读取的请求，chunkserver会检查数据块的校验和是否正确，如果checksum不正确，chunkserver会报告给client和master，返回错误，让client从其它副本读取数据。而master会clone一个新副本，当新副本clone好后，master会删除掉这个checksum出错的副本。</p>
<h3 id="Diagnostic-Tools"><a href="#Diagnostic-Tools" class="headerlink" title="Diagnostic Tools"></a>Diagnostic Tools</h3><p>GFS服务器生成诊断日志，记录许多重要事件，比如上下游的chunkservers，RPC的请求和回复。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/27/MapReduce-MIT6-824/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LucienXian">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/27/MapReduce-MIT6-824/" itemprop="url">MapReduce--MIT6.824</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-27T00:38:31+08:00">
                2019-02-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><blockquote>
<p><a href="https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf" target="_blank" rel="noopener">论文《MapReduce: Simplified Data Processing on Large Clusters》</a></p>
</blockquote>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>MapReduce是谷歌提出的一种编程模型，主要目的是为了处理和生成大数据。通过定义map函数来处理key/value对，生成中间键值对，而reduce函数则是用来归并这些中间键值对。</p>
<p>以这种编程模式来实现的程序会自动在大的集群上并行执行。</p>
<h2 id="Programming-Model"><a href="#Programming-Model" class="headerlink" title="Programming Model"></a>Programming Model</h2><p>运算时键值对输入，产生另外的一系列键值对。Map函数是用户编写，输入键值对，产生键值对，将具有相同的中间key的值传到reduce函数。</p>
<p>reduce函数则是接收上面的中间键值对，将那些value合并起来。</p>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>考虑计算文档单词数目的伪代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">map(String key, String value):</span><br><span class="line">    <span class="comment">// key: document name</span></span><br><span class="line">    <span class="comment">// value: document contents</span></span><br><span class="line">    <span class="keyword">for</span> each word w in value:</span><br><span class="line">    	EmitIntermediate(w, <span class="string">"1"</span>);</span><br><span class="line"></span><br><span class="line">reduce(String key, Iterator values):</span><br><span class="line">    <span class="comment">// key: a word</span></span><br><span class="line">    <span class="comment">// values: a list of counts</span></span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> each v in values:</span><br><span class="line">    	result += ParseInt(v);</span><br><span class="line">    Emit(AsString(result));</span><br></pre></td></tr></table></figure>
<h3 id="Types"><a href="#Types" class="headerlink" title="Types"></a>Types</h3><p>map和reduce函数都是有类型的：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">map 	(k1, v1) 		--&gt; list(k2, v2)</span><br><span class="line">reduce	(k2, list(v2))	--&gt; list(v2)</span><br></pre></td></tr></table></figure>
<h3 id="More-Examples"><a href="#More-Examples" class="headerlink" title="More Examples"></a>More Examples</h3><p>一些应用了mapReduce的例子：</p>
<ul>
<li>Distributed Grep</li>
<li>Count of URL Access Frequency</li>
<li>Reverse Web-Link Graph</li>
<li>Term-Vector per Host</li>
<li>Inverted Index</li>
<li>Distributed Sort</li>
</ul>
<h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>论文介绍了谷歌内部的使用。</p>
<h3 id="Execution-Overview"><a href="#Execution-Overview" class="headerlink" title="Execution Overview"></a>Execution Overview</h3><ol>
<li>MapReduce库先将input分成M份(16MB-64MB)，然后启动集群上多个机器上的进程；</li>
<li>其中一个进程是master，其它都是worker；</li>
<li>分配了map任务的worker会读取那M份输入的一份，解析键值对，将其传到自定义的Map函数中，产生的中间键值对将会缓存起来；</li>
<li>缓存的内容会被周期性写入到磁盘上，这里磁盘被分成R个区域。写入后的位置信息将会反馈到maser，master再将位置信息传给reduce的worker；</li>
<li>reduce的worker将会调用RPC去读取缓存，并根据中间结果的key进行排序，使得相同key的键值对分到一个组；</li>
<li>reduce worker将会遍历键值对，然后将key和相关联的values传到自定义的reduce函数里；</li>
<li>当所有任务完成后，master将会从MapReduce中返回；</li>
</ol>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/MapReduceF1.png" alt="img"></p>
<h3 id="Master-Data-Structures"><a href="#Master-Data-Structures" class="headerlink" title="Master Data Structures"></a>Master Data Structures</h3><p>master保存着多种数据结构，比如worker的状态。</p>
<p>另外master还是map任务和reduce任务关于文件位置的沟通渠道。</p>
<h3 id="Fault-Tolerance"><a href="#Fault-Tolerance" class="headerlink" title="Fault Tolerance"></a>Fault Tolerance</h3><h4 id="Worker-Failure"><a href="#Worker-Failure" class="headerlink" title="Worker Failure"></a>Worker Failure</h4><p>master周期性地pingworker，如果没有响应，就认为worker失败了。在失败worker上完成的map任务会设置为idle状态，而还在失败worker上运行的map或者reduce任务都会被设置为idle状态。</p>
<p>完成的map任务此时还需要重新执行，因为中间结果被存在失败机器的磁盘上；而reduce任务不需要重新运行，因为它的输出存储在全局文件系统。另外，所有的reduce任务都应该知晓任务在重新执行，以便读取到正确磁盘上的中间结果。</p>
<h4 id="Master-Failure"><a href="#Master-Failure" class="headerlink" title="Master Failure"></a>Master Failure</h4><p>一般情况下，是将master的数据结构持久化。一旦master任务挂了，就从上次的checkpoint点重新起来。</p>
<h4 id="Semantics-in-the-Presence-of-Failures"><a href="#Semantics-in-the-Presence-of-Failures" class="headerlink" title="Semantics in the Presence of Failures"></a>Semantics in the Presence of Failures</h4><p>当用户的map和reduce函数是确定性的，那么MapReduce产生的结果也是唯一确定的，这是依赖于Map和Reduce任务的原子性提交实现的。</p>
<p>而对于非确定性的Map或者Reduce操作，单个reduce操作的输出对应于整个程序某次序列化输出的结果。</p>
<h3 id="Locality"><a href="#Locality" class="headerlink" title="Locality"></a>Locality</h3><p>由于在计算环境中，网络带宽是很重要的资源，所以谷歌文件系统将输入数据平分，存储到本地磁盘上，而且一般会进行3备份。在运行过程中，MapReduce操作会从本地读取。</p>
<h3 id="Task-Granularity"><a href="#Task-Granularity" class="headerlink" title="Task Granularity"></a>Task Granularity</h3><p>M和R的任务数量应该要比worker机器要多，这样使得worker可以执行多种任务，从而提高负载均衡，也可以在某个worker挂掉的时候快速恢复，因为它已经完成的大量map任务都可以重新分配给其它worker机器上执行。</p>
<p>因为master进行任务分配决策的复杂度是O(M+R)，并且需要在内存中使用O(M*R)大小的空间来保存之前所说的状态。</p>
<h3 id="Backup-Tasks"><a href="#Backup-Tasks" class="headerlink" title="Backup Tasks"></a>Backup Tasks</h3><p>因为某些机器磁盘的故障等原因，MapReduce任务会变得特别慢。这时MapReduce采用的机制就是：</p>
<ul>
<li>在整个计算快要结束时，将一些还在进行的任务进行backup，当backup任务或者源任务其中一个完成时，我们就任务整个计算完成了</li>
</ul>
<h2 id="Refinements"><a href="#Refinements" class="headerlink" title="Refinements"></a>Refinements</h2><h3 id="Partitioning-Function"><a href="#Partitioning-Function" class="headerlink" title="Partitioning Function"></a>Partitioning Function</h3><p>该函数的作用是将中间key结构划分为R部分，默认使用<strong>hash(key) mod R</strong>，但也可以根据需求自定义</p>
<h3 id="Ordering-Guarantees"><a href="#Ordering-Guarantees" class="headerlink" title="Ordering Guarantees"></a>Ordering Guarantees</h3><p>这个函数主要是对中间结果根据key进行排序</p>
<h3 id="Combiner-Funct"><a href="#Combiner-Funct" class="headerlink" title="Combiner Funct"></a>Combiner Funct</h3><p>该函数是在执行map任务的机器上操作的，将一些数据合并起来，然后写到中间结果去。</p>
<h3 id="Input-and-Output-Types"><a href="#Input-and-Output-Types" class="headerlink" title="Input and Output Types"></a>Input and Output Types</h3><p>Mapreduce支持三种文件格式：第一种是逐行读入，key是文件偏移，value是行内容；第二种是key/value读入；第三种是用户自定义reader，可以从文件、数据库或者内存中的数据结构读取。</p>
<h3 id="Side-effects"><a href="#Side-effects" class="headerlink" title="Side-effects"></a>Side-effects</h3><p>MapReduce允许用户生成额外的输出，但其原子性应该由应用本身来实现</p>
<h3 id="Skipping-Bad-Records"><a href="#Skipping-Bad-Records" class="headerlink" title="Skipping Bad Records"></a>Skipping Bad Records</h3><p>对于一些不好修复的bug，或者确定性的错误。worker通过一个信号处理器来捕获错误，然后在执行Map或者Reduce操作前，MapReduce会存储一个全局序列号，一旦发现了用户代码的错误，信号处理器就会发一个内含序列号的UDP包给master，如果master发现了特定记录有了多次的失败，就会指示该记录应该跳过，不再重试。</p>
<h3 id="Local-Execution"><a href="#Local-Execution" class="headerlink" title="Local Execution"></a>Local Execution</h3><p>因为分布式环境调试不方便，MapReduce提供在本机串行化执行MapReduce的接口，方便用户调试。</p>
<h3 id="Status-Information"><a href="#Status-Information" class="headerlink" title="Status Information"></a>Status Information</h3><p>master把内部的状态通过网页的方式展示出来</p>
<h3 id="Counters"><a href="#Counters" class="headerlink" title="Counters"></a>Counters</h3><p>MapReduce提供一个计数器来计算各种时间的发生频率。例如这样：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Counter* uppercase;</span><br><span class="line">uppercase = GetCounter(<span class="string">"uppercase"</span>);</span><br><span class="line"></span><br><span class="line">map(String name, String contents):</span><br><span class="line">	<span class="keyword">for</span> each word w in contents:</span><br><span class="line">		<span class="keyword">if</span> (IsCapitalized(w)):</span><br><span class="line">			uppercase-&gt;Increment();</span><br><span class="line">		EmitIntermediate(w, <span class="string">"1"</span>);</span><br></pre></td></tr></table></figure>
<p>计数器的值会周期性传达给master。当MapReduce操作完成时，count值会返回给用户程序，需要注意的是，重复执行的任务的count只会统计一次。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/26/列表优先于数组/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LucienXian">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/26/列表优先于数组/" itemprop="url">列表优先于数组</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-26T18:36:37+08:00">
                2019-02-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="列表优先于数组"><a href="#列表优先于数组" class="headerlink" title="列表优先于数组"></a>列表优先于数组</h1><h2 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h2><ol>
<li>数组和泛型的不同首先体现在数组是covariant的，所以如果Sub是Super的一个子类型，那么数组类型Sub[]也是数组类型Super[]的子类型。相反，泛型列表对此则有限制。这意味着：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Object[] objectArray = <span class="keyword">new</span> Long[<span class="number">1</span>];</span><br><span class="line">objectArray[<span class="number">0</span>] = <span class="string">"I don't fit in"</span>; <span class="comment">//在运行时会报错</span></span><br></pre></td></tr></table></figure>
<p>但如果使用列表：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Object&gt; ol = <span class="keyword">new</span> ArrayList&lt;Long&gt;(); <span class="comment">// Incompatible types</span></span><br><span class="line">ol.add(<span class="string">"I don't fit in"</span>);</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>数组是具化的，数组只有在运行时才能直到并检查元素类型，而泛型是通过擦除来实现的，这意味着泛型只在编译时进行类型约束的检查，而运行时是忽略元素类型的。因此无法混合使用数组和泛型，以下的操作都是不合法的：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> List&lt;E&gt;[], <span class="keyword">new</span> List&lt;String&gt;[], <span class="keyword">new</span> E[]</span><br></pre></td></tr></table></figure>
<h2 id="优先使用列表"><a href="#优先使用列表" class="headerlink" title="优先使用列表"></a>优先使用列表</h2><p>当你强转成数组类型时，若得到一个泛型数组创建错误或者未检查强转警告，最好的解决办法是，总是优先采用集合类型List\<e>，而不是数组类型E[]。</e></p>
<p>考虑这样一个类，构造器接受一个集合：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Chooser</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Object[] choiceArray;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Chooser</span><span class="params">(Collection choices)</span> </span>&#123;</span><br><span class="line">        choiceArray = choices.toArray();</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">choose</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Random rnd = ThreadLocalRandom.current();</span><br><span class="line">        <span class="keyword">return</span> choiceArray[rnd.nextInt(choiceArray.length)];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么在使用时，我们每次都要在调用choose方法之后，将Object类型转换为需要的类型，有可能强转失败，如果我们使用泛型：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Chooser</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> T[] choiceArray;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Chooser</span><span class="params">(Collection&lt;T&gt; choices)</span> </span>&#123;</span><br><span class="line">        choiceArray = choices.toArray();</span><br><span class="line">    &#125;<span class="comment">// choose method unchanged</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样会编译报错，除非我们强制换位Object数组：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">choiceArray = (T[]) choices.toArray();</span><br></pre></td></tr></table></figure>
<p>这样只会产生一个警告，因为编译器无法保证运行时强转的安全性。当然，我们可以消除warning，但最佳的做法还是使用泛型列表：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Chooser</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;T&gt; choiceList;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Chooser</span><span class="params">(Collection&lt;T&gt; choices)</span> </span>&#123; </span><br><span class="line">        choiceList = <span class="keyword">new</span> ArrayList&lt;&gt;(choices);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">choose</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Random rnd = ThreadLocalRandom.current();</span><br><span class="line">        <span class="keyword">return</span> choiceList.get(rnd.nextInt(choiceList.size()));</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/18/深度学习中的正则化-一-——DeepLearning系列/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LucienXian">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LucienXian's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/18/深度学习中的正则化-一-——DeepLearning系列/" itemprop="url">深度学习中的正则化<一>——DeepLearning系列</一></a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-18T00:23:19+08:00">
                2019-02-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="深度学习中的正则化-lt-一-gt"><a href="#深度学习中的正则化-lt-一-gt" class="headerlink" title="深度学习中的正则化&lt;一&gt;"></a>深度学习中的正则化&lt;一&gt;</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>深度学习的一个核心问题就是提高模型的泛化性，即不仅仅要在训练数据上表现好，还能在新输入上有更好的泛化，这些策略就是正则化。</p>
<p>首先来理解偏差和方差的含义：</p>
<ul>
<li>方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。</li>
<li>偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力</li>
</ul>
<p><img src="https://lucienxian-blog-666-1258586914.cos.ap-shanghai.myqcloud.com/var_bias_dl.png" alt="img"></p>
<p>在一些过拟合的场景下，正则化会以偏差的增加来换取方差的减少。</p>
<h2 id="参数范数惩罚"><a href="#参数范数惩罚" class="headerlink" title="参数范数惩罚"></a>参数范数惩罚</h2><p>许多正则化方法会对目标函数J增加一个参数范数惩罚$\Omega(\theta)$，限制模型的学习能力，目标函数变为：<br>$$<br>J’(\theta, X, y) = J(\theta, X, y) + \alpha \Omega(\theta)<br>$$<br>$\alpha$越大，对应的正则化惩罚就越大。当我们的训练算法最小化正则化后的目标函数J时，它会降低原始目标J关于<br>训练数据的误差并同时减小在某些衡量标准下参数θ(或参数子集)的规模。</p>
<p>一般情况下，在神经网络中我们只对权重做惩罚而不对偏置做惩罚。精确拟合偏置所需要的数据比拟合权重少，我们不对其进行正则化也不会导致太大的方差，而且正则化偏置参数可能会导致明显的欠拟合。</p>
<h3 id="L2参数正则化"><a href="#L2参数正则化" class="headerlink" title="L2参数正则化"></a>L2参数正则化</h3><p>$L^2$参数范数惩罚是最简单最常见的正则化方式，这个策略添加了一个正则项（权值向量w中各个元素的平方和），使得权重更加接近原点。这个目标函数就变成了：<br>$$<br>J’(w, X, y)=\frac{\alpha}{2}w^Tw+J(w, X, y)<br>$$<br>与之对应的梯度为：<br>$$<br>\nabla_wJ’(w, X, y) = \alpha w+\nabla_wJ(w, X, y)<br>$$<br>那么更新权重的方式也会发生变化：<br>$$<br>w = w-\epsilon(\alpha w+\nabla_wJ(w, X, y)) = (1-\epsilon \alpha)w-\epsilon \nabla_wJ(w, X, y)<br>$$<br>我们可以看到每步更新执行时都会先收缩权重向量。</p>
<p>我们进一步分析整个训练过程中会发生什么，令w<em>为未正则化的目标函数取得最小训练误差时的权重向量，那么近似的误差函数就是：<br>$$<br>J’(\theta) = J(w^</em>) + \frac{1}{2}(w-w^<em>)^TH(w-w^</em>)<br>$$<br>其中H是J在w<em>处计算的Hessian矩阵，当$J’$取得最小时，其梯度为：<br>$$<br>\nabla_wJ’(w) = H(w-w^</em>) = 0<br>$$<br>然后我们添加上权重衰减的梯度，其中w是此时的最优点：<br>$$<br>\alpha w+H(w-w^*) = 0<br>$$</p>
<p>$$<br>w = (H+\alpha I)^{-1}Hw^*<br>$$</p>
<p>可以看到当$\alpha$趋向于0的时候，正则化的解w会趋向$w^*$。那么当$\alpha$增加时，在显著减小目标函数方向上的参数会保留得相对完好，而在无助于目标函数减小的方向(对应 Hessian 矩阵较小的特征值)上改变参数不会显著增加梯度，这种不重要方向对应的分量会在训练过程中因正则化而衰减掉。</p>
<p>简单来说，L2正则化能让学习算法对与具有较高方差的输入x更加敏感，使得与输出目标的协方差较小的特征的权重收缩，</p>
<h3 id="L1参数正则化"><a href="#L1参数正则化" class="headerlink" title="L1参数正则化"></a>L1参数正则化</h3><p>L1正则化则是添加一个另外的正则化项（权值向量w中各个元素的绝对值之和）：<br>$$<br>J’(w, X, y)=\alpha||w||_1+J(w, X, y)<br>$$<br>对应的梯度为：<br>$$<br>\nabla_wJ’(w, X, y) = \alpha sign(w)+\nabla_wJ(w, X, y)<br>$$<br>其中sign(w)只是简单地取w各个元素的正负号，其中若w&gt;0，则sign(w)=1；若w&lt;0，则sign(w)=−1；若w=0，则sign(w)=0。</p>
<p>相比L2正则化，L1正则化会产生更加稀疏的解，这里的稀疏指的是最优值中的一些参数为0。由L1正则化导出的稀疏性质被广泛用于特征选择机制，从可用的特征子集中选择出有意义的特征。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="LucienXian">
          <p class="site-author-name" itemprop="name">LucienXian</p>
           
              <p class="site-description motion-element" itemprop="description">LucienXian's Garden</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">211</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">25</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/LucienXian" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/feng-shao-37-35/activities" target="_blank" title="Zhihu">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                    
                      Zhihu
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LucienXian</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
