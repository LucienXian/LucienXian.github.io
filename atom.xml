<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LucienXian&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-08-01T16:00:48.243Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>LucienXian</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>RocksDB源码学习一</title>
    <link href="http://yoursite.com/2021/08/01/Rocksdb%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E4%B8%80/"/>
    <id>http://yoursite.com/2021/08/01/Rocksdb源码学习一/</id>
    <published>2021-08-01T15:59:54.000Z</published>
    <updated>2021-08-01T16:00:48.243Z</updated>
    
    <content type="html"><![CDATA[<h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><p>第一章先来看一下Rocksdb的编码情况，具体的实现在：<code>util/coding.cc, util/coding.h, util/coding_lean.h</code>。Rocksdb的编码实现与leveldb基本一致的，由于需要将Key、Value等数据按序写入到内存中，并最终flush到磁盘上，因此需要一个高效的编解码实现。这里的编解码很多会用在key size、value size的整型编码上面。</p><p>Rocksdb的整型编码方式很简单，主要支持两种方案：定长编码和变长编码。</p><ul><li>定长编码：定长编码的实现比较简单，比如可以直接将4字节/8字节的整型直接按序写入到指定的位置；</li><li>变长编码：节省空间，如果用定长编码的方式，实际上对于小数来说，很多位其实是没必要存储。结合ASCII码的特点，所有字符ASCII码的最高位都是0，可以利用最高位去做一些特别的标记；</li></ul><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><h4 id="字节端序"><a href="#字节端序" class="headerlink" title="字节端序"></a>字节端序</h4><p>关于编码，首先需要了解计算机在存储字节时分为大端字节序和小端字节序两种，Rocksdb是用小端序存储（低位放在较小的地址处，高位放在较大的地址处）的，因此需要提供根据不同平台对内存存储模型进行转换的选项。</p><p>在port/port.h文件内包含了一些平台相关的的头文件：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(ROCKSDB_PLATFORM_POSIX)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"port/port_posix.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(OS_WIN)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"port/win/port_win.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>以<code>port_posix.h</code>为例，这里包含了posix平台关于大小端的定义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> PLATFORM_IS_LITTLE_ENDIAN</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(OS_MACOSX)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;machine/endian.h&gt;</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">if</span> defined(__DARWIN_LITTLE_ENDIAN) &amp;&amp; defined(__DARWIN_BYTE_ORDER)</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">define</span> PLATFORM_IS_LITTLE_ENDIAN \</span></span><br><span class="line">        (__DARWIN_BYTE_ORDER == __DARWIN_LITTLE_ENDIAN)</span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(OS_SOLARIS)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/isa_defs.h&gt;</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">ifdef</span> _LITTLE_ENDIAN</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">define</span> PLATFORM_IS_LITTLE_ENDIAN true</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">define</span> PLATFORM_IS_LITTLE_ENDIAN false</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;alloca.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(OS_AIX)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;arpa/nameser_compat.h&gt;</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> PLATFORM_IS_LITTLE_ENDIAN (BYTE_ORDER == LITTLE_ENDIAN)</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;alloca.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(OS_FREEBSD) || defined(OS_OPENBSD) || defined(OS_NETBSD) || \</span></span><br><span class="line">    defined(OS_DRAGONFLYBSD) || defined(OS_ANDROID)</span><br><span class="line">  <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/endian.h&gt;</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> PLATFORM_IS_LITTLE_ENDIAN (_BYTE_ORDER == _LITTLE_ENDIAN)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;endian.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">constexpr</span> <span class="keyword">bool</span> kLittleEndian = PLATFORM_IS_LITTLE_ENDIAN;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> PLATFORM_IS_LITTLE_ENDIAN</span></span><br></pre></td></tr></table></figure><h4 id="定长编码"><a href="#定长编码" class="headerlink" title="定长编码"></a>定长编码</h4><p>定长编码比较简单，首先判断大小端序，对于小端，value本身就是按小端排放的，可以直接拷贝；对于大端，则是将value的最低位放置在内存的最低地址端。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">EncodeFixed32</span><span class="params">(<span class="keyword">char</span>* buf, <span class="keyword">uint32_t</span> value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (port::kLittleEndian) &#123;</span><br><span class="line">    <span class="built_in">memcpy</span>(buf, &amp;value, <span class="keyword">sizeof</span>(value));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    buf[<span class="number">0</span>] = value &amp; <span class="number">0xff</span>;</span><br><span class="line">    buf[<span class="number">1</span>] = (value &gt;&gt; <span class="number">8</span>) &amp; <span class="number">0xff</span>;</span><br><span class="line">    buf[<span class="number">2</span>] = (value &gt;&gt; <span class="number">16</span>) &amp; <span class="number">0xff</span>;</span><br><span class="line">    buf[<span class="number">3</span>] = (value &gt;&gt; <span class="number">24</span>) &amp; <span class="number">0xff</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解码也一样，Rocksdb提供了三种整型编解码：<code>uint16_t,uint32_t,uint64_t</code>。解码时，gcc会优化里面的memcpy的操作，变成inline copy loops，提高效率。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> uint32_t <span class="title">DecodeFixed32</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* ptr)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (port::kLittleEndian) &#123;</span><br><span class="line">    <span class="comment">// Load the raw bytes</span></span><br><span class="line">    <span class="keyword">uint32_t</span> result;</span><br><span class="line">    <span class="built_in">memcpy</span>(&amp;result, ptr, <span class="keyword">sizeof</span>(result));  <span class="comment">// gcc optimizes this to a plain load</span></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> ((<span class="keyword">static_cast</span>&lt;<span class="keyword">uint32_t</span>&gt;(<span class="keyword">static_cast</span>&lt;<span class="keyword">unsigned</span> <span class="keyword">char</span>&gt;(ptr[<span class="number">0</span>]))) |</span><br><span class="line">            (<span class="keyword">static_cast</span>&lt;<span class="keyword">uint32_t</span>&gt;(<span class="keyword">static_cast</span>&lt;<span class="keyword">unsigned</span> <span class="keyword">char</span>&gt;(ptr[<span class="number">1</span>])) &lt;&lt; <span class="number">8</span>) |</span><br><span class="line">            (<span class="keyword">static_cast</span>&lt;<span class="keyword">uint32_t</span>&gt;(<span class="keyword">static_cast</span>&lt;<span class="keyword">unsigned</span> <span class="keyword">char</span>&gt;(ptr[<span class="number">2</span>])) &lt;&lt; <span class="number">16</span>) |</span><br><span class="line">            (<span class="keyword">static_cast</span>&lt;<span class="keyword">uint32_t</span>&gt;(<span class="keyword">static_cast</span>&lt;<span class="keyword">unsigned</span> <span class="keyword">char</span>&gt;(ptr[<span class="number">3</span>])) &lt;&lt; <span class="number">24</span>));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="变长编码"><a href="#变长编码" class="headerlink" title="变长编码"></a>变长编码</h4><p>前面提到的，为了节省空间，Rocksdb使用变长的编码方式<em>varint</em>。Rocksdb使用最高位来表示编码是否结束，而低7bit则存储实际的数据。根据统计来说，小整型出现的概率更高，这样就能节省更多的空间，比如0-127的整数都可以只用一个字节来表示，而uint32较大的数字则需要5个字节。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">0001 0001 ====&gt;&gt; 表示33</span><br><span class="line">^                           A: 最高位为0，表示结束；</span><br><span class="line">A</span><br><span class="line">=======================================================</span><br><span class="line">1000 0011 0110 1111 ====&gt;&gt; 表示1007</span><br><span class="line">^         ^                 A: 最高位为1，表示未结束，实际值是000 0011；</span><br><span class="line">A         B                 B: 最高位为0，表示结束，实际值是110 1111；</span><br></pre></td></tr></table></figure><p>具体的编码以<code>uint32_t</code>为例，将<code>uint32_t</code>编码成变长字符：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">char</span>* <span class="title">EncodeVarint32</span><span class="params">(<span class="keyword">char</span>* dst, <span class="keyword">uint32_t</span> v)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Operate on characters as unsigneds</span></span><br><span class="line">  <span class="keyword">unsigned</span> <span class="keyword">char</span>* ptr = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">unsigned</span> <span class="keyword">char</span>*&gt;(dst);</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">int</span> B = <span class="number">128</span>;</span><br><span class="line">  <span class="keyword">if</span> (v &lt; (<span class="number">1</span> &lt;&lt; <span class="number">7</span>)) &#123;</span><br><span class="line">    *(ptr++) = v;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v &lt; (<span class="number">1</span> &lt;&lt; <span class="number">14</span>)) &#123;</span><br><span class="line">    *(ptr++) = v | B;</span><br><span class="line">    *(ptr++) = v &gt;&gt; <span class="number">7</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v &lt; (<span class="number">1</span> &lt;&lt; <span class="number">21</span>)) &#123;</span><br><span class="line">    *(ptr++) = v | B;</span><br><span class="line">    *(ptr++) = (v &gt;&gt; <span class="number">7</span>) | B;</span><br><span class="line">    *(ptr++) = v &gt;&gt; <span class="number">14</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v &lt; (<span class="number">1</span> &lt;&lt; <span class="number">28</span>)) &#123;</span><br><span class="line">    *(ptr++) = v | B;</span><br><span class="line">    *(ptr++) = (v &gt;&gt; <span class="number">7</span>) | B;</span><br><span class="line">    *(ptr++) = (v &gt;&gt; <span class="number">14</span>) | B;</span><br><span class="line">    *(ptr++) = v &gt;&gt; <span class="number">21</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    *(ptr++) = v | B;</span><br><span class="line">    *(ptr++) = (v &gt;&gt; <span class="number">7</span>) | B;</span><br><span class="line">    *(ptr++) = (v &gt;&gt; <span class="number">14</span>) | B;</span><br><span class="line">    *(ptr++) = (v &gt;&gt; <span class="number">21</span>) | B;</span><br><span class="line">    *(ptr++) = v &gt;&gt; <span class="number">28</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">char</span>*&gt;(ptr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>uint64_t</code>的变长编码实现，作者用了循环来编码，每7bit一组，并在最低位判断是否需要置位1。因此对于64位整型，最多需要10个字节：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">char</span>* <span class="title">EncodeVarint64</span><span class="params">(<span class="keyword">char</span>* dst, <span class="keyword">uint64_t</span> v)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> B = <span class="number">128</span>;</span><br><span class="line">  <span class="keyword">unsigned</span> <span class="keyword">char</span>* ptr = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">unsigned</span> <span class="keyword">char</span>*&gt;(dst);</span><br><span class="line">  <span class="keyword">while</span> (v &gt;= B) &#123;</span><br><span class="line">    *(ptr++) = (v &amp; (B - <span class="number">1</span>)) | B; <span class="comment">// leveldb的实现是v | B; 不明白区别在哪</span></span><br><span class="line">    v &gt;&gt;= <span class="number">7</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  *(ptr++) = <span class="keyword">static_cast</span>&lt;<span class="keyword">unsigned</span> <span class="keyword">char</span>&gt;(v);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">char</span>*&gt;(ptr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解码的实现也有一些优化，主要是利用内联函数提高效率，当数字小于等于127时，直接返回结果：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">const</span> <span class="keyword">char</span>* <span class="title">GetVarint32Ptr</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* p,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  <span class="keyword">const</span> <span class="keyword">char</span>* limit,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  <span class="keyword">uint32_t</span>* value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (p &lt; limit) &#123;</span><br><span class="line">    <span class="keyword">uint32_t</span> result = *(<span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">char</span>*&gt;(p));</span><br><span class="line">    <span class="keyword">if</span> ((result &amp; <span class="number">128</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">      *value = result;</span><br><span class="line">      <span class="keyword">return</span> p + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> GetVarint32PtrFallback(p, limit, value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">const</span> <span class="keyword">char</span>* <span class="title">GetVarint32PtrFallback</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* p, <span class="keyword">const</span> <span class="keyword">char</span>* limit,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   <span class="keyword">uint32_t</span>* value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">uint32_t</span> result = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">uint32_t</span> shift = <span class="number">0</span>; shift &lt;= <span class="number">28</span> &amp;&amp; p &lt; limit; shift += <span class="number">7</span>) &#123;</span><br><span class="line">    <span class="keyword">uint32_t</span> byte = *(<span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">char</span>*&gt;(p));</span><br><span class="line">    p++;</span><br><span class="line">    <span class="keyword">if</span> (byte &amp; <span class="number">128</span>) &#123;</span><br><span class="line">      <span class="comment">// More bytes are present</span></span><br><span class="line">      result |= ((byte &amp; <span class="number">127</span>) &lt;&lt; shift);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      result |= (byte &lt;&lt; shift);</span><br><span class="line">      *value = result;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">const</span> <span class="keyword">char</span>*&gt;(p);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>编解码这里还是比较简单和高效的，比较有意思的是实现了一个variant编码，源码值得一看。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;编码&quot;&gt;&lt;a href=&quot;#编码&quot; class=&quot;headerlink&quot; title=&quot;编码&quot;&gt;&lt;/a&gt;编码&lt;/h2&gt;&lt;p&gt;第一章先来看一下Rocksdb的编码情况，具体的实现在：&lt;code&gt;util/coding.cc, util/coding.h, util/
      
    
    </summary>
    
    
      <category term="RocksDB" scheme="http://yoursite.com/tags/RocksDB/"/>
    
  </entry>
  
  <entry>
    <title>Dynamo: Amazon’s Highly Available Key-value Store</title>
    <link href="http://yoursite.com/2021/07/26/Dynamo-Amazon%E2%80%99s-Highly-Available-Key-value-Store/"/>
    <id>http://yoursite.com/2021/07/26/Dynamo-Amazon’s-Highly-Available-Key-value-Store/</id>
    <published>2021-07-25T16:10:16.000Z</published>
    <updated>2021-07-25T16:10:53.243Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Dynamo"><a href="#Dynamo" class="headerlink" title="Dynamo"></a>Dynamo</h1><blockquote><p>原文是2007年SOSP上Amazon发布的分布式存储经典论文<a href="https://sites.cs.ucsb.edu/~agrawal/fall2009/dynamo.pdf" target="_blank" rel="noopener">《<strong>Dynamo: Amazon’s Highly Available Key-value Store</strong>》</a>。这是一个高可用的分布式KV存储——Dynamo，Amazon的一些核心服务就是依赖Dynamo提供持续可用的服务，为了达到这种可用级别，Dynamo牺牲了几种特定场景下的一致性。并且，Dynamo大量地使用了对象版本化和应用层面的冲突解决机制。</p></blockquote><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>支撑着Amazon电商发展的是建立在分布于全球数据中心成千上万的服务器基础上的，因此对性能、可靠性和效率都有很高的要求。同时为了支撑业务的持续增长和避免因故障导致的经济损失，平台需要有足够好的可扩展性、可靠性。</p><p>Amazon使用的是去中心化的、松耦合的、面向服务的架构，这种服务架构对持续可用的存储技术有着强烈的诉求。例如，即便是磁盘故障、路由抖动、数据中心被摧毁，用户仍然能够向购物车添加和查看商品。因此Amazon推出了一款高可用的kv存储组件——Dynamo。Dynamo用于管理对可靠性要求非常高的服务，这些服务还要求对一致性、成本效率和性能有很强的控制能力。</p><p>Dynamo使用了一些常见的技术来实现了可扩展性和高可用性：</p><ul><li>数据通过一致性哈希来分区和复制；</li><li>通过对象版本化来实现一致性；</li><li>副本之间的一致性使用了类似quorum的技术和一个去中心化的副本同步协议；</li><li>gossip-based分布式故障检测和成员检测协议；</li></ul><p>Dynamo是一个极少需要人工管理的、完全去中心化的系统，向Dynamo添加或者删除节点不需要人工调整哈希节点和重分布节点间数据。</p><h2 id="BACKGROUND"><a href="#BACKGROUND" class="headerlink" title="BACKGROUND"></a>BACKGROUND</h2><p>传统上生产系统会使用关系型数据库来存储状态，但这并不是一种理想的方式，大多数服务并不需要RDBMS提供的复杂查询和管理功能，这些额外的支持带来的硬件成本并不经济，并且这类数据库的复制功能有局限，往往是通过牺牲可用性来换取一致性。</p><h3 id="System-Assumptions-and-Requirements"><a href="#System-Assumptions-and-Requirements" class="headerlink" title="System Assumptions and Requirements"></a>System Assumptions and Requirements</h3><p>Dynamo对于使用它的服务有几点假设：</p><ul><li>Query Model：通过唯一的key对数据进行读写，存储状态是binary objects。没有relational schema需求，无跨data items的操作。存储对象较小，往往小于1MB；</li><li>ACID Properties：Dynamo的设计目标是使用部分一致性来换取更高的可用性；</li><li>Efficiency：存储系统必须满足那些严格的SLA；</li><li>Other Assumptions：内部使用，假设环境足够安全；</li></ul><h3 id="Service-Level-Agreements-SLA"><a href="#Service-Level-Agreements-SLA" class="headerlink" title="Service Level Agreements (SLA)"></a>Service Level Agreements (SLA)</h3><p>在Amazon去中心化的基础设施中，SLA会扮演着重要的角色，客户端和服务端会定义一个 SLA协议。Amazon不是使用传统的平均值、中位数和方差来描述面向性能的SLA，而是更多使用了P99.9分布，来确定性能的长尾结果。</p><h3 id="Design-Considerations"><a href="#Design-Considerations" class="headerlink" title="Design Considerations"></a>Design Considerations</h3><p>前面提过，很多系统中数据复制算法一般是同步的，为了提供一个强一致性的数据访问结果，往往会牺牲掉某些场景下的可用性。考虑到这一点，Dynamo最终被设计为最终一致的数据存储系统。</p><p>在分布式系统中，需要关注的是机器或者网络故障时可能会导致数据冲突，需要检测和解决冲突。一些传统的数据库可能会在写的时候解决冲突，牺牲一点可用性。但Dynamo的目标是提供一个持续可写的存储，因此将解决冲突的逻辑放到了读操作，从而避免写操作被拒绝。同时Dynamo可以配置是存储系统来解决冲突还是应用选择自行实现冲突解决操作。</p><h2 id="SYSTEM-ARCHITECTURE"><a href="#SYSTEM-ARCHITECTURE" class="headerlink" title="SYSTEM ARCHITECTURE"></a>SYSTEM ARCHITECTURE</h2><p>本文主要介绍了Dynamo用到的部分分布式系统技术：包括partitioning, replication, versioning, membership, failure handling 和 scaling。</p><h3 id="System-Interface"><a href="#System-Interface" class="headerlink" title="System Interface"></a>System Interface</h3><p>Dynamo的存储接口非常简单，只有两个：</p><ul><li>get()：会返回存储key对应的所有对象副本，以及一个context；</li><li>put()：确定对象的存储位置，写入到相应的磁盘。</li></ul><p>Dynamo将调用方提供的key和对象都视作是opaque array of bytes，其对key应用MD5哈希得到一个128bit的ID，并根据ID计算应该存储到哪个存储节点。</p><h3 id="Partitioning-Algorithm"><a href="#Partitioning-Algorithm" class="headerlink" title="Partitioning Algorithm"></a>Partitioning Algorithm</h3><p>Dynamo的设计有一个核心诉求：支持增量扩展。这就要求有一种机制能够将数据分散到系统的不同节点中，Dynamo的方案是基于一致性哈希，其哈希函数的输出是一个固定范围，作为一个循环空间环，每个节点会随机分配一个循环空间内的值，代表着节点在环上的节点。</p><p>Dynamo寻找item对应节点的方法：</p><ul><li>首先对key做哈希得到哈希值；</li><li>然后在环上沿着顺时针方向找到第一个多带值被这个哈希值更大的节点；</li></ul><p>这种方法有一个缺陷，就是每个节点随机分配的位置可能会导致数据不均匀分布负载，也没有考虑到节点的异构因素。为了解决这些问题，Dynamo做了优化，每个节点不是映射到环上的一个点，而是多个点。Dynamo使用了虚拟节点的概念，一个新节点加入到系统后，会在环上分配多个位置（对应多个token）。</p><p>虚拟节点的好处就是：</p><ul><li>当一个节点不可用离开时，会将该节点管理的虚拟节点平均分配给其他真实节点均衡管理；</li><li>同理，新节点加入时，会从现有虚拟节点中拿出虚拟节点分配给新节点；</li><li>一个节点负责的虚拟节点数量可以根据节点容量来决定，充分利用机器的异构性信息；</li></ul><h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>为了实现高可用性和持久性，Dynamo会将数据复制到N台机器上，N可配置。</p><p>具体的做法是，每个Key都会分配一个coordinator节点，coordinator负责落到它管理范围内的复制，除了自己存储一份之外，还会沿着顺时针方向的其他N-1个节点存储一份副本。</p><p>如下图，B除了自己存储一份之外，还会将数据存储到C和D节点。D实际存储的数据，其key范围包括了<code>(A, B]</code>、<code>(B, C]</code> 和 <code>(C, D]</code>。</p><p><img src="https://pic.imgdb.cn/item/60fd8cb75132923bf82b2916.png" alt></p><p>存储某个特定key的所有节点会组成一个<strong>preference list</strong>，为了防止节点的failure，整这个preference list可能多于N个节点，另外由于引入了虚拟节点机制，preference list会保证N个节点不落在相同的物理机上。</p><h3 id="Data-Versioning"><a href="#Data-Versioning" class="headerlink" title="Data Versioning"></a>Data Versioning</h3><p>Dynamo提供最终一致性，所有更新操作会异步地传递给所有的副本。put()操作返回时，更新可能还没有应用到所有的副本，后续的get操作可能去不到最新数据。Amazon有些应用是可以容忍这种不一致性的，应用在这种情况下能继续运行。以操作购物车威力，如果购物车的最新状态不可用，用户对一个老版本的购物车状态做了修改，这种修改是需要保留的，由后续的步骤来解决冲突。</p><p>为了解决冲突，Dynamo将每次修改结果都作为一个全新的版本，允许系统多个版本共存。使得冲突一致化的两种方式：syntactic reconciliation和semantic reconciliation。在大多数情况下，新版本都包含了老版本的数据，而且系统可以判断哪个是权威版本，这就是syntactic reconciliation。</p><p>但是在发生故障并且并发更新的情况下，版本可能发生分叉，系统无法处理这种情况，需要客户端介入，从而将多个版本分支合并成一个，这就是semantic reconciliation。这种操作的好处是写操作永远可用，但会导致业务应用上一些奇怪现象，比如已经删除的商品偶尔又在购物车中冒出来。</p><p>Dynamo使用<strong>向量时钟（vector clock）</strong>来追踪同一个对象不同版本之间的因果关系，一个向量时钟就是一个 (node, counter) 列表。一个向量时钟关联了一个对象的所有版本，可以用来判断对象两个版本是并行分支还是具备因果关系。如果对象的第一个时钟上的所有 counter 都小于它的第二个时钟上的 counter，那第一 时钟就是第二个的祖先，可以安全的删除。否则需要进行reconciliation。</p><p>在Dynamo中，客户端更新一个对象需要指明基于哪个版本进行更新。流程是先读拿到context，context带有vector clock，写的时候把context带下去。在读的时候如果发现了多个版本，并且系统无法reconcile这些版本，就会返回所有的版本，待解决了冲突将多个版本分支合并起来。</p><p>以下图为例</p><p><img src="https://pic.imgdb.cn/item/60fd8cb75132923bf82b2923.png" alt></p><ul><li>客户端写入一个对象。处理这个key的写请求节点Sx增加key的counter，系统有了一个对象D1和它的时钟[(Sx, 1)]；</li><li>客户端更新这个对象。假设还是Sx处理这个请求。此时，系统有了对象D2和它的时钟 [(Sx, 2)]，但可能D1在其他节点的副本还没有看到这个更新；</li><li>假设这个客户端，再次更新了对象，并且这次是由另外的一个节点Sy处理 请求。此时，系统有了D3和它的时钟[(Sx, 2), (Sy, 1)]。假设另一个客户端读取D2，并尝试更新它，写请求由另一个节点Sz处理。 现在，系统有D4（D2的后代），版本clock是[(Sx, 2), (Sz, 1)]。</li><li>此时，D3和D4各自的改动都没有反映在对方之中。因此这两个版本都应当被保留，然后交给客户端，由客户端在下次读取的时候执行semantic reconciliation；</li><li>假设某个客户端读到了D3和D4，即[(Sx, 2), (Sy, 1), (Sz, 1)]。如果客户端执行 reconciliation，并且节点Sx执行协调写，Sx会更新自己在clock中的序列号。最终新生成的数据D5的clock格式如下：[(Sx, 3), (Sy, 1), (Sz, 1)]。</li></ul><p>vector clock的一个潜在问题是，如果有多个节点先后协调同一个对象的写操作，那这个对象的clock vector会变得很长。这种情况发生的可能性不大，只有在网络分裂或多台服务器挂掉的情况下，写操作才可能由非preference list前N个节点来执行，导致vector clock变长。</p><p>为了避免这个问题，Dynamo采用的方法是clock truncation scheme，另外保存一个和<code>(node, counter)</code> 对应的时间戳，记录最后一次更新该记录的时间，当vector clock达到阈值时就删掉最老的一个。这种方案可能会导致无法精确判断部分后代的因果关系，但论文说生产环境没遇到过这个问题。</p><h3 id="Execution-of-get-and-put-operations"><a href="#Execution-of-get-and-put-operations" class="headerlink" title="Execution of get () and put () operations"></a>Execution of get () and put () operations</h3><p>Dynamo中所有存储节点都可以接受key的读写操作。</p><p>读写操作由Amazon基础设施相关的请求处理框架发起HTTP请求。客户端有两种选择：</p><ul><li>将请求路由到负载均衡器，由后者根据负载信息选择后端节点；</li><li>使用能感知partition的客户端，直接路由到coordinator节点；</li></ul><p>前者是负载均衡器转发到环上任意一个节点，如果收到请求的节点不是preference list前N个节点中的一个，那它就不会处理这个请求，而是转发到preference list第一个节点。</p><p>读写操作需要preference list中有不可用节点，就跳过。优先访问preference list中编号较小的节点。</p><p>为了保证副本的一致性，Dynamo使用了一种类似quorum的一致性协议。这个协议有两个配置参数：<code>R</code> 和 <code>W</code>：</p><ul><li>R：允许执行一次读操作所需的最少节点数；</li><li>W：允许执行一次写操作所需的最少节点数；</li></ul><p>设置<code>R + W &gt; N</code>，就得到了一个quorum系统。在这种模型下，读写请求由R/W副本中最慢的一个决定。</p><p>当收到写请求后，coordinator 会为新版本生成 vector clock，并将其保存到节点本地。然后将新版本（和对应的vector clock）发送给N个排在最前面的、可用的节点，只要有至少W-1个节点返回成功，就认为写操作成功。</p><p>读操作类似，如果coordinator收集到多个版本，它会将所有系统判断没有因果关系的版本返 回给客户端。客户端需要对版本进行reconcile，合并成一个最新版本，然后将结果写回 Dynamo。</p><h3 id="Handling-Failures-Hinted-Handoff"><a href="#Handling-Failures-Hinted-Handoff" class="headerlink" title="Handling Failures: Hinted Handoff"></a>Handling Failures: Hinted Handoff</h3><p>如果使用传统的quorum算法，Dynamo无法在节点不可用时保持可用。Dynamo采用了一种更为宽松quorum：所有读和写操作在preference list的前N个健康节点上执行，遇到不可用节点，会沿着哈希环的顺时针方向顺延。</p><p>以下图为例，如果A临时不可用，正常情况下发到A的请求会发送到D，发到D副本的元数据中会提示这个副本数据应该发到A，然后这个数据会被D保存到本地的一个独立数据库中，并且有一个定期任务不断扫描，一旦A可用了，就将这个数据发送回 A，然后D就可以从本地数据库中将其删除了。</p><h3 id="Handling-permanent-failures-Replica-synchronization"><a href="#Handling-permanent-failures-Replica-synchronization" class="headerlink" title="Handling permanent failures: Replica synchronization"></a>Handling permanent failures: Replica synchronization</h3><p>如果出现了在hinted副本移交给原副本节点之前就变的不可用，就会威胁到持久性。Dynamo基于Merkle trees实现了一种逆熵（副本同步）协议来保证副本是同步的。</p><h3 id="Membership-and-Failure-Detection"><a href="#Membership-and-Failure-Detection" class="headerlink" title="Membership and Failure Detection"></a>Membership and Failure Detection</h3><h4 id="Ring-Membership"><a href="#Ring-Membership" class="headerlink" title="Ring Membership"></a>Ring Membership</h4><p>Amazon使用显式机制来向Dynamo环增删节点，管理员通过命令行或web方式连接到 Dynamo node，然后下发一个成员变更命令增删节点。负责处理这个请求的 node 将成员变动信息和对应的时间写入持久存储。成员变动会形成历史记录。Dynamo使用一个gossip-based的算法传播成员变更信息。</p><h4 id="External-Discovery"><a href="#External-Discovery" class="headerlink" title="External Discovery"></a>External Discovery</h4><p>上面的逻辑会有个问题，假设管理员同时添加两个节点，那么它们不会立即感知到对方，导致临时的逻辑分裂。为了避免这个问题，论文将部分Dynamo节点作为种子节点，所有节点都知道种子节点的存在，因为所有节点最终都会和种子节点reconcile成员信息，所以逻辑分裂就几乎不可能发生了。种子是从静态配置文件或者配置中心获取的。</p><h4 id="Failure-Detection"><a href="#Failure-Detection" class="headerlink" title="Failure Detection"></a>Failure Detection</h4><p>故障检测在Dynamo中的读写操作或者partition和hinted replica时移跳过不可用的节点。其做法是，节点B只要没有应答节点A的消息，A就认为B不可达。在有持续的client请求时，Dynamo Ring上的节点会有持续的交互，能定期检查及诶但是否恢复。使用简单的gossip协议就可以感知到节点的增删。</p><h3 id="Adding-Removing-Storage-Nodes"><a href="#Adding-Removing-Storage-Nodes" class="headerlink" title="Adding/Removing Storage Nodes"></a>Adding/Removing Storage Nodes</h3><p>当新节点加入系统后，会获得一些随机分散到Ring上的token，此时原本负责某些key range的节点会将此时负责的key转移到新节点。</p><h2 id="IMPLEMENTATION"><a href="#IMPLEMENTATION" class="headerlink" title="IMPLEMENTATION"></a>IMPLEMENTATION</h2><p>Dynamo支持选择不同的本地存储组件来作为存储引擎，其实以插件的方式引入的，包括了BDB、Mysql、in-memory buffer with persistent backing store等。应用能够为不同的访问类型选择最合适的存储引擎。</p><p>coordinator会代替客户端执行读写请求，每个客户端请求都会在收到这个请求的节点上创建一个状态机，包括了所有相关的逻辑。</p><p>对于写请求，前面提到过由preference list前N个节点中任一个coordinate，总是由第一个来coordinate的好处是使得在同一个地方完成写操作的顺序化，但可能会导致复杂不均匀。为了解决这个问题，preference list内的所有N个节点都可以coordinate写操作，另外由于写操作前面都带有读操作，写操作的coordinator会选择前一次读操作返回最快的节点（这个信息会被存在返回的上下文中）。由于这项优化使得前一次读操作选中的存储节点更容易被选中，提高了read-your-writes的概率。</p><h2 id="CONCLUSIONS"><a href="#CONCLUSIONS" class="headerlink" title="CONCLUSIONS"></a>CONCLUSIONS</h2><p>本文介绍了Dynamo作为一个高可用、高可扩展性的数据存储系统，在Amazon的诸多核心系统中都有应用。Dynamo提供了期望的可用性与性能，能够很好处理节点不可用、网络分裂的情况。Dynamo最大的意义是证明了：一些去中心化的技术结合起来能够提供一个高可用的系统，并且在很多应用环境中投产了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Dynamo&quot;&gt;&lt;a href=&quot;#Dynamo&quot; class=&quot;headerlink&quot; title=&quot;Dynamo&quot;&gt;&lt;/a&gt;Dynamo&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;原文是2007年SOSP上Amazon发布的分布式存储经典论文&lt;a href=&quot;h
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>TiDB: A Raft-based HTAP Database</title>
    <link href="http://yoursite.com/2021/07/26/TiDB-A-Raft-based-HTAP-Database/"/>
    <id>http://yoursite.com/2021/07/26/TiDB-A-Raft-based-HTAP-Database/</id>
    <published>2021-07-25T16:03:14.000Z</published>
    <updated>2021-07-25T16:06:13.186Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TIDB"><a href="#TIDB" class="headerlink" title="TIDB"></a>TIDB</h1><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>Hybrid Transactional and Analytical Processing (HTAP，混合事务和分析处理)数据库要求独立地处理事务和分析查询，避免相互干扰。为了实现这一点，需要为两类查询维护不同的数据副本。然而，为存储系统中的分布式副本提供一致性视图并不容易。在该系统中，分析请求可以大规模地、高可靠性地从事务工作负载中读取一致的实时数据。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>关系型数据库（RDBMS）一直因其关系模型、强力的事务保证和SQL接口而广受好评，但它不具备高可扩展性和高可用性。因此NoSQL就应运而生，像Google bigtable和DynamoDB之类的放宽了一致性要求，提供了更高的可扩展性。但由于业务又需要事务处理能力、数据一致性和SQL接口等，就慢慢出现了像CockroachDB和Spanner之类的NewSQL。此外，像许多架构在Hadoop之上的SQL系统一样，在线分析处理系统（OLAP）也在迅速发展。</p><p>以前一般认为针对OLAP和OLTP应该采用的不同的数据模型和技术方案，但维护多个系统的成本很高。业界开始探索OLTP和OLAP的混合系统HTAP。HTAP系统需要满足几个关键点：一是数据新鲜度，即OLAP需要拿到最新的数据；二是隔离，即为单独的OLTP或者OLAP查询提供不同的硬件资源处理，避免性能相互影响。</p><p>本文就是基于上面的考虑，提出了一个以Raft为共识算法的HTAP数据库——TiDB，在Raft中引入了一个专门的节点Learner，Learner会异步地复制Leader节点的事务日志，并为OLAP查询构造新副本，并将日志中的行格式元组转换为列格式，便于查询。</p><h2 id="RAFT-BASED-HTAP"><a href="#RAFT-BASED-HTAP" class="headerlink" title="RAFT-BASED HTAP"></a>RAFT-BASED HTAP</h2><p>使用共识算法如Raft、Paxos等可以基于复制状态机在服务器之间实时可靠地复制数据，通过调整，该论文的做法可以针对不同的 HTAP 工作负载将数据复制到不同的服务器，并且保持资源隔离和数据新鲜度。</p><p><img src="https://pic.imgdb.cn/item/60fd8ba35132923bf82635ad.png" alt></p><p>如上图所示，TiDB将数据按行格式存储在多个Raft Group里，每个Raft Group由一个Leader和多个Follower组成，另外为每个组增加一个Learner角色，可以异步复制Leader的数据，并将行格式转换为列格式。另外，扩展的查询优化器用来构建访问列存和行存的物理计划。</p><p>在该实现中，Leader不参与Leader选举，也不计入日志复制的个数，不参与Quorum。读数据时，需要保证Leader和Learner之间的强一致性和日志复制的低延迟。行列格式的转换也有优点，行格式可以利用索引来高效进行事务查询，列格式可以有效利用数据压缩和矢量化处理。由于Learner部署在单独的物理资源中，OLAP和OLTP可以在独立的资源中得到处理。</p><p>总的来说，这个设计克服了几个困难：一是基于Raft的系统如何应对高并发读写；二是资源独立如何保证数据新鲜度；另外就是如何构建查询计划在行式存储和列式存储中选择最优的。</p><h2 id="ARCHITECTURE"><a href="#ARCHITECTURE" class="headerlink" title="ARCHITECTURE"></a>ARCHITECTURE</h2><p>如下图所示，这是TIDB的架构，兼容MySQL协议，由三个核心组件组成：分布式存储层、Placement Driver布局驱动器和计算引擎层。</p><p><img src="https://pic.imgdb.cn/item/60fd8ba35132923bf82635cf.png" alt></p><ul><li>分布式存储层</li></ul><p>由行式存储（TiKV）和列式存储（TiFlash）组成，存储在TiKV的数据是有序的key-value对，key由两个整数table id和row id组成，其中row id就是主键列，value就是真实的行数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Key: &#123;table&#123;tableID&#125; record&#123;rowID&#125;&#125;</span><br><span class="line">Value: &#123;col0, col1, col2, col3&#125;</span><br></pre></td></tr></table></figure><p>为了保证可扩展性，TiDB采用了range partition的策略，将kv对映射分割成若干个连续的范围，每个范围称为一个region，每个region都有多个副本来保证可用性，Raft就是用于维护每个region中若干个副本的一致性的。</p><p>PD负责管理region，包括提供每个key对应的region和其物理位置，以及自动转移region以平衡负载。同时PD也是时间戳分配器，提供了严格递增全剧唯一的时间戳。PD不具备持久状态。</p><p>计算引擎层是无状态、可扩展的，其SQL引擎由cost-based query optimizer和distributed query executor组成。另外TiDB基于Percolator实现了2PC协议。</p><p>除此之外，TiDB还与Spark集成，方便集成TiDB和HDFS中存储的数据。</p><h2 id="MULTI-RAFT-STORAGE"><a href="#MULTI-RAFT-STORAGE" class="headerlink" title="MULTI-RAFT STORAGE"></a>MULTI-RAFT STORAGE</h2><p>下图展示了分布式存储层的架构，其由TiKV和TiFlash组成。每个Region的副本之间都使用Raft来维护数据一致性。当数据复制到TiFlash的时候，为了方便扫描，多个Regions会被合并成一个Partition。</p><p><img src="https://pic.imgdb.cn/item/60fd8ba35132923bf82635e8.png" alt></p><h3 id="Row-based-Storage"><a href="#Row-based-Storage" class="headerlink" title="Row-based Storage"></a>Row-based Storage</h3><p>TiKV是由多个TiKV服务器组成的，每个TiKV服务器都可以是不同Region的Raft Leader或者Follower，另外在TiKV服务器上，数据和原数据都会保存在RocksDB上。</p><p>基于Raft算法响应读写请求的过程如下：</p><ol><li>Region的Leader从SQL引擎层接受请求；</li><li>Leader将请求Append到日志中；</li><li>Leader向Follower发送新的日志条目，Follower会将接收到的日志Append到自己的日志中；</li><li>Leader等待Follower回应，满足指定数量的节点响应成功后，Leader会在本地commit并Apply；</li><li>Leader将结果发送给客户端；</li></ol><h4 id="Optimization-between-Leaders-and-Followers"><a href="#Optimization-between-Leaders-and-Followers" class="headerlink" title="Optimization between Leaders and Followers"></a>Optimization between Leaders and Followers</h4><p>为了提高吞吐，可以在Leaders和Followers之间的操作做一些优化。首先是，上述过程的第二步和第三步可以并行进行，即便第二步失败了，只要第三步成功了仍然可以提交日志。另外就是，第三步中Leader可以缓冲这些日志条目，并批量发送。并且发送日志后也不需要等待Follower响应，可以假设发送成功，并利用预测的日志索引发送后来的日志。即便出现错误，Leader可以调整日志索引进行重发。还有就是，第四步中，Leader应用日志可以交给其他线程去做。整体流程就变成：</p><ol><li>Region的Leader从SQL引擎层接受请求；</li><li>Leader并行地向Follower发送日志，并同时Append本地日志；</li><li>Leader继续接收请求，重复2；</li><li>Leader commit日志，并将应用逻辑交给另外的线程去做；</li><li>应用日志后，Leader返回结果；</li></ol><h4 id="Accelerating-Read-Requests-from-Clients"><a href="#Accelerating-Read-Requests-from-Clients" class="headerlink" title="Accelerating Read Requests from Clients"></a>Accelerating Read Requests from Clients</h4><p>从Leader读取数据具有线性化的语义，但通过常规的Raft流程来保证会导致很高的网络IO开销。为了提高性能，可以避免日志同步阶段。</p><p>Raft保证：一旦Leader成功写入数据，就可以响应任何读取请求，而无需同步日志。但Leader是可能改变的。为了实现从Leader读取，TiKV做了以下优化：</p><ul><li>read index：Leader响应请求时，会将当前的提交索引记录为本地read index，然后向Follower发送heartbeat确认Leader地位。如果确实是Leader，并且应用的索引大于或等于read index，就可以返回值。</li><li>lease read：为了减少heartbeat开销，Leader和Follower之间维护一个Lease期限，Follower在这期间不发出选举请求，因此Leader在此期间也无需与Follower进行heartbeat交流。</li></ul><p>Follower也可以响应client的读请求，但需要向Leader询问read index，如果本地应用索引等于或大于read index，则Follower可以将值返回给客户端。</p><h4 id="Managing-Massive-Regions"><a href="#Managing-Massive-Regions" class="headerlink" title="Managing Massive Regions"></a>Managing Massive Regions</h4><p>为了实现跨机器平衡Region，Plancement Driver会对Region副本数量和位置施予限制。一个就是必须要在不同的TiKV实例上放置至少三个Region副本。PD通过Heartbeat从服务器收集信息、监控服务器负载，并将热Region进行转移。</p><p>另一方面，维护大量Region涉及Heartbeat信息和元数据管理导致的大量的网络和存储开销，会被PD根据负载情况调整心跳频率。</p><h4 id="Dynamic-Region-Split-and-Merge"><a href="#Dynamic-Region-Split-and-Merge" class="headerlink" title="Dynamic Region Split and Merge"></a>Dynamic Region Split and Merge</h4><p>这里主要设计Region的拆分和合并。热点Region或者大型Region会被拆成小Region，小或者访问少的Region，会被合并成大Region，以减少由于维护小Region心跳和元数据带来的网络和CPU开销。</p><p>PD操作Region，是通过向TiKV发送拆分和合并指令，然后以Raft流程来完成更新请求。Region拆分比较简单，只需要更改元数据。合并的话，PD会移动两个Region的副本，放到单独的服务器上。然后通过两阶段操作，在每台服务器上本地合并两个Region的并置副本：即停止其一Region的服务并将其与另一Region合并。</p><h3 id="Column-based-Storage-TiFlash"><a href="#Column-based-Storage-TiFlash" class="headerlink" title="Column-based Storage (TiFlash)"></a>Column-based Storage (TiFlash)</h3><p>考虑到TiKV中的行存数据并不适合OLAP，因此将列存储TiFlash合并到TiDB中。TiFlash由Learner节点组成，仅从Raft组接收Raft日志，并将行格式的元祖转换为列存数据。</p><p>用户可以通过SQL语句为表设置列格式副本，<code>ALTER TABLE x SET TiFLASH REPLICA n;</code>其中x是表名，n是副本数量。在TiFlash中，每个表会按partitions进行划分，每个partitions包括几个连续Regions，更大的Regions便于范围扫描。</p><p>当初始化一个TiFlash实例时，相关Region的Leader开始讲数据复制到新的Learner。一旦初始化完成后，TiFlash开始监听Raft组的更新。Learner收到日志后，会将日志应用到本子状态机，包括日志重放、转换数据格式和更新本地存储中的引用值。</p><h4 id="Log-Replayer"><a href="#Log-Replayer" class="headerlink" title="Log Replayer"></a>Log Replayer</h4><p>由于在Raft中，Learner接收到的日志时可线性化的，因此重放日志也会按照FIFO的策略重放日志，具体步骤包括：</p><ul><li>压缩日志：事务日志分为三种状态：预写、提交或回滚。回滚的日志不需要写盘；</li><li>解码元组：缓冲区中的日志被解码为行格式的元组，去除关于事务的冗余信息；</li><li>转换数据格式：行元组会被转换为列数据；</li></ul><p><img src="https://pic.imgdb.cn/item/60fd8be25132923bf8275779.png" alt></p><p>更具体的步骤可以参考上图。</p><h4 id="Schema-Synchronization"><a href="#Schema-Synchronization" class="headerlink" title="Schema Synchronization"></a>Schema Synchronization</h4><p>为了实时将元组转换为列格式，Learner需要知道最新的schema，因此TiFlash会通过Schema syncer与TiKV中最新的Schema同步。同时为了减少TiFlash向TiKV的请求次数，每个Learner都会维护一个schema cache。这里采取两阶段策略：</p><ul><li>Regular synchronization：定期同步；</li><li>Compulsive synchronization：synced检测到不匹配的schema，就会主动从TiKV拉去最新的Schema；</li></ul><h4 id="Columnar-Delta-Tree"><a href="#Columnar-Delta-Tree" class="headerlink" title="Columnar Delta Tree"></a>Columnar Delta Tree</h4><p>TiFlash设计了一个新的列存储引擎——Delta Tree，该引擎支持快速追加增量更新，然后将其与每个Partitions的稳定版本合并。如下图所示，在Stable space中，Partitions以chunks的形式存储，每个chunk都覆盖了一个较小的元组范围。TiFlash将元组的列数据及其元数据存储到不同的文件中，以同时更新文件。</p><p><img src="https://pic.imgdb.cn/item/60fd8ba35132923bf82635fd.png" alt></p><p>新进来的增量更新时插入或者删除数据的原子批处理，这些增量会缓存到内存中，并持久化道磁盘。另外TiFlash会定期将小增量压缩成大增量，并持久化。传入增量的内存副本有助于读取最新数据。</p><p>另外，读取的时候由于需要合并增量文件和稳定空间中的数据，而且增量文件本身也可能存在空间放大的问题。TiFlash需要定期将增量合并到稳定空间中，每个增量文件及其相关chunks被读入内存进行合并，合并后的chunks自动替换磁盘中的原始chunks。</p><p>由于相关的键在增量空间中是无序的，合并成本较高，并且也会影响合并读的速度，因此会在增量空间构建B+ Tree索引，每个增量更新项都被插入到 B+ Tree 中，并按其关键字和时间戳进行排序。便于快速响应读请求，和有序数据也更易与稳定块合并。</p><h4 id="Read-Process"><a href="#Read-Process" class="headerlink" title="Read Process"></a>Read Process</h4><p>与Follower read类似，Learner提供snapshot isolation，在接收到读取请求后，Learner向其Leader发送read index请求，以获取涵盖所请求时间戳的最新数据。Learner拿到日志后，回放日志，写入Delta Tree，就可以读到特定数据响应请求了。</p><h2 id="HTAP-ENGINES"><a href="#HTAP-ENGINES" class="headerlink" title="HTAP ENGINES"></a>HTAP ENGINES</h2><p>为了提供OLAP和OLTP查询，TiDB引入了SQL引擎来为了查询计划做决策。SQL引擎使用Percolator模型来实现分布式集群的乐观和悲观锁，并基于优化器、索引和下推算子来支持OLAP查询。</p><h3 id="Transactional-Processing"><a href="#Transactional-Processing" class="headerlink" title="Transactional Processing"></a>Transactional Processing</h3><p>TiDB为ACID事务提供了snapshot isolation语义或者repeatable read语义，前者允许每个请求读取版本一致的数据，后者则是事务中的不同语句可能为同一个key读取不同的值，但重复读取将会读取到相同的值。这是基于MVCC实现。</p><p>如下图，TiDB中的事务由SQL引擎、TiKV和PD三个组件共同完成：</p><p><img src="https://pic.imgdb.cn/item/60fd8ba35132923bf8263619.png" alt></p><p>TiDB对于悲观锁和乐观锁的实现启发自Percolator模型。</p><ol><li>client接收到Begin命令后，SQL引擎向PD请求一个start_ts时间戳；</li><li>SQL引擎从TiKV读取数据并在本地内存中执行SQL DMLs。TiKV提供在start_ts之前最近的commit_ts数据；</li><li>SQL引擎收到client的commit命令后，启动2PC协议。随机选择一个主键，并行锁定所有的key，并将prewrite发送TiKV节点；</li><li>如果所有的prewrite都成功了，SQL引擎会向PD请求一个commit_ts，并向TiKV发送commit命令。TiKV commit主键，并响应成功回到SQL引擎；</li><li>SQL引擎向Client响应成功；</li><li>SQL引擎向TiKV发送commit命令，异步并行地提交从键和清除锁；</li></ol><p>悲观事务和乐观事务的区别在于获取锁的实际，前者是在第二步执行DMLs的时候获取，后者则是第三步prewrite的时候。</p><h3 id="Analytical-Processing"><a href="#Analytical-Processing" class="headerlink" title="Analytical Processing"></a>Analytical Processing</h3><p>TiDB通过两阶段查询优化来实现优化器：rule-based optimization生成逻辑计划， cost-based optimization将逻辑计划转换为物理计划。由于TiDB有两类存储、因此扫描表往往有三种选项：扫描TiKV的行格式表、扫描TiKV中有索引的表和骚婊TiFlash的列。</p><p>索引可以提高点查询和范围查询的性能，TiDB实现了可扩展性的索引，由于维护索引会消耗大量资源，因此会在后台以非同步的形式构建或删除索引。索引是以与数据相同的方式按Regions分割，并作为键值存储在TiKV 中。唯一键索引上的索引项编码为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Key: &#123;table&#123;tableID&#125; index&#123;indexID&#125; indexedColValue&#125;</span><br><span class="line">Value: &#123;rowID&#125;</span><br></pre></td></tr></table></figure><p>非唯一索引上的索引项被解码为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Key: &#123;table&#123;tableID&#125; index&#123;indexID&#125; indexedColValue rowID&#125;</span><br><span class="line">Value: &#123;null&#125;</span><br></pre></td></tr></table></figure><p>物理计划的执行是由SQL引擎层使用pulling iterator model进行的，通过将部分计算下推到存储层，可以进一步优化执行。在存储层，执行计算的组件称为coprocessor，coprocessor在不同的服务器上并行执行substrees of an execution 破烂，这减少了必须从存储层发送到引擎层的元组数量。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要是介绍了一个投入生产环境的HTAP数据库——TiDB。TiDB建立在TiKV上，这是一个基于Raft的分布式行式存储，并引入一个TiFlash组件用于实时分析，作为Raft的learner从TiKV异步复制日志，并将行格式的数据转换为列格式。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TIDB&quot;&gt;&lt;a href=&quot;#TIDB&quot; class=&quot;headerlink&quot; title=&quot;TIDB&quot;&gt;&lt;/a&gt;TIDB&lt;/h1&gt;&lt;h2 id=&quot;ABSTRACT&quot;&gt;&lt;a href=&quot;#ABSTRACT&quot; class=&quot;headerlink&quot; title=&quot;A
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>SuRF: Range Query Filter</title>
    <link href="http://yoursite.com/2021/07/18/SuRF-Range-Query-Filter/"/>
    <id>http://yoursite.com/2021/07/18/SuRF-Range-Query-Filter/</id>
    <published>2021-07-18T15:26:19.000Z</published>
    <updated>2021-07-18T15:27:01.007Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SuRF"><a href="#SuRF" class="headerlink" title="SuRF"></a>SuRF</h1><blockquote><p>本文介绍了一种SuRF的数据结构实现，用以替代传统的布隆过滤器，支持单点查询和范围查询使用。</p></blockquote><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>LSM树是市面上数据库常用的底层存储引擎，能提供快速写和一定速度的读取。但该设计的一个问题是由于SSTable的多层设计导致大量磁盘IO读取，由此引入了布隆过滤器作为内存数据结构来帮助查询。布隆过滤器对于单点查询很有用，但并不能处理范围查找，尽管也有一些类似的设计（如前缀布隆过滤器）做了优化，但总体不够灵活通用。</p><p>因此本文提出了Succinct Range Filter（下文简称SuRF），这是一种快速紧凑的过滤器，提供了精确匹配过滤、范围过滤和近似范围计数等功能。SuRF是建立在Fast Succinct Trie（FST）这一新型空间高效简洁的数据结构上，FST每个trie节点仅需要10bit。文章使用SuRF替代了RocksDB的布隆过滤器，这将范围查询的速度提高了1.5倍到5倍，但极端情况下会导致单点查询变慢40%。</p><h2 id="FAST-SUCCINCT-TRIES"><a href="#FAST-SUCCINCT-TRIES" class="headerlink" title="FAST SUCCINCT TRIES"></a>FAST SUCCINCT TRIES</h2><p>SuRF的核心数据结构是FST，这是一种空间优化的静态tire，可以做单点查询和范围查询，其设计基于以下的思路：一个tire的上层节点较少，但访问量很大；下层节点虽多，但访问不算频繁。因此FST使用了基于位图的快速编码方案（LOUDS-Dense）来对上层节点编码，下层则用LOUDS-Sparse方案来编码，节省空间。</p><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>如果一颗树所占用的空间接近于信息论的下限，则该树可以认为是succinct。论文使用的是一种叫Level-Ordered Unary Degree Sequence的技术，LOUDS以广度优先的顺序遍历节点，并使用一元编码Unary coding对每个节点的度进行编码，例如下图节点3有三个字节点，因此被编码成”1110”。</p><p><img src="https://pic.imgdb.cn/item/60f447735132923bf826bdba.png" alt></p><p>编码完成后，该树会变成一组bit序列，需要访问节点时，则使用rank＆select两种操作：</p><ul><li>rank1(i): 返回[0, i]位置区间中, 1的个数；</li><li>select1(i): 返回第i个1的位置(整个bit序列)；</li><li>对应的则是rank0(i)和select0(i)操作；</li></ul><p>如今关于rank＆select的实现会使用查找表预算存取计算好的结果，保证查询时可以在常数时间里完成。有了rank＆select的支持，LOUDS就可以在常数时间内实现SuRF需要的点查询和范围查询。假设节点代号和bit位置都是从0开始的：</p><ul><li>在bit序列中第i个节点的位置：<code>select0(i)+1</code>；</li><li>在bit序列中从p开始的节点的第k个子节点：<code>select0 (rank1 (p + k)) + 1</code>；</li><li>始于p的节点的父节点位置：<code>select1 (rank0 (p))</code>；</li></ul><p><img src="https://pic.imgdb.cn/item/60f447735132923bf826bdda.png" alt></p><h3 id="LOUDS-Dense"><a href="#LOUDS-Dense" class="headerlink" title="LOUDS-Dense"></a>LOUDS-Dense</h3><p>LOUDS-Dense使用三个bit map和一个value的字节序列对每个trie节点按层级进行编码：</p><ul><li>D-Labels：记录每个节点的分支标签；上图中根节点具有标记为f，s和t的三个分支。 D-Labels位图设置第102位（f），115位（s）和116位（t）并清除其余位；</li><li>D-HasChild：表示节点是叶子节点还是中间节点，以上图根节点为例，f和t都有子节点，但s没有，所以102和106两个bit会设置为1；</li><li>D-IsPrefixKey：标记当前前缀是否为有效key；以上图根节点为例，f既作为前缀，同时也是trie里的有效key；</li><li>D-Values : 存储的是固定大小的 value，本文中则是三种后缀的指针；</li></ul><p>用rank&amp;select操作trie树，则是：</p><ul><li>第一个孩子节点：<code>D-ChildNodePos(pos)=256 × rank1(D-HasChild, pos)</code>；</li><li>父节点：<code>DParentNodePos(pos)=select1(D-HasChild,[pos / 256])</code>；</li></ul><h3 id="LOUDS-Sparse"><a href="#LOUDS-Sparse" class="headerlink" title="LOUDS-Sparse"></a>LOUDS-Sparse</h3><p>如上图所示，LOUDS-Sparse使用四个字节或者bit序列对trie节点进行编码，然后将编码的节点按层次顺序进行串联。</p><ul><li>S-Labels：记录分支标签，按level order顺序记录所有节点的label，并且使用0xFF($)来标记该key同时也是key节点；</li><li>S-HasChild：使用一个bit记录节点的label是否含有分支子节点；</li><li>S-LOUDS：使用一个bit记录每个label是否为该节点的第一个label；</li><li>S-Values：与上面类似；</li></ul><p>用rank&amp;select操作trie树，则是：</p><ul><li>孩子节点：<code>S-ChildNodePos(pos) = select1(S-LOUDS, rank1(S-HasChild, pos) + 1);</code>；</li><li>父节点：<code>S-ParentNodePos(pos) = select1(S-HasChild, rank1(S-LOUDS, pos) - 1)</code>；</li></ul><h3 id="LOUDS-DS-and-Operations"><a href="#LOUDS-DS-and-Operations" class="headerlink" title="LOUDS-DS and Operations"></a>LOUDS-DS and Operations</h3><p>LOUDS-DS就是一种混合trie，上层用LOUDS-Dense编码，下层使用LOUDS-Sparse编码。其中的分界点则根据性能和空间进行调整，LOUDS-Dense-Size(l)表示从0到l（不包含l）层采用LOUDS-Dense编码，而LOUDS-Sparse-Size(l)则表示从l到H层采用LOUDS-Sparse方式编码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOUDS-Dense-Size(l) × R ≤ LOUDS-Sparse-Size(l) <span class="comment">// 通常使用R = 64作为默认值，R越小，性能越好但空间使用更多</span></span><br></pre></td></tr></table></figure><p>LOUDS-DS支持三个基本操作：</p><ul><li>ExactKeySearch(key)：如果key存在，则返回key的值（否则返回NULL）；</li><li>LowerBound(key)：返回一个迭代器，该迭代器指向的键-值对(k, v)，其中k是按字典顺序的满足k≥key的最小的键；</li><li>MoveToNext(iter)：将迭代器移至下一个键值；</li></ul><p>对于点查询，则是先在LOUDS-Dense上查询，查不到即到LOUDS-Sparse查询。对于范围查询，则是执行LowerBound，找到最小的满足k≥key的键后，则光标将从当前的叶子标签位置开始并向前移动，就是正常的tree搜索方式。</p><h3 id="Space-and-Performance-Analysis"><a href="#Space-and-Performance-Analysis" class="headerlink" title="Space and Performance Analysis"></a>Space and Performance Analysis</h3><p>考虑到在LOUDS-DS中LOUDS-Sparse的节点更多，假设这是一个具备n个节点的trie，其中会有8n位用于S标签，2n位用于S-HasChild和S-LOUDS，总共10n位。</p><p>对于点查询，在每个LOUDS-Dense级别上进行搜索都需要两次数组查找，以及对位向量D-HasChild的rank操作。因此，主要操作是对所有位向量进行rank和 select，并在LOUDS-Sparse层进行标签搜索。</p><h3 id="Optimizations"><a href="#Optimizations" class="headerlink" title="Optimizations"></a>Optimizations</h3><p>论文针对LOUDS-DS中的三个关键操作：rank、select和label search进行了优化。</p><p><img src="https://pic.imgdb.cn/item/60f447735132923bf826be06.png" alt></p><ul><li>Rank</li></ul><p>上图展示了一个简洁的Rank结构，将bit vector分割成B bits大小的块，每个块用32bits的字段预先计算好的到这个block的rank值。对于一个pos来说，就有<code>rank1(pos) = LUT[i / B] + popcount[i / B * B, i]</code>。popcount是内置的CPU指令，可以快速计算出某一段区间1的个数。</p><ul><li>Select</li></ul><p>同样是使用LUT的方法，预先计算好值。假设采样周期是3，上图中第三个LUT保存的就是3x2，也就是第6个1的pos值，即8。那就有<code>select1(i) = LUT[i / S] + (selecting (i - i / S * S)th set bit starting from LUT[i / S] + 1) + 1</code>。</p><ul><li>Label Search</li></ul><p>使用SIMD指令在LOUDS-Sparse中执行标签搜索。</p><ul><li>Prefetching</li></ul><p>在切换到LOUDS-DS中的不同位/字节序列之前进行预取。</p><h2 id="SUCCINCT-RANGE-FILTERS"><a href="#SUCCINCT-RANGE-FILTERS" class="headerlink" title="SUCCINCT RANGE FILTERS"></a>SUCCINCT RANGE FILTERS</h2><p>基于FST构建SuRF，最重要的是在false positive rate和filter所需要的内存使用之间取得平衡。论文的做法是使用裁剪trie，通过截断低层次的trie，并使用从key获得的后缀位（key本身或者key的哈希值）做替代。论文介绍了4种不同的trie树裁剪方式。</p><p><img src="https://pic.imgdb.cn/item/60f447735132923bf826be2f.png" alt></p><ol><li>Basic SuRF</li></ol><p>Basic SuRF的基本思路就是只存储key的共有前缀和一个额外的byte，裁剪掉树的部分叶节点。Basic SuRF的FPR与key的分布有关。</p><ol start="2"><li>SuRF with Hashed Key Suffixes</li></ol><p>在Basic SuRF基础上，通过对key进行哈希计算，将hash值的n个bits存储到value中，这种方法可以降低FPR，但对范围查询没有帮助。</p><ol start="3"><li>SuRF with Real Key Suffixes</li></ol><p>SuRF-Real存储n个bits的真实key，这样同时增强了Point query和Range query，但其FPR还是要比SuRF-Hash高。</p><ol start="4"><li>SuRF with Mixed Key Suffixes</li></ol><p>SuRF-Mixed的做法是混合使用2和3两种方式，一部分是real key，另一部分是hashed key。</p><h3 id="Operations"><a href="#Operations" class="headerlink" title="Operations"></a>Operations</h3><p>论文总结了如何使用FST实现SuRF的基本操作。</p><ul><li>build(keyList)：根据给定的key构建fitter；</li><li>result = lookup(k)：对k执行点查询，返回true意味着k可能存储。以上面SuRF为例，首先搜寻key，直到叶子结点。如果未到叶节点就终止了则返回false；否则计算k的相关bits与叶节点的相关bits做比较；</li><li>iter, fp_flag = moveToNext(k)：这个操作实际上是LowerBound执行，返回满足&gt;=k的最小key的双向迭代器；</li><li>count, low_fp_flag, high_fp_flag = count(lowKey, highKey)：返回在[lowKey, highKey]范围内的key个数；</li></ul><h2 id="EXAMPLE-APPLICATION-ROCKSDB"><a href="#EXAMPLE-APPLICATION-ROCKSDB" class="headerlink" title="EXAMPLE APPLICATION: ROCKSDB"></a>EXAMPLE APPLICATION: ROCKSDB</h2><p>论文将SuRF与RocksDB集成在一起，以替代其Bloom过滤器。下图显示了RocksDB中Get，Seek和Count查询的执行路径。Next的核心算法类似于Seek。过滤器操作在红色框中。如果该框为虚线，则可能由于误报需要检查边界key。</p><p><img src="https://pic.imgdb.cn/item/60f447735132923bf826be57.png" alt></p><p>对于Get(key)，SuRF的用法与Bloom过滤器完全相同。</p><p>对于Seek(lk, hk)，RocksDB首先通过在块索引中搜索lk来决定所有级别的候选SSTable。在没有SuRF的情况下，RocksDB会检查每个候选SSTable并获取满足&gt;=lk的最小的块。 RocksDB然后比较候选key，找到全局最小key。使用SuRF，则无需获取实际的块，RocksDB可以通过在其SuRF上执行moveToNext(lk)查询来避免每个SSTable都进行IO，从而获取每个SSTable的候选key。如果查询成功（例如，是Open Seek或K≤hk），RocksDB将从选定的SSTable中精确地获取一个包含全局最小值K的块。如果查询失败（即，K&gt;hk），则不没有读盘IO。</p><h2 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h2><p>本文介绍了SuRF，该filter支持单点查询、范围查询和计数查询，SuRF建立在一个新的succinct数据结构上，即FST。FST的性能极高，并且SuRF本身的内存使用也是较为搞笑的，其空间使用与FPR的权衡可以通过不同数量的后缀位来调整。通过在RocksDB上替换了bloom filter的测试，显著地减少了IO并提高了范围查询的吞吐量。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;SuRF&quot;&gt;&lt;a href=&quot;#SuRF&quot; class=&quot;headerlink&quot; title=&quot;SuRF&quot;&gt;&lt;/a&gt;SuRF&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;本文介绍了一种SuRF的数据结构实现，用以替代传统的布隆过滤器，支持单点查询和范围查询使用。&lt;/p
      
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Percolator</title>
    <link href="http://yoursite.com/2021/06/20/Percolator/"/>
    <id>http://yoursite.com/2021/06/20/Percolator/</id>
    <published>2021-06-19T16:14:20.000Z</published>
    <updated>2021-06-19T16:14:52.598Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Percolator"><a href="#Percolator" class="headerlink" title="Percolator"></a>Percolator</h1><blockquote><p>本文是谷歌的经典论文，介绍了一个对大型数据集做增量处理更新的系统Percolator，谷歌用它来构建索引系统，极大地提高了处理速度。Percolator基于BigTable构建的，由于BigTable不支持跨行事务，更像是给BigTable打补丁。</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>索引系统是Google Web搜索的核心系统，在应对海量索引数据时，索引创建和索引的实时更新必须要面对的挑战。Google使用Mapreduce解决了高效创建索引的问题，但MR对于实时更新的场景是不合适的，因此他们构建了一个新的增量更新系统Percolator。Percolator主要关注的是跨行事务和Notification，支持在PB级别存储库中进行随机访问，并提供强一致性的保证。</p><h2 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h2><p>Percolator为了大规模的增量更新提供了两个抽象：</p><ul><li>基于随机访问库的ACID事务；</li><li>observers，一种处理增量计算的方式；</li></ul><p>每个Percolator系统包含三个二进制文件：Percolator的worker、一个BigTable的tablet服务器和一个GFS chunkserver。所有的observer都会连接到Percolator的worker中，该worker会扫描所有在BigTable中发生改变的列，然后调用observer中的回调逻辑。另外Percolator还会依赖两个服务：timestamp oracle和一个轻量级锁服务，前者通过递增的时间戳提供了快照隔离协议，后者则是依赖锁服务来搜索“dirty notification”。</p><h3 id="BigTable"><a href="#BigTable" class="headerlink" title="BigTable"></a>BigTable</h3><p>Percolator是在BigTable基础上构建，数据被组织到BigTable的行列中，元数据则存储在旁边的特殊列中，基于BigTable的接口封装了大量的API，主要目的是提供BigTable缺失的功能：多行事务和observer框架。</p><p>至于BigTable和SSTable所在的GFS的具体实现可以查看对应的论文。</p><h3 id="Transactions"><a href="#Transactions" class="headerlink" title="Transactions"></a>Transactions</h3><p>Percolator使用ACIS快照隔离来基于BigTable的跨行跨表事务。Percolator使用Bigtable中的timestamp，对每个数据项都存储多版本，以实现快照隔离。在一个事务中，按照某个timestamp读出来的版本数据就是一个快照，然后再用一个往后的timestamp写入新数据。快照隔离可以有效解决write- write冲突，如果事务A和B并行运行，同时往某个cell执行写操作，大部分情况下都能正常提交。任意的timestamp都代表了一个一致快照，读取一个cell仅仅需要用给出的timestamp执行BigTable查询即可。</p><p><img src="https://pic.imgdb.cn/item/60ce1787844ef46bb231edf4.png" alt></p><p>考虑到Percolator不能直接控制对存储介质的访问，而是需要修改BigTable的状态，所以Percolator需要明确地维护锁，以实现分布式事务。这个锁服务需要具备几个特点：高可用，能够解决锁在2PC阶段消失的情况；高吞吐，上千台机器同时请求锁；低延时，读请求需要读取锁。BigTable作为存储介质，恰好满足这些需求，所以Percolator将数据和锁存储在同一行，特殊的内存列存取锁。访问某一行数据时，Percolator将在一个BigTable行事务中同时对同行的锁进行Read and Modify。</p><p>下图是Percolator在执行事务期间，数据和元数据的布局情况。以银行转账为例，Bob向Joe转7元，该事务从<code>start_ts=7开始，commit_ts=8</code>结束。</p><p><img src="https://pic.imgdb.cn/item/60ce1787844ef46bb231ee35.png" alt></p><p>下图则展示了Percolator在BigTable中的列所展现的作用，其在BigTable中使用了5个列，其中3个与事务相关：</p><ul><li>c:lock：事务产生的锁，未commit的事务会写该列，映射对是{key,start_ts}=&gt;{primary_key}；</li><li>c:write: 已commit的数据信息，映射对是{key,commit_ts}=&gt;{start_ts}；</li><li>c:data: 具体存储的数据，映射对是{key,start_ts} =&gt; {value}；</li></ul><p><img src="https://pic.imgdb.cn/item/60ce1787844ef46bb231ee6d.png" alt></p><p>事务的处理流程则是经典的两阶段提交，首先是<strong>Prewrite</strong>：</p><ul><li>client首先从Oracle获取全局唯一的时间戳start_ts；</li><li>client然后从所有key中选出一个primary，其余作为secondaries，并将所有数据写入请求并行发往存储节点；<ul><li>存储节点首先会进行write-write冲突检查，从c:write获取当前key的最新数据，如果该列中的commit_ts&gt;=start_ts，则返回写冲突错误；</li><li>然后会检查key是否被锁，如果锁了则返回错误；</li><li>向c:lock写入{key, start_ts} =&gt; {primary_key}；</li><li>向c:data写入{key,start_ts} =&gt; {value}；</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// prewrite tries to lock cell w, returning false in case of conflict.</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">Prewrite</span><span class="params">(Write w, Write primary)</span> </span>&#123;</span><br><span class="line">Column c = w.col;</span><br><span class="line">bigtable::Txn T = bigtable::StartRowTransaction(w.row);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (T.Read(w.row, c+<span class="string">"write"</span>, [start_ts_, max])) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">if</span> (T.Read(w.row, c+<span class="string">"lock"</span>, [<span class="number">0</span>, max])) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">T.Write(w.row, c+<span class="string">"data"</span>, start_ts_, w.value);</span><br><span class="line">T.Write(w.row, c+<span class="string">"lock"</span>, start_ts_, &#123;primary.row, primary.col&#125;);</span><br><span class="line"><span class="keyword">return</span> T.Commit();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Prewrite成功后，则进入第二阶段<strong>commit</strong>：</p><ul><li>从Oracle获取全局唯一的时间戳commit_ts；</li><li>向primary key所在节点发起commit请求；</li><li>primary commit成功后则标记为事务成功了，紧接着就是向secondaries发起commit请求（事实上这里primary commit成功后，即可响应client，后续异步往secondaries发起commit即可）；</li><li>存储节点的处理：<ul><li>首先是检查key的lock是否合法；</li><li>往c:write写入{key,commit_ts}=&gt;{start_ts}；</li><li>清除c:lock中内容，释放锁；</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">Commit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">Write primary = write_[<span class="number">0</span>];</span><br><span class="line"><span class="built_in">vector</span>&lt;Write&gt; secondaries(write_.begin() + <span class="number">1</span>, write_.end());</span><br><span class="line"><span class="keyword">if</span> (!Prewrite(primary, primary)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">for</span> (Write w : secondaries)</span><br><span class="line"><span class="keyword">if</span> (!Prewrite(w, primary)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> commit_ts = oracle.GetTimestamp();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Commit primary first.</span></span><br><span class="line">Write p = primary;</span><br><span class="line">bigtable::Txn T = bigtable::StartRowTransaction(p.row);</span><br><span class="line"><span class="keyword">if</span> (!T.Read(p.row, p.col+<span class="string">"lock"</span>, [start_ts_, start_ts_]))</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// aborted while working</span></span><br><span class="line">T.Write(p.row, p.col+<span class="string">"write"</span>, commit_ts, start_ts_); <span class="comment">// Pointer to data written at start_ts_</span></span><br><span class="line">T.Erase(p.row, p.col+<span class="string">"lock"</span>, commit_ts); <span class="comment">// 应该是start_ts_</span></span><br><span class="line"><span class="keyword">if</span>(!T.Commit()) <span class="keyword">return</span> <span class="literal">false</span>;  <span class="comment">// commit point</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Second phase: write our write records for secondary cells.</span></span><br><span class="line"><span class="keyword">for</span> (Write w:secondaries) &#123;</span><br><span class="line">bigtable::write(w.row, w.col+<span class="string">"write"</span>, commit_ts, start_ts_);</span><br><span class="line">bigtable::Erase(w.row, w.col+<span class="string">"lock"</span>, commit_ts);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Percolator的读取操作则相对简单，由于c:write记录了key的commit记录，client读取key的时候会先从c:write找到start_ts_，然后到c:data查找相对应的数据，具体流程：</p><ul><li>检查[0, start_ts_]内是否存在锁，若存在，则意味着有未commit的事务，client则必须进行等待和cleanup操作；</li><li>否则，获取最新的commit记录，从c:write中获取start_ts；</li><li>根据{key, start_ts}从c:data中获取数据；</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">Get</span><span class="params">(Row row, Column c, <span class="built_in">string</span>* value)</span> </span>&#123;</span><br><span class="line"><span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">bigtable::Txn = bigtable::StartRowTransaction(row);</span><br><span class="line"><span class="comment">// Check for locks that signal concurrent writes.</span></span><br><span class="line"><span class="keyword">if</span> (T.Read(row, c+<span class="string">"locks"</span>, [<span class="number">0</span>, start_ts_])) &#123;</span><br><span class="line"><span class="comment">// There is a pending lock; try to clean it and wait</span></span><br><span class="line">BackoffAndMaybeCleanupLock(row, c);</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Find the latest write below our start_timestamp.</span></span><br><span class="line">latest_write = T.Read(row, c+<span class="string">"write"</span>, [<span class="number">0</span>, start_ts_]);</span><br><span class="line"><span class="keyword">if</span>(!latest_write.found()) <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// no data</span></span><br><span class="line"><span class="keyword">int</span> data_ts = latest_write.start_timestamp();</span><br><span class="line">*value = T.Read(row, c+<span class="string">"data"</span>, [data_ts, data_ts]);</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至于事务处理过程中如何应对异常：若commit一个事务时出现了异常，导致前面Prepare阶段的锁留下来，为避免阻塞住后来的事务，Percolator采取lazy的方式清理这些锁，即访问到了这个key才会去处理。</p><p>Prewrite阶段遇到锁冲突会直接返回失败，因此锁的清理是在读阶段进行的。当事务执行过程中commit失败时，事务会留下一个commit point（Primary Key写入c:write了），但可能留下一些锁没有清理。另一个事务发现锁冲突时，会去Primary上查找primary lock是否存在。如果存在，说明前面的事务没有提交，进行roll back；如果不存在，则需要检查c:write是否已经被写入，写入了就说明事务已经被成功提交，此时执行Roll Forward（在secondaries上将c:lock替换成c:write）。BigTable的行级事务避免了数据竞争。</p><h3 id="Timestamps"><a href="#Timestamps" class="headerlink" title="Timestamps"></a>Timestamps</h3><p>时间戳oracle是一个分配严格递增时间戳的服务器，考虑到每个事务需要调用oracle两次，因此oracle需要具备很好的可扩展性。oracle会定期分配一定范围的时间戳，并把该范围的最大值持久化存储，这样如果服务器挂了就直接从上次范围的最大值作为开始值进行分配。为了减少RPC消耗，Percolator的worker会维持一个长连接RPC到oracle，低频批量地获取时间戳。</p><p>事务协议使用严格递增的时间戳，保证了Get操作能看到所有在start_ts之前已提交的写操作。</p><h3 id="Notifications"><a href="#Notifications" class="headerlink" title="Notifications"></a>Notifications</h3><p>Percolator提供了一种方法来触发和运行事务，用户编写的代码即observer会表的变化而触发，observer会被放入Percolator worker中，随着每一个tablet服务器运行。每个observer都会向Percolator注册一个function和它感兴趣的列，一旦这些列发生了变化就会调用function。</p><p>与数据库中的触发器不一样，假设写操作触发了observer，但他们会运行在各自的事务中，产生的结果不是原子的。Percolator提供了一种保证：对于一个被观察列的变化，至多一个observer的事务被提交。反之则不然，对于一个被观察列的多次变化，可能只会触发一次observer事务。</p><p>为了实现通知机制，Percolator为每个被监测的列额外提供一个“acknowledgment”列。包含最近一次observer事务的开始时间戳。当被监测的列发生改变时，Percolator启动一个事务来处理通知，该事务读取被监测列和它对应的acknowledgment列，判断acknowledgment列的时间戳是否在被检测列之前，若是则意味着可以开启observer事务，否则意味着已经有observer被运行了。</p><p>为了实现通知机制，Percolator需要高效找到被观察的脏cell，其在BigTable的locality group维护了一个特殊的“notify”列，表示该cell是否为脏，当一个事务对被监测列进行写入时，同时会写对应的notify cell。每个Percolator的worker指定几个线程负责扫描这些脏cell。 </p><p>Percolator的通知机制主要是异步实现的，当改变发生时，并不是立刻以同步方式调用observer，而是写入一个notify列，等worker线程扫描到才会调用observer。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Percolator的一大特点就是构建在仅支持单行事务的BigTable之上，提供了良好的跨行事务，实现了比较简洁的分布式事务。但其性能本身不够高效，每个work都需要发送大量的RPC（比如获取两次事务timestamp，比如可能读取secondary的lock列是指向primary的，还要多读取一次），虽然论文提到了一些合并RPC，延迟发送，提高并行和增大BatchSize等措施来优化RPC的调用，但Percolator对于写协议本身也要需要多次在BigTable做持久化，读的话则可能遇到由于先写primary再同步到其他参与者导致的锁被持有而等待的问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Percolator&quot;&gt;&lt;a href=&quot;#Percolator&quot; class=&quot;headerlink&quot; title=&quot;Percolator&quot;&gt;&lt;/a&gt;Percolator&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;本文是谷歌的经典论文，介绍了一个对大型数据集做增量
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>《UCB cs294》Required Reading 3</title>
    <link href="http://yoursite.com/2021/05/15/%E3%80%8AUCB-cs294%E3%80%8BRequired-Reading-3/"/>
    <id>http://yoursite.com/2021/05/15/《UCB-cs294》Required-Reading-3/</id>
    <published>2021-05-15T15:41:29.000Z</published>
    <updated>2021-05-15T15:43:47.748Z</updated>
    
    <content type="html"><![CDATA[<h1 id="《UCB-cs294》Required-Reading-3"><a href="#《UCB-cs294》Required-Reading-3" class="headerlink" title="《UCB cs294》Required Reading 3"></a>《UCB cs294》Required Reading 3</h1><h2 id="论文一"><a href="#论文一" class="headerlink" title="论文一"></a>论文一</h2><p>《Hidden Technical Debt in Machine Learning Systems》这篇文章是谷歌基于多年的机器学习系统开发和使用经验总结出来的，着重强调了在机器学习系统中出现的technical debt：</p><ul><li>Complex Models Erode Boundaries</li></ul><p>在一般的软件开发中，人们会使用封装、模块化等抽象手段，但机器学习系统由于其依赖大量外部数据，特征的改变会影响全局。论文提到的解决方法是模型隔离和监测模型中的变化。</p><ul><li>Data Dependencies Cost More than Code Dependencies</li></ul><p>这个主要是将对数据依赖关系的分析成本比通常的代码依赖关系分析要高，一是因为数据依赖关系不够稳定，可能存在把一个输出当成另一个地方外部输入的使用；二是存在不必要的数据依赖。对于这两个问题，论文的解决方法是做数据输入的版本控制和定期检查去除不必要的依赖。</p><ul><li>Feedback Loops</li></ul><p>机器学习系统的一大特征就是他们未来的更新很可能会影响到自身，导致analysis debt的出现，在模型部署之前很难预测模型的行为。Direct Feedback Loops是指模型直接影响自身的特征选择，Hidden Feedback Loops是指系统之间间接影响对方，这种Feedback Loops的问题更加严重。</p><ul><li>ML-System Anti-Patterns</li></ul><p>在实际的机器学习系统中，仅仅一小部分代码是用于学习和预测的，慢慢地，系统中会出现各种系统设计的Anti-Patterns。比如出现大量的机器学习库代码，论文的建议是使用胶水语言封装API；数据准备阶段积攒了更多的输入信号，混杂着各种数据操作；机器学习实验过程中，代码出现了一些不必要的条件分支，导致技债出现；还有就是一些代码的code smell比较差。</p><ul><li>Configuration Debt</li></ul><p>由于机器学习系统和算法比较复杂，大型的ML系统往往依赖大量的配置，因此需要关注配置的可维护性、易读性、需要做code review提交到库中。</p><ul><li>Dealing with Changes in the External World</li></ul><p>这个指的是ML系统与外部世界有较多的交互，外部世界的变化会影响系统、影响模型等。因此需要高效的监控预警配套。</p><ul><li>Other Areas of ML-related Debt</li></ul><p>Data Testing Debt，提供基本的、完整的代码测试；Reproducibility Debt，真实的ML系统由于外部世界的变化、并行学习中的随机等等难以保持严格的可重复性；Process Management Debt，模型的管理问题，真实的系统可能存在数以百计的模型，如何分配资源、控制优先级等很重要；Cultural Debt，文化问题，研究员和系统工程师可能存在沟通不当的情况。</p><h2 id="论文二"><a href="#论文二" class="headerlink" title="论文二"></a>论文二</h2><p>《TFX: A TensorFlow-Based Production-Scale Machine Learning Platform》这篇论文主要介绍了Google开发的一个机器学习平台TFX。TFX最大的特点就是将机器学习所需的各个组件部分集成在一起，提供训练模型、分析验证模型和模型部署的完整工作流，避免了机器学习pipeline各个部分的割裂。</p><h3 id="platform-overview"><a href="#platform-overview" class="headerlink" title="platform overview"></a>platform overview</h3><p>作为一个机器学习平台，不单单只关注机器学习算法，还需要考虑到依赖分布式系统架构促使数据和模型的并行，机器学习工作流便于搭建，拥有集中的仓库跟踪保存训练过的多模型等等。</p><p>TFX的设计主要考虑了以下几点：</p><ul><li>平台能应对多种学习任务，除了选用tensorflow作为核心算法库，还支持数据验证分析和可视化工具、模型验证评估和推断工具等；</li><li>持续训练，TFX考虑支持多种持续训练策略；</li><li>易用的配置与工具；</li><li>生产级别的可靠性与可扩展性；</li></ul><p>基于上述的特点，把多种组建模块集成在一起，就形成了下图的平台。</p><p><img src="https://pic.imgdb.cn/item/609ab7ced1a9ae528fce25e3.png" alt></p><h3 id="DATA-ANALYSIS-TRANSFORMATION-AND-VALIDATION"><a href="#DATA-ANALYSIS-TRANSFORMATION-AND-VALIDATION" class="headerlink" title="DATA ANALYSIS, TRANSFORMATION, AND VALIDATION"></a>DATA ANALYSIS, TRANSFORMATION, AND VALIDATION</h3><p>对于机器学习来说，了解数据并及时发现异常数据是至关重要的，有利于避免下游数据出错。这一章主要讲TFX将数据分析、转换和验证作为独立又相互关联的部分。</p><p>数据分析的时候，需要对输入的数据集进行统计，输出一系列统计数据，如连续型数据需要分位数、直方图等等，离散数据需要top-K值和频率等等。</p><p>数据转换则是对数据进行格式转换，如将特征转换为特定的整数。这里的关键是保证在训练和推断期间确保转换逻辑的一致性。TFX会将任何数据转换导出为经过训练的模型的一部分，从而避免了不一致的问题。</p><p>数据验证则是使用schema来描述数据规范，每个算法团队维护自己的schema，数据验证时可以快速确认数据集的异常情况，如何进行修正，反映出数据的变化情况。</p><h3 id="MODEL-TRAINING"><a href="#MODEL-TRAINING" class="headerlink" title="MODEL TRAINING"></a>MODEL TRAINING</h3><p>TFX的设计一大核心是尽可能流水线地、自动化地完成训练生产模型，支持训练使用Tensorflow配置的所有模型。TFX使用了warm starting来在模型质量和模型时效性之间达到一个平衡，这是迁移学习使用的技术，讲一个训练好的基准模型应用另一个场景。</p><p>论文另外一点就是TFX用了定义和描述模型的API——model specification API，通过对Tensorflow的封装减少代码冗余，提高开发速度。</p><h3 id="MODEL-EVALUATION-AND-VALIDATION"><a href="#MODEL-EVALUATION-AND-VALIDATION" class="headerlink" title="MODEL EVALUATION AND VALIDATION"></a>MODEL EVALUATION AND VALIDATION</h3><p>模型的评估是模型上线前验证模型有效性的关键步骤，TFX对于好模型的定义主要是：<strong>safe to serve</strong>和<strong>the desired prediction quality</strong>，前者关心的是模型完整性，不会使得推断服务crash，资源使用少，后者则主要是模型预测准确率。</p><p>TFX一方面也使用了各种准确率标准来做AB Test，根据不同的产品团队要求提供告警配置，另一方面也支持对数据集根据feature做slice切分，帮助更好地评估模型在不同feature伤的表现。</p><h3 id="MODEL-SERVING"><a href="#MODEL-SERVING" class="headerlink" title="MODEL SERVING"></a>MODEL SERVING</h3><p>最后则是模型服务，TFX主要依赖Tensorflow serving去做这个事情，通过多用户隔离和快速的训练数据反序列化来满足系统的低时延和高性能要求，总的来说提供了一套工业级的模型上线推断服务。</p><h2 id="论文三"><a href="#论文三" class="headerlink" title="论文三"></a>论文三</h2><p>《Towards Unified Data and Lifecycle Management for Deep Learning》这篇论文主要关注了深度学习中数据和生命周期管理系统的实现，提出了一个modelHub系统，包括了三个部分，一种DSL来帮助泛化对模型的探索、查询，一种新的模型版本管理系统（Dlv）和一种读参数优化的参数归档存储系统（PAS）。</p><p><img src="https://pic.imgdb.cn/item/609febea6ae4f77d357d697a.png" alt></p><p>ModelHub主要分为local组件和远程组件，local functionality包括了一些DNN系统与本地计算机集群的集成，remote functionality则是不同用户组共享模型与其版本。</p><p>DLV是一种通过命令行工具的版本控制系统，可以用来与其他本地或者远程组件进行交互，替代了传统的git/svn可以方便其更好地描述查询建模过程中生成的artifacts内部结构。另外通过DQL模块可以帮助研究员开发新模型。Model Learning模块本质是特定DNN系统的wrapper。</p><p>至于本地仓库的PAS则是用来存储大量的模型学习参数，PAS的目标是在不影响查询性能的情况下，尽可能维护大量学习的模型信息。其中一大特点是使用了一种新的近似模型评估技术，适用于分段存储PAS。由于浮点算数表示中浮点数具备高熵，难以压缩，PAS提供了按字节分割的浮点矩阵存储方案，通过分割高阶和低阶尾数位，浮点数矩阵按块存储，第一个块由8个高位组成，其余的每个块被分割为一个字节，由于高阶位具有低熵，能更好地做压缩。</p><p>这篇论文描述了如何通过ModelHub去解决一些在管理和调整深度学习模型中的关键数据管理挑战：</p><ul><li>通过调整网络结构和超参数，更容易优化潜在的模型效果；</li><li>减少跟踪模型的负担；</li><li>在不影响查询和检索性能的前提下，尽可能多地存储大量模型和构造快照；</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;《UCB-cs294》Required-Reading-3&quot;&gt;&lt;a href=&quot;#《UCB-cs294》Required-Reading-3&quot; class=&quot;headerlink&quot; title=&quot;《UCB cs294》Required Reading 3&quot;&gt;&lt;/a
      
    
    </summary>
    
    
      <category term="AiSys" scheme="http://yoursite.com/tags/AiSys/"/>
    
  </entry>
  
  <entry>
    <title>C++ atomics, from basic to advanced</title>
    <link href="http://yoursite.com/2021/05/12/C-atomics-from-basic-to-advanced/"/>
    <id>http://yoursite.com/2021/05/12/C-atomics-from-basic-to-advanced/</id>
    <published>2021-05-11T17:00:54.000Z</published>
    <updated>2021-05-11T17:01:19.589Z</updated>
    
    <content type="html"><![CDATA[<h1 id="C-atomics-from-basic-to-advanced"><a href="#C-atomics-from-basic-to-advanced" class="headerlink" title="C++ atomics, from basic to advanced"></a>C++ atomics, from basic to advanced</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在C++11中引入了对多线程的支持，同时也带来了关于mutex和atomic相关的一些列标准，定义了memory model。这篇文章将关注C++11带来的一个无锁编程工具——atomics。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="无锁编程"><a href="#无锁编程" class="headerlink" title="无锁编程"></a>无锁编程</h3><p>在文章开始之前，首先来关注一些无锁编程这个概念（lock free——不使用锁来保持代码同步）。一般人在使用无锁编程或者了解这个概念之前，会先入为主地认为无锁编程性能更快，相对使用锁来同步拥有更好的运行速度。</p><p>实际上，无论是lock free还是更严格的wait free都没有直接跟运行速度有直接关系，他们关联的是“steps”，但在程序运行过程中“step”的运行时间不一定是一样的。无锁编程的优势在于通过减少阻塞和等待来提高并发的可能性，消除race condition、死锁等潜在危机。因此在使用无锁编程之前应该先测试程序，观察代码的算法逻辑是否有问题。</p><p>接下来我们开始了解C++的原子操作。</p><h3 id="C-atomics"><a href="#C-atomics" class="headerlink" title="C++ atomics"></a>C++ atomics</h3><h4 id="何谓原子操作"><a href="#何谓原子操作" class="headerlink" title="何谓原子操作"></a>何谓原子操作</h4><p>原子操作是一种以单个事务来执行的操作，这是一个“不可再分且不可并行的”操作，其他线程只能看到操作完成前或者完成后的资源状态，不存在中间状态可视。</p><p>从底层来看，原子操作是一些硬件指令，其原子性是由硬件保证的，C++11对原子操作抽象出统一的接口，避免使用时嵌入平台相关的代码来支持跨平台使用。</p><p>先来看看如果多线程中没有原子操作会发生什么情况：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// ===============</span></span><br><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">int</span> tmp = x; <span class="comment">// 0</span></span><br><span class="line">  ++tmp; <span class="comment">// 1</span></span><br><span class="line">  x = tmp; <span class="comment">// 1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">int</span> tmp = x; <span class="comment">// 0</span></span><br><span class="line">  ++tmp; <span class="comment">// 1</span></span><br><span class="line">  x = tmp; <span class="comment">// 1!!! What!!!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是一个很典型的Read-modify-write的递增场景，多线程环境下就会出现data race。为什么会这样，以一个简易的计算机架构图来举例，这里存在三级缓存，变量在内存中初始化好为0，由于这里没有同步机制，每个CPU都从主存中将变量取出来（此时变量都是0），在寄存器中进行递增，最后将递增后的值1写回内存。</p><p><img src="https://pic.imgdb.cn/item/609ab7ced1a9ae528fce263b.png" alt></p><p>那么我们怎么在C++中进行数据共享呢？在C++11之前是没有标准的线程库的，在C++11之后引入了std::atomic模版类来提供原子操作。一个简单例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; x(<span class="number">0</span>); <span class="comment">// Not support std::atomic&lt;int&gt; x = 0</span></span><br><span class="line">++x; <span class="comment">// now atomic operation</span></span><br></pre></td></tr></table></figure><h4 id="std-atomic的使用"><a href="#std-atomic的使用" class="headerlink" title="std::atomic的使用"></a>std::atomic的使用</h4><p>std::atomic是一个模版，那么哪些类型可以实例画该模版呢？按照标准的说法，需要是Trivially Copyable的类型，简单来说就是满足三个条件：</p><ul><li>连续的内存；</li><li>拷贝对象意味着按bit拷贝（memcpy）；</li><li>没有虚函数；</li></ul><p>用代码来表达则是自定义结构满足下面5个条件：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::is_trivially_copyable&lt;T&gt;::value</span><br><span class="line"><span class="built_in">std</span>::is_copy_constructible&lt;T&gt;::value</span><br><span class="line"><span class="built_in">std</span>::is_move_constructible&lt;T&gt;::value</span><br><span class="line"><span class="built_in">std</span>::is_copy_assignable&lt;T&gt;::value</span><br><span class="line"><span class="built_in">std</span>::is_move_assignable&lt;T&gt;::value</span><br></pre></td></tr></table></figure><p>那么对于一个合法的<code>std::atomic&lt;T&gt;</code> 类型来说，它能进行哪些操作？一个是assignment，则读写操作；另一个则是特定的原子操作和跟类型T相关的其他操作。下面几种操作要么编译失败、要么是非原子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; x&#123;<span class="number">0</span>&#125;;</span><br><span class="line">x *= <span class="number">2</span>; <span class="comment">// compile error</span></span><br><span class="line">x = x + <span class="number">1</span>; <span class="comment">// Not atomic: Atomic read followed by atomic write</span></span><br><span class="line">x = x * <span class="number">2</span>; <span class="comment">// Not atomic: Atomic read followed by atomic write</span></span><br></pre></td></tr></table></figure><p>还有一个就是原子自增不支持浮点数。其他的原子操作包括CAS、exchange等等；</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;T&gt; x;</span><br><span class="line">T y = x.load(); <span class="comment">// same sa T y = x</span></span><br><span class="line">x.store(y); <span class="comment">// same as x = y</span></span><br><span class="line">T z = x.exchange(y); <span class="comment">// Atomically: z = x; x = y;</span></span><br><span class="line"><span class="comment">// if x == y, make x=z and return true</span></span><br><span class="line"><span class="comment">// Otherwise, set y=x and return false</span></span><br><span class="line"><span class="comment">// 还有一个compare_exchange_week，x == y也可能会失败，主要是因为某些平台会对锁有类似超时释放的操作，满足其高效调度</span></span><br><span class="line"><span class="keyword">bool</span> success = x.compare_exchange_strong(y, z);</span><br></pre></td></tr></table></figure><p>这里重点看一下CAS的使用，CAS在大多数无锁算法中都有应用，除了原子自增外，CAS还支持递增浮点数，进行乘法运算：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; x&#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> x0 = x;</span><br><span class="line"><span class="keyword">while</span> (!x.compare_exchange_strong(x0, x0+<span class="number">1</span>)) &#123;&#125;</span><br><span class="line"><span class="keyword">while</span> (!x.compare_exchange_strong(x0, x0*<span class="number">2</span>)) &#123;&#125;</span><br><span class="line"><span class="comment">// fetch_xxx() == some operators</span></span><br><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; x&#123;<span class="number">0</span>&#125;;</span><br><span class="line">x.fetch_add(y); <span class="comment">// same as x += y</span></span><br><span class="line"><span class="keyword">int</span> z = x.fetch_add(y); <span class="comment">// same as z = (x += y) - y;</span></span><br></pre></td></tr></table></figure><h4 id="std-atomic与无锁的关系"><a href="#std-atomic与无锁的关系" class="headerlink" title="std::atomic与无锁的关系"></a>std::atomic与无锁的关系</h4><p>这里有一个关键的信息：std::atomic并不意味着一定是无锁的；首先来看下面的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> x; <span class="comment">// lock free</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span> &#123;</span> <span class="keyword">long</span> x; &#125;; <span class="comment">// lock free</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span> &#123;</span> <span class="keyword">long</span> x; <span class="keyword">long</span> y; &#125;; <span class="comment">// run-time and platfrom dependent. x86 is lock free</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">C</span> &#123;</span> <span class="keyword">long</span> x; <span class="keyword">long</span> y; <span class="keyword">long</span> z; &#125;; <span class="comment">// &gt; 16 bytes. not lock free</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">D</span> &#123;</span> <span class="keyword">long</span> x; <span class="keyword">int</span> y; &#125;; <span class="comment">// alignment 16 bytes. lock free</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">E</span> &#123;</span> <span class="keyword">long</span> x; <span class="keyword">int</span> y; &#125;; <span class="comment">// 12 bytes. not lock free</span></span><br></pre></td></tr></table></figure><p>判断atomc是否无锁可以通过一个成员函数<code>std::atomic&lt;T&gt;::is_lock_free()</code>，这是一个运行时的判断（C++17提供了编译时判断<code>constexpr is_always_lock_free()</code>），之所以会出现无锁不确定的情况主要是因为对齐alignment。</p><p>假设atomic是无锁的，但也有可能出现两个atomic变量互相等待的情况，假设存在这样的场景，两个atomic变量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; x[N];</span><br><span class="line"><span class="comment">// thread 1</span></span><br><span class="line">++x[<span class="number">0</span>];</span><br><span class="line"><span class="comment">// thread 2</span></span><br><span class="line">++x[<span class="number">1</span>];</span><br></pre></td></tr></table></figure><p>这种情况下就会出现两个atomic变量互相等待的可能性，主要是因为这两个操作都是在同一个cache line，都从主存到CPU来回写入，因为两个CPU可能互斥访问同一个cache line，这就是所谓的false sharing。一个提高性能解决这个问题的方式是将每个线程的数据对齐到充满整个cache line。（NUMA机器上，可能是整个page）</p><p><img src="https://pic.imgdb.cn/item/609ab7ced1a9ae528fce268d.png" alt></p><h4 id="memory-barrier"><a href="#memory-barrier" class="headerlink" title="memory barrier"></a>memory barrier</h4><p>memory barrier控制着某个CPU对内存的修改被另一个CPU可见的方式，这是一个对所有CPU的全局控制。这是通过硬件实现，确定指令的特定操作顺序。简单来说，就是CPU在执行指令的时候不一定按照编写顺序来执行，从而挖掘更多并行能力。</p><p>如果仔细观察std::atomic相关操作的参数，会发现其还接受一个memory_order的枚举作为参数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">enum</span> memory_order &#123;</span><br><span class="line">memory_order_relaxed,</span><br><span class="line">memory_order_consume,</span><br><span class="line">memory_order_acquire,</span><br><span class="line">memory_order_release,</span><br><span class="line">memory_order_acq_rel,</span><br><span class="line">memory_order_seq_cst</span><br><span class="line">&#125; memory_order;</span><br></pre></td></tr></table></figure><ul><li>memory_order_relaxed：不对执行顺序做任何保证，即该原子操作指令可以任由编译器重排或者CPU乱序执行；</li><li>memory_order_acquire：当前线程里，所有在该原子操作之后的读操作，都不能重排到该原子操作指令之前执行。原子操作指令先读；</li><li>memory_order_release：当前线程里，所有在该原子操作之前的写操作，都不能重排到该原子操作指令之后执行。原子操作最后写；</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Thread1</span><span class="params">(<span class="keyword">int</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> t=<span class="number">1</span>;</span><br><span class="line">    a.store(t,memory_order_relaxed);</span><br><span class="line">    b.store(<span class="number">2</span>,memory_order_release); <span class="comment">// a必须在b之前完成写入</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Thread2</span><span class="params">(<span class="keyword">int</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(b.load(memory_order_acquire)!=<span class="number">2</span>); <span class="comment">// b必须在a之前读 </span></span><br><span class="line">    <span class="built_in">cout</span>＜＜a.load(memory_order_relaxed)＜＜<span class="built_in">endl</span>;<span class="comment">//输出1. </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>memory_order_acq_rel：包含memory_order_acquire和memory_order_release两个标志；</li><li>memory_order_seq_cst：默认标志。顺序一致，确保代码在线程中的执行顺序与顺序看到的代码顺序一致，禁止重拍指令和乱序执行；</li></ul><p>改变memory order参数，在一定程度上可能会提高程序的性能，从代码中表达出程序员的意图。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>C++的atomic操作在一定条件下能很好提高程序的性能，并且也提高了易用性，但也存在很多容易踩坑的地方，因此在使用前仍然需要做详细的设计。使用atomic的时机也需要细细斟酌，对于不适用的地方使用无锁或者atomic操作可能收效甚微。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.infoq.com/news/2014/10/cpp-lock-free-programming/" target="_blank" rel="noopener">https://www.infoq.com/news/2014/10/cpp-lock-free-programming/</a></p><p><a href="https://www.youtube.com/watch?v=ZQFzMfHIxng" target="_blank" rel="noopener">https://www.youtube.com/watch?v=ZQFzMfHIxng</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;C-atomics-from-basic-to-advanced&quot;&gt;&lt;a href=&quot;#C-atomics-from-basic-to-advanced&quot; class=&quot;headerlink&quot; title=&quot;C++ atomics, from basic to a
      
    
    </summary>
    
    
      <category term="C++" scheme="http://yoursite.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Macro Free in C++</title>
    <link href="http://yoursite.com/2021/04/19/Macro-Free-in-C/"/>
    <id>http://yoursite.com/2021/04/19/Macro-Free-in-C/</id>
    <published>2021-04-18T16:43:30.000Z</published>
    <updated>2021-04-18T16:43:53.781Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Macro-Free-In-Cpp"><a href="#Macro-Free-In-Cpp" class="headerlink" title="Macro Free In Cpp"></a>Macro Free In Cpp</h1><blockquote><p>One of C++’s aims is to make C’s preprocessor redundant because I consider its actions inherently error prone</p></blockquote><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>C预处理器本质是一个文本替换工具，用来在实际编译之前进行一定的预处理操作，一般情况下#开头的预处理操作并不认为是语言本身的一部分，因为编译器永远看不到这些宏定义符号。</p><p>以C++来说，用宏的目的并不是出于性能的缘由，更多的只是为了减少重复的代码和进行条件编译。随着modern cpp的发展，越来越的新特性加入使得对宏的使用依赖进一步降低。本文将关注如何使用C++新特性替换C预处理程序。</p><h2 id="如何替代宏的使用"><a href="#如何替代宏的使用" class="headerlink" title="如何替代宏的使用"></a>如何替代宏的使用</h2><ol><li>表达式别名</li></ol><p>有一些宏定义会用在表达式别名，替换后的文本会被识别为C++表达式，对于这种情况比较简单的是使用常量表达式或者lambda替换宏，</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> PI 3.14</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SEVEN 3 + 4</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FILENAME <span class="meta-string">"header.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SUM a + b</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">summer</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> a = <span class="number">1</span>, b=<span class="number">2</span>;</span><br><span class="line">  <span class="keyword">int</span> c = SUM;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ========================&gt;&gt;&gt;</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="keyword">auto</span> PI = <span class="number">3.14</span>;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="keyword">auto</span> SEVEN = <span class="number">3</span> + <span class="number">4</span>;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="keyword">auto</span> FILENAME = <span class="string">"header.h"</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">summer</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> a = <span class="number">1</span>, b=<span class="number">2</span>;</span><br><span class="line">  <span class="keyword">auto</span> SUM = [&amp;a, &amp;b]() &#123; <span class="keyword">return</span> a + b; &#125;;</span><br><span class="line">  <span class="keyword">int</span> c = SUM();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>类型别名</li></ol><p>类型别名是一个类似于对象的宏，其替换文本可以识别为C ++类型表达式。对于这种，可以使用C++的别名声明来替换：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> A T</span></span><br><span class="line"><span class="comment">// ========================&gt;&gt;&gt;</span></span><br><span class="line"><span class="keyword">using</span> A = T;</span><br></pre></td></tr></table></figure><ol start="3"><li>参数表达式</li></ol><p>参数表达式是一种类似于函数的宏，替换文本后会扩展为表达式或语句。对于这种使用，C++中的最佳实践是使用内联模版函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MIN(A, B) ((A) &lt; (B) ? (A) : (B))</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ASSIGN(A, B) &#123; B = A; &#125;</span></span><br><span class="line"><span class="comment">// ========================&gt;&gt;&gt;</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2&gt;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">auto</span> <span class="title">MIN</span><span class="params">(T1&amp;&amp; A, T2&amp;&amp; B)</span></span></span><br><span class="line">  -&gt; decltype(((A) &lt; (B) ? (A) : (B)))</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">return</span> ((A) &lt; (B) ? (A) : (B));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2&gt;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">ASSIGN</span><span class="params">(T1&amp;&amp; A, T2&amp;&amp; B)</span> </span>&#123;</span><br><span class="line">  B = A;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里引入了内联，自动的推导类型和完美转发等modern c++的特性。完美转发使得调用方可以根据需要决定参数传递的类型。</p><ol start="4"><li>参数化类型别名</li></ol><p>这种其实就是模版别名，在C++11之前需要用宏去实现。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> AliasMap(T) std::map<span class="meta-string">&lt;std::string, T&gt;;</span></span></span><br><span class="line"><span class="comment">// ========================&gt;&gt;&gt;</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">using</span> AliasMap = <span class="built_in">std</span>::<span class="built_in">map</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>, T&gt;;</span><br></pre></td></tr></table></figure><ol start="5"><li>条件编译</li></ol><p>目前绝大多数开源的C++项目都会依赖宏来进行条件编译，其本质意义是通过定义宏与否来改变某个定义/声明。</p><p>比如存在一个绘制三角形的API，但其具体实现会根据操作系统而变化，通过预处理器就可以很好地实现类似的兼容：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">draw_triangle</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="meta">#<span class="meta-keyword">if</span> _WIN32</span></span><br><span class="line">    <span class="comment">// Windows triangle drawing code here </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="comment">// Linux triangle drawing code here</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中某个分支的代码会在进行编译之前被去掉，这样编译时就不会出现API未定义的错误。</p><p>在C++17中有了新的语法特性<code>if constexpr</code>，我们可以用来替代一部分<code>#if … #else</code>的使用。以下面的使用为例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_sth</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="meta">#<span class="meta-keyword">if</span> DEBUG_MODE</span></span><br><span class="line">    <span class="built_in">log</span>();</span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="comment">// …</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ========================&gt;&gt;&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_sth</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(DEBUG_MODE)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">log</span>(); </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="comment">// …</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用<code>if constexpr</code>的好处是其只会检查语法错误，像宏那样的使用方式，一旦<code>DEBUG_MODE</code>出现typo的错误，编译器是无法准确辨识的。</p><p>当然<code>if constexpr</code>的使用也是有其不足之处的，以上面的<code>draw_triangle</code>函数为例，即便某个条件分支不会被使用，你仍然需要有相关冗余的声明。所以对于这种情况，个人建议还是不需要使用<code>if constexpr</code>替代宏。</p><ol start="6"><li>源码位置</li></ol><p>目前几乎所有的断言或者宏会用到宏，比如需要使用<code>__LINE__, __FILE__, __func__</code> 等定位断言的位置，又或者需要断言开关等等。</p><p>要想替代对这些宏的使用则需要用上C++20的<code>std::source_location</code>，该类可以表示关于源码的具体信息，例如文件名、行号以及函数名。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string_view&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;source_location&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">log</span><span class="params">(<span class="built_in">std</span>::string_view message,</span></span></span><br><span class="line"><span class="function"><span class="params">         <span class="keyword">const</span> <span class="built_in">std</span>::source_location&amp; location = <span class="built_in">std</span>::source_location::current())</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"info:"</span></span><br><span class="line">      &lt;&lt; __FILE__ &lt;&lt; <span class="string">':'</span></span><br><span class="line">              &lt;&lt; __LINE__ &lt;&lt; <span class="string">' '</span></span><br><span class="line">              &lt;&lt; message &lt;&lt; <span class="string">'\n'</span>;</span><br><span class="line">  <span class="comment">// ========================&gt;&gt;&gt;</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"info:"</span></span><br><span class="line">              &lt;&lt; location.file_name() &lt;&lt; <span class="string">':'</span></span><br><span class="line">              &lt;&lt; location.line() &lt;&lt; <span class="string">' '</span></span><br><span class="line">              &lt;&lt; message &lt;&lt; <span class="string">'\n'</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这里提供了一些更“现代”的C++写法来替换不够安全的、使用了宏定义的老式代码，事实上C++的发展过程中一直在提出一些减少预处理宏使用依赖的方案。但从目前来看，还是有不少预处理使用无法替换，即便如此，个人认为适当使用宏和合适的，其AST的生成功能是非常强大的工具，并且某种情况下能使得代码更加易读。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>《cppcon 2019》——<a href="https://www.youtube.com/watch?v=c6NkeF1eChs" target="_blank" rel="noopener">https://www.youtube.com/watch?v=c6NkeF1eChs</a></li><li>《Rejuvenating C++ Programs through Demacrofication》——<a href="https://www.stroustrup.com/icsm-2012-demacro.pdf" target="_blank" rel="noopener">https://www.stroustrup.com/icsm-2012-demacro.pdf</a></li><li>《if statement》——<a href="https://en.cppreference.com/w/cpp/language/if" target="_blank" rel="noopener">https://en.cppreference.com/w/cpp/language/if</a></li><li>《The year is 2017 - Is the preprocessor still needed in C++?》——<a href="https://foonathan.net/2017/05/preprocessor/" target="_blank" rel="noopener">https://foonathan.net/2017/05/preprocessor/</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Macro-Free-In-Cpp&quot;&gt;&lt;a href=&quot;#Macro-Free-In-Cpp&quot; class=&quot;headerlink&quot; title=&quot;Macro Free In Cpp&quot;&gt;&lt;/a&gt;Macro Free In Cpp&lt;/h1&gt;&lt;blockquote&gt;

      
    
    </summary>
    
    
      <category term="C++" scheme="http://yoursite.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>《UCB cs294》Required Reading 2</title>
    <link href="http://yoursite.com/2021/04/14/%E3%80%8AUCB-cs294%E3%80%8BRequired-Reading-2/"/>
    <id>http://yoursite.com/2021/04/14/《UCB-cs294》Required-Reading-2/</id>
    <published>2021-04-13T16:16:18.000Z</published>
    <updated>2021-04-13T16:17:45.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="《UCB-AI-Sys-cs294》Required-Reading-2"><a href="#《UCB-AI-Sys-cs294》Required-Reading-2" class="headerlink" title="《UCB AI-Sys cs294》Required Reading 2"></a>《UCB AI-Sys cs294》Required Reading 2</h1><h2 id="论文一"><a href="#论文一" class="headerlink" title="论文一"></a>论文一</h2><p>课程推荐的第一篇文章《SysML: The New Frontier of Machine Learning Systems》，这其实一个会议的白皮书，主要的研究方向是设计实现一类系统，来满足支持部署机器学习模型，这是一个计算机系统和机器学习交叉的会议。</p><p>白皮书里将机器学习系统遇到的问题分为两种：一种是高层次的问题，主要解决的是算法、接口的设计实现；另一种则是低层次问题，主要关注的是硬件、调度等底层优化。该文也仔细分析了机器学习系统中遇到的瓶颈，比如部署相关的设计、成本问题以及实用性是否合适。</p><h2 id="论文二"><a href="#论文二" class="headerlink" title="论文二"></a>论文二</h2><p>第二篇论文是《A Few Useful Things to Know About Machine Learning》，这是一片机器学习领域的经典论文，总结了机器学习相关的12个重点实践，并以分类器来举例。</p><ol><li>Learning = Representation + Evaluation + Optimization</li></ol><p>所有的机器学习算法都是由三个部分组成：</p><ul><li>Representation：表现数据的方式，比如用距离表现数据的knn、svm，用数表现数据的决策树；</li><li>Evaluation：用来评估分类器好坏的函数；</li><li>Optimization：用来搜索得分最高分类器的方法；</li></ul><ol start="2"><li>It’s Generalization that Counts</li></ol><p>泛化能力是很重要的，在使用分类器数据时，需要留出部分数据来做测试，避免过拟合。</p><ol start="3"><li>Data Alone Is Not Enough</li></ol><p>将泛化能力作为一个指标，仅仅有数据是不够的，还需要大量的编程工作，例如选择合适的模型，合适的评估函数、损失函数。</p><ol start="4"><li>Overfitting Has Many Faces</li></ol><p>过拟合有很多种，主要需要关注的是偏差和方差，偏差是指模型往着相同的错误方向训练，方差则是模型有学习随机信号的倾向。解决过拟合的方法一般有交叉验证、增加正则化项、进行类似卡方检验的统计显著性检验。</p><ol start="5"><li>Intuition Fails in High Dimensions</li></ol><p>一般来说，特征维度越高，就更好表达数据，但也可以引发curse of dimensionality，即样本数量相对不足，难以覆盖其输入空间，并且也难以从直觉上找出不同类别样本之间的合理边界，最终导致bias和variance的增加。</p><ol start="6"><li>Theoretical Guarantees Are Not What They Seem</li></ol><p>机器学习论文中充斥着理论保证，其存在的意义不仅在于作为评断实际决策的标准，还是设计算法的来源动力。但机器学习是一个复杂的工程，理论上可行不代表实践也是可行的。</p><ol start="7"><li>Feature Engineering Is The Key</li></ol><p>这一点主要是将特征工程的重要性，机器学习不单单是构建数据跑一次就足够了，还需要有分析结果、根据结果修改数据集的迭代过程。</p><ol start="8"><li>More Data Beats a Cleverer Algorithm</li></ol><p>数据量非常重要，数据量的增多会导致某些模型的表征能力也随之增强。</p><ol start="9"><li>Learn Many Models, Not Just One</li></ol><p>机器学习中每个模型都有其适用范围，因此模型的集成如bagging、boosting、stacking等算法就会得到很好的结果。</p><ol start="10"><li>Simplicity Does Not Imply Accuracy</li></ol><p>这里主要是Occam’s razor的一个修正，即简单的模型不一定就能很好避免过拟合或者得到很好的效果。</p><ol start="11"><li>Representable Does Not Imply Learnable</li></ol><p>机器学习具备局限性，不是所有的模型都可以学习的。另外，如果评估函数在假设空间内具备多个局部最优点，模型可能会找不到最优函数。</p><ol start="12"><li>Correlation Does Not Imply Causation</li></ol><p>机器学习只能发觉特征的相关性，但相关性并不等于因果性。</p><h2 id="论文三"><a href="#论文三" class="headerlink" title="论文三"></a>论文三</h2><p>第三篇文章《A Berkeley View of Systems Challenges for AI》是伯克利从计算机系统对机器学习的支持中，总结出来的一篇文章。</p><p>该文章将AI飞速发展的原因归结为：大数据、高扩展性的计算机系统和开源软件技术的流行。</p><p>文章还提出了机器学习相关的趋势与挑战：</p><ol><li>Mission-critical AI：人工智能开始设计一些与人类生命安全相关的领域，需要为这些机器学习任务设计更加稳定安全的决策；</li><li>Personalized AI：提供更加个性化的人工智能系统，同时需要注意用户隐私安全；</li><li>AI across organizations：每个机构、企业都有自己独特的数据，如何提供数据共享的机制，支持跨组织的人工智能系统，也是一个需要注意的挑战；</li><li>AI demands outpacing the Moore’s Law：后摩尔定律时期的AI发展需要更加关注与人工智能适配的硬件架构与系统；</li></ol><p>接下来的介绍就是关于解决上述挑战亟需深入研究的方向：</p><ol><li>Acting in dynamic environments：动态环境下的技术表现，人工智能需要在复杂性动态性更强的环境工作，能够应对突发的、不可预测的事件，并快速做出响应。这包括了Continual learning、Reinforcement learninig等系统的构建；作出更鲁棒的决策（Robust decisions）和可解释的决策（Explainable decisions）</li><li>Secure AI：这里的安全分为两个部分，一是攻击影响系统作出决策的正确性、而是攻击者获取AI训练的影响数据、破解AI加密模型。这种方向包括了构建 Secure enclaves，提供一个安全的硬件执行环境；进行对抗学习避免推理阶段和训练阶段引入了恶意的数据；构建更安全的共享数据系统；</li><li>AI-specic architectures：随着AI的发展，硬件系统架构的迭代显得越来越来重要。这包括了 Domain specic hardware，设计专用的硬件架构来提升系统性能和安全能力；Composable AI systems，为AI系统做定制的的模块化、组件化，进行模型的组合、操作行为的组合；Cloud-edge systems，设计合适的连接云端与边缘设备的AI系统，降低边缘设备的延时，充分利用云端的能力来提供更复杂的计算模型和高效的决策。</li></ol><p>下图就是上面四大趋势与九大研究方向的关联关系：</p><p><img src="https://img.imgdb.cn/item/6075c41e8322e6675cebd742.png" alt></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这是这个课程的week2内容，主要是介绍了一些机器学习系统的研究方法和关注的趋势挑战。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;《UCB-AI-Sys-cs294》Required-Reading-2&quot;&gt;&lt;a href=&quot;#《UCB-AI-Sys-cs294》Required-Reading-2&quot; class=&quot;headerlink&quot; title=&quot;《UCB AI-Sys cs294》Re
      
    
    </summary>
    
    
      <category term="AiSys" scheme="http://yoursite.com/tags/AiSys/"/>
    
  </entry>
  
  <entry>
    <title>Paxos Made Simple——论文阅读</title>
    <link href="http://yoursite.com/2021/03/20/Paxos-Made-Simple%E2%80%94%E2%80%94%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <id>http://yoursite.com/2021/03/20/Paxos-Made-Simple——论文阅读/</id>
    <published>2021-03-20T15:36:18.000Z</published>
    <updated>2021-03-20T15:36:48.577Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Paxos-Made-Simple"><a href="#Paxos-Made-Simple" class="headerlink" title="Paxos Made Simple"></a>Paxos Made Simple</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Paxos——一个用于实现容错的分布式系统算法，核心是一个一致性算法——“synod”算法。基本上是根据一个一致性算法所必需满足的条件而呈现出来的，完整的Paxos算法会通过作为应用到使用状态机的分布式系统中的一致性实现部分来得出。</p><h2 id="The-Consensus-Algorithm"><a href="#The-Consensus-Algorithm" class="headerlink" title="The Consensus Algorithm"></a>The Consensus Algorithm</h2><h3 id="The-Problem"><a href="#The-Problem" class="headerlink" title="The Problem"></a>The Problem</h3><p>假设存在一个多进程集合，里面每个进程都可以发出提案，那么一致性算法需要保证一个值能够被选定，而且一旦一个值被选定，所有进程都需要能够获知选定值。</p><p>一致性safety的要求就是：</p><ul><li>只有被提出的值能够被选定；</li><li>只能有一个选定值；</li><li>只有一致同意该值，才能周知给集合里的所有进程；</li></ul><p>这里主要关注算法的safety，而不会明确要求liveness。</p><p>在该一致性算法中，有三种角色：proposers，acceptors和learners，实际实现中，一个独立的进程可以充当不止一种角色。论文的假设是基于传统的异步模型，而不是拜占庭问题模型。</p><h3 id="Choosing-a-Value"><a href="#Choosing-a-Value" class="headerlink" title="Choosing a Value"></a>Choosing a Value</h3><p>该算法在提案过程主要包括下面几个步骤</p><p>对于proposer：</p><ul><li>proposer选择一个新的提案编号n，然后向acceptors集合的每个成员发送请求，要求acceptors对请求作出响应：<ul><li>a. 一个承诺，保证不再通过任何编号小于n的提案；</li><li>b. 如果接受过其他提案的话，需要返回当前通过的编号小于n的最大编号提案；</li></ul></li><li>如果proposer从大多数acceptors收到期待的响应，则可以接着提议一个编号为n并且值为v的提案，这里的v要么是自由选择一个值（所有的响应都没接收过任何的提案），要么是从上面b响应中选出最大编号的提案的值；</li></ul><p>对于acceptor，acceptors可能会收到prepare请求和accept请求，acceptors可以忽略任何请求而不用担心算法的正确性。至于acceptors在什么情况下可以对一个请求作出回应呢，对于prepare请求可以在任何时候做出响应，而对accept请求，只要它没响应过任何编号大于n的prepare请求， acceptor就可以接受编号为n的提案。</p><p>总结起来，acceptor和proposer的算法操作可以分为两个阶段：</p><ul><li>阶段一</li></ul><p>a. proposer提出一个编号为n的提案，向大多数acceptors发送一个带有编号为n的prepare请求；</p><p>b. 如果acceptors收到了该请求，并且n比它之前响应过的prepare请求编号都大，那么它就会对该请求作出响应，返回一个保证不再通过任何编号小于n的提案的承诺，以及如果存在的话，接受过的最大编号的提案；</p><ul><li>阶段二</li></ul><p>a. 如果proposer从大多数acceptors收到响应，则会提出一个accept请求，内容包括了编号n和值为v，其中v要么是自由选择一个的值，要么是从响应中选出最大编号的提案的值；</p><p>b. 如果acceptors收到该accept请求，并且之前没有响应过大于编号n的prepare请求，那么它就会对接受该请求；</p><h3 id="Learning-a-Chosen-Value"><a href="#Learning-a-Chosen-Value" class="headerlink" title="Learning a Chosen Value"></a>Learning a Chosen Value</h3><p>为了获取到选定的值，learner必须要找出某个以及被大多数acceptors接受的提案。如果是每个acceptors都将通过的提案告知所有的learners，那么通信次数等于两者个数乘积；如果是只告诉一个特定learner，虽然通信次数减少了，但可靠行也降低了；更一般情况是，将它们的通过提案信息发送给一个特定的learners集合，其中的每个learner都可以将该信息告知所有的learners。</p><p>由于信息的丢失，learners可能无法确定一个值是否有一个大多数的acceptors通过了，为了确定选定的值，必须重新发起一次新的提案。</p><h3 id="Progress"><a href="#Progress" class="headerlink" title="Progress"></a>Progress</h3><p>假设存在这样一个场景，两个proposers轮流提议一系列递增编号的提案，但无一通过：Proposer p提出一个编号为n1的提案并且完成了phase1，然后另一个Proposer q为编号为n2(n2&gt;n1)的提案完成了phase1。因此n1提案的accept请求会被忽略，从而触发使用一个新的编号n3(n3&gt;n2)重新开始并完成phase1，同理又导致前面编号为n2的提案的accept请求被忽略。</p><p>为了保证progress的进行，必须选择一个特定proposer来作为唯一一个提议提案的。如果这个proposer可以和半数以上的acceptors通信，同时使用一个比现有通过编号都大的编号作为提案的话，就可以产生一个成功通过的提案。</p><blockquote><p>The famous result of Fischer, Lynch, and Pat- terson [1] implies that a reliable algorithm for electing a proposer must use either randomness or real time—for example, by using timeouts. However, safety is ensured regardless of the success or failure of the election.</p></blockquote><p>无论选举是否成功，proposer选举算法的安全性都是可以得到保证的。</p><h3 id="The-Implementation"><a href="#The-Implementation" class="headerlink" title="The Implementation"></a>The Implementation</h3><p>Paxos算法假设了一个多进程网络，在该算法里，每个进程都扮演了proposer，acceptor及learner的角色。Paxos算法通过选定一个leader来扮演上面提到的特定learner和proposer。Paxos一致性算法就是上述所描述的，其中请求和响应都作为普通消息发送。acceptor在发出响应消息之前，会需要可靠性存储来记录信息。</p><p>接下来就是描述一种提案编号唯一性的机制了，不同的proposer从不相交的编号集合中选择编号，并且每个proposer都会在存储设备上记录目前生成的最大编号，然后使用一个更大的编号来开始phase 1。</p><h2 id="Implementing-a-State-Machine"><a href="#Implementing-a-State-Machine" class="headerlink" title="Implementing a State Machine"></a>Implementing a State Machine</h2><p>实现分布式系统的一种简单方式是由一组客户端向一个中央服务器发出命令请求，该服务器可以看作是一个按顺序执行客户端命令的状态机。但使用单个服务器的可用性较低，因此想到了可以使用一组服务器，每个服务器独立地实现同样的状态机，只要所有服务器都产生一致的状态和输出，那么发出命令的客户端就可以采用任意一个服务器的输出了。</p><p>然而为了所有服务器的命令序列一致，需要实现一系列独立的paxos一致性算法的实例。其中第i个选定的值就是序列中的第i 个状态机命令。每一个服务器都在每一个实例中扮演这个算法的所有角色。</p><p>假设服务器的集合是固定的，一般情况下一个独立的服务器被选为了leader，它就会扮演特定的proposer角色，多个客户端发送命令到leader，leader会决定每个命令的顺序。假设存在某条命令的序号为135，那么它就会通过一致性算法的第135个实例来选定一个提案，这里的命令就是提案的值。这个提案可能成功也可能失败，失败的原因可能来自机器故障，或者是存在另一个服务器认为自己是leader，从而判断了135实例存在其他值。但该算法能够保证最多只有一个命令被选定。</p><p>这个策略的关键在于，Paxos算法中被提出的值只有phase 2才能被选定。前面说过的，phase 1完成时，要么提案的值已经确定，要么proposer可以自由提出一个值。这是正常工作的情况，论文还提到了异常情况：前一个leader失败了，选举了新leader。</p><p>新leader选出后会成为learner，假设它知道命令1-134,138及139，即对应实例，此时它需要执行实例135-137以及所有大于139的实例的phase 1。假设执行结果表明，实例135和140中被提出的提案值已经确定，但其他实例没有限制，那么该leader就可以执行实例135和140的phase 2，选定135和140的命令。</p><p>此时136和137还没确定，leader可以选择接下来的客户端请求作为命令136和137，也可以提起一个特殊的”noop”命令来填补这两个空缺。此处，noop命令不会改变状态机状态，也可以快速填补空缺。一旦这些noop命令选定了，138-140 号命令就可以被执行了。</p><p>由此1-140命令都被选定了，leader就可以继续往下推进所有大于140的实例了。</p><p>接下来讲讲空缺的产生，leader可以在提出命令141被选定之前，先提出命令142，但发送的关于141的信息可能会全部丢失，因此其他服务器可能先知道了142命令的选定，而不知道选择了什么作为命令141。这就产生了空缺。</p><p>由于 leader 的故障以及新 leader 的选举都是比较罕见的情况，因此执行状态机命令并达成一致的成本主要是phase 2的成本。在所有的一致性算法中， paxos一致性算法的phase 2的时间复杂度可能是最小的，因此paxos算法基本就是最优的。</p><p>特殊情况下，leader选举失败，导致出现多个“疑似”的leader，但paxos算法的安全性仍然可以保证不会同时有两个命令被选为第i个状态机命令。</p><p>如果服务器的集合是变化的，那么也存在某种方式来决定哪些服务器可以作为这个一致性算法的实力，论文提到的方式是通过状态机自身来实现，即当前的服务器集合作为状态的一部分，比如将在执行完第i个状态机命令后标识的服务器集合，作为一致性算法执行实例i+a的服务器集合。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Paxos-Made-Simple&quot;&gt;&lt;a href=&quot;#Paxos-Made-Simple&quot; class=&quot;headerlink&quot; title=&quot;Paxos Made Simple&quot;&gt;&lt;/a&gt;Paxos Made Simple&lt;/h1&gt;&lt;h2 id=&quot;Intro
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Better I/O Through Byte-Addressable, Persistent Memory——论文学习</title>
    <link href="http://yoursite.com/2021/03/07/Better-I-O-Through-Byte-Addressable-Persistent-Memory%E2%80%94%E2%80%94%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2021/03/07/Better-I-O-Through-Byte-Addressable-Persistent-Memory——论文学习/</id>
    <published>2021-03-06T17:26:02.000Z</published>
    <updated>2021-03-06T17:26:37.033Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Better-I-O-Through-Byte-Addressable-Persistent-Memory"><a href="#Better-I-O-Through-Byte-Addressable-Persistent-Memory" class="headerlink" title="Better I/O Through Byte-Addressable, Persistent Memory"></a>Better I/O Through Byte-Addressable, Persistent Memory</h1><blockquote><p>现代的计算机系统一般是通过基于块的接口来缓慢地访问持久性存储的，但近年来，像Phase-Change Memory这种基于字节寻址的持久性存储技术提供了更快速、和更细粒度的访问方式。本论文介绍了新的文件系统和硬件体系结构，具备基于字节寻址持久性内存的属性。</p></blockquote><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>新的基于字节寻址的持久性存储技术（BPRAM）消除了volatile和non- volatile存储之间的许多传统差异，尤其是随着Phase-Change Memory和memristors等技术的发展，也可像DRAM一样按字节寻址，同时能够像磁盘一样持久化。</p><p>本文通过研究文件系统来探索BPRAM的好处，并为BPRAM线了一个新的文件系统BPFS，提供了远快于传统基于块存储设备的文件系统的速度。此外，与现有系统相比，BPFS通过一种short-circuit shadow paging的新技术来提供了强大的安全性和一致性保证。</p><p>BPFS的存储方法在一些重要方面与传统文件系统也存在不同，包括不将DRAM缓冲区高速缓存用于文件系统数据，针对小型随机写入进行优化，减小了尚未持久的数据漏洞窗口。</p><h2 id="DESIGN-PRINCIPLES"><a href="#DESIGN-PRINCIPLES" class="headerlink" title="DESIGN PRINCIPLES"></a>DESIGN PRINCIPLES</h2><p>论文主要关注两个目标：</p><ul><li>设计对BPRAM的体系结构支持；</li><li>设计一个文件系统，以利用BPRAM的属性来提高性能和可靠性；</li></ul><h3 id="Expose-BPRAM-Directly-to-the-CPU"><a href="#Expose-BPRAM-Directly-to-the-CPU" class="headerlink" title="Expose BPRAM Directly to the CPU"></a>Expose BPRAM Directly to the CPU</h3><p>传统的永久性存储位于总线控制器和存储控制器的后面，由于对这些控制器的访问带来的性能损耗，即使是最快的NAND闪存SSD，延迟也要几十微秒。</p><p>论文的做法是，将BPRAM直接与DRAM并排放置在内存总线上，使得CPU能够在BPRAM的地址上加载和存储，降低访问延迟。另外，BPRAM的可寻址还能够利用高速缓存的层次结构来提高对持久性存储器的写入性能。</p><p>但将BPRAM放在内存总线上也是有一些缺点：</p><ul><li>BPRAM的流量有可能会干扰易失性存储器的访问并进一步损害整体系统性能；</li><li>系统中可用的BPRAM数量受BPRAM密度和计算机中可用DIMM插槽数量的限制；</li><li>若应用或驱动程序存在缺陷，则可能导致杂散写入，即stray write；</li></ul><p>因此不建议用BPRAM完全替代DRAM，虽然论文也提到一些论据证明这几个缺点不是很大问题的。</p><h3 id="Enforce-Ordering-and-Atomicity-in-Hardware"><a href="#Enforce-Ordering-and-Atomicity-in-Hardware" class="headerlink" title="Enforce Ordering and Atomicity in Hardware"></a>Enforce Ordering and Atomicity in Hardware</h3><p>为了保证安全性和一致性，文件系统需要清楚写入持久性存储的顺序和时间。但执行强制性的排序约束会对性能有一定的影响。文中提出了一种软件机制来声明对硬件的排序约束，软件可以发出特殊的写屏障，以分隔一组epoch的写操作，而硬件将保证每个epoch都按顺序写回到主存器中。</p><p>除了对顺序的限制外，文件系统还考虑对应对故障原子性的问题，如果由于电源故障而中断对持久性存储的写操作，则该存储器可能会处于中间状态，从而破坏了一致性。借助BPRAM，可以直接在硬件中提供一个简单的原子写入基元。</p><h3 id="Use-Short-Circuit-Shadow-Paging"><a href="#Use-Short-Circuit-Shadow-Paging" class="headerlink" title="Use Short-Circuit Shadow Paging"></a>Use Short-Circuit Shadow Paging</h3><p>大多数存储系统都使用以下两种方式来确保可靠性：WAL预写日志和影子分页shadow paging。WAL会使得大多数写入需要进行两次操作，而shadow paging则是实用写时复制来执行所有更新。由于shadow paging每次写入都会因为传播到文件系统根目录树而输出多个块，shadow paging的副本成本远超日志记录，因此目前应用都是使用前者。</p><p>但BPRAM的字节寻址能力和快速的随机写入使影子分页成为文件系统设计的一种高效方法，BPFS通过实现一种称为短路影子寻呼（SCSP）的新技术，允许BPFS在文件系统树中的任何位置提交更新，从而避免了将副本传播到文件系统根目录所产生的开销。</p><h2 id="BPFS-DESIGN-AND-IMPLEMENTATION"><a href="#BPFS-DESIGN-AND-IMPLEMENTATION" class="headerlink" title="BPFS DESIGN AND IMPLEMENTATION"></a>BPFS DESIGN AND IMPLEMENTATION</h2><h3 id="File-System-Layout"><a href="#File-System-Layout" class="headerlink" title="File System Layout"></a>File System Layout</h3><p>BPFS的持久数据结构组织成了一个具备固定大小的块的树，使得能够原子更新树的任意部分，并且块大小固定使得释放和分配都比较方便。</p><p>BPFS数据结构由三种文件组成，每种文件都由相同的树数据结构表示。</p><ul><li>索引节点文件是一个包含固定大小的索引节点数组的单个文件，每个索引节点表示文件系统中的某个文件或目录；</li><li>目录文件包含目录项数组，该目录项数组由inumber（即inode文件中inode的索引）和相应文件的名称组成；</li><li>数据文件仅包含用户数据；</li></ul><p>所有文件都是由相同的数据结构组成的，即一棵全由4K块组成的树。树的叶节点代表文件的数据（即用户数据，目录条目或索引节点），每棵树的内部节点包含了指向树的下一级的512个64位指针。文件系统的根结点就是inode文件。</p><p><img src="https://img.imgdb.cn/item/601ed79e3ffa7d37b3abbef5.png" alt></p><p>每个树的高度由树的根指针的低位所表示，这使得BPFS可以通过记住从中获取的数来确定给定的块是内部节点还是叶子节点。对于高度为0的树，根指针直接指向一个数据块，该数据块最多可以包含4KB的文件数据。在高度树为1的情况下，根指针指向512个指针的内部块，每个指针指向4KB数据块，总共2 MB。以此类推。内部节点没有存储文件数据。</p><p>为了简化将数据写入文件中间的任务，我们在树的任何级别使用空指针，以此表示该指针跨越的文件某个范围内的零数据。例如，如果文件的根指针是高度为5的空指针，则它表示一个空的256TB文件。空指针也可以出现在内部节点上，此文件就可以实现大型的稀疏文件的紧凑表示形式。另外，还会存储每个文件的大小以及每个根指针，若文件较大，则假定文件的尾部为零；若文件较小，则忽略文件末尾在树中的任何数据。这样能够在不更新树本身的情况下更改文件大小。</p><h3 id="Persistent-Data-Updates"><a href="#Persistent-Data-Updates" class="headerlink" title="Persistent Data Updates"></a>Persistent Data Updates</h3><p>Short-circuit shadow paging通过三种不同的方法来更新持久性数据：</p><ul><li>就地更新：由于硬件能保证这些更新是原子的，因此能对64位或更少位数的写入执行就地更新。</li><li>就地追加：就地追加利用了每个文件的根指针附带着文件大小变量。由于超出文件大小的所有数据都将被忽略，因此可以安全地就地写入这些位置，并且一旦写入了所有数据，我们就可以自动更新文件大小来扩展有效数据范围；</li><li>写时复制：在将受此操作影响的树的所有部分上执行写时复制，直到可以通过一次写操作可以提交变更的最少部分。</li></ul><p><img src="https://img.imgdb.cn/item/60217ded3ffa7d37b3d71967.png" alt></p><p>对于所有这些操作，必须要在提交该操作的原子写入之前和之后发出epoch barriers。这些屏障确保了提交之前所有写操作都先将被刷新到BPRAM，并且任何后续的文件系统操作都将在提交之后进行。</p><h3 id="Volatile-Data-Structures"><a href="#Volatile-Data-Structures" class="headerlink" title="Volatile Data Structures"></a>Volatile Data Structures</h3><p>该文件系统布局允许对持久状态进行高效可靠的更新，因此暂不允许将诸如哈希表之类的复杂数据结构存储在持久内存中。但考虑到这些复杂数据结构可以提高性能，因此在易失性内存中维护一些派生的数据结构。这里介绍了三个：</p><ul><li>在DRAM中存储的空闲BPRAM块列表以及释放或者分配的inumber列表，这些数据结构在每次启动时都从文件系统元数据初始化。</li><li>正在进行的写时复制操作中已释放和已分配的块列表。</li><li>第三个数据结构存储用户打开的每个目录中目录条目的缓存。</li></ul><h3 id="File-System-Operations"><a href="#File-System-Operations" class="headerlink" title="File System Operations"></a>File System Operations</h3><p>由于所有BPFS文件类型都使用BPFS树数据结构，因此的论文实现了一组核心routines——crawler，它们可以遍历这些树并可以对三种文件执行读写操作。为了执行这些操作，需要为crawler提供根指针，树的高度，文件偏移范围和回调函数。crawler到达叶节点后，它将使用适当的地址调用回调。</p><p>crawler负责更新树的高度和内部指针。更新高度的操作：先查看请求的文件偏移量是否超出当前文件树所覆盖的偏移量，如果超过了，则以原子操作使树的高度增加适当的数量。</p><p>在叶节点上，crawler将调用一个回调，如果该回调希望执行写时复制操作，它将分配一个新块，执行任何必要的更新，然后必须适当地更新任何内部节点。如果回调未进行任何修改，则crawler将返回未触及的现有指针块。如果回调仅修改了一个指针，那么crawler将就地提交该操作。如果修改了多个指针，crawler将对该指针块进行完整复制，将提交推迟到树中的高层节点。</p><p>下面是单个的文件系统操作：</p><ul><li>Open：打开文件后，BPFS会解析路径并使用目录项缓存来查找目标文件或目录；如果该文件不存在，并且请求创建，则从可用列表中声明一个新的inumber，然后以适当的偏移量将一个新的inode写入inode文件。写完后，将一个新目录项写入包含文件的目录中，最后更新易失性存储器中的目录条目缓存；</li><li>Read：读取文件时，BPFS在文件的适当范围内调用crawler。读取的回调将数据块中的数据复制到用户提供的缓冲区中，然后使用就地原子写入来更新访问时间；读取目录则是将目录加载到目录条目缓存（如果尚未缓存）中；</li><li>Write：写入文件时，可能需要对inode本身执行写时复制操作。顶层crawler对inode文件进行操作，并找到目标文件的inode，然后在此文件的适当范围上调用写crawler，并确定是否可以就地更新，如果不可以则使用写时复制。如果需要同时更新文件大小和inode内文件的根指针，将对inode块本身执行写时复制，然后将新版本返回给inode文件；</li><li>Close：关闭文件或目录后，BPFS会检查该文件或目录是否已标记为删除。如果是，crawler则到目录条目的位置写入inumber为0来表示删除。最后则更新易失性数据结构，包括空闲块列表和空闲inumber列表；</li></ul><h3 id="Multiprocessor-Operation"><a href="#Multiprocessor-Operation" class="headerlink" title="Multiprocessor Operation"></a>Multiprocessor Operation</h3><p>BPFS保证将更新按顺序提交给BPRAM。在单处理器系统上，epoch barrier通过按照创建它们的顺序将从缓存子系统中拿到epoch来强制执行此保证。</p><p>对于多处理器的情况，硬件修改可确保如果在两个不同的CPU上发出了共享状态的两个epoch，那么这些epoch将被序列化。但如果进程或线程在两个不同的CPU上执行时更新了两个不同的状态，则可以按任何顺序将更新写回PCM。为了正确实现这些更新，必须考虑三种情况：</p><ul><li>可以在单个文件系统操作期间在多个CPU上调度线程；</li><li>可以在两个不同的文件系统操作之间将线程切换到新的CPU；</li><li>两个进程可以在两个不同的CPU中更新文件系统中的两个不同位置；</li></ul><p>BPFS的当前实现尚未强制执行前两个约束。</p><h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>BPFS也存在一些局限性：</p><ul><li>其一是写入时间不像写入本身进行原子更新，这是基于性能的折衷考虑；</li><li>另一个局限性是跨越树一大块的原子操作可能需要大量额外的副本；</li><li>还有一个局限是BPRAM的整体接口实现了新的文件系统，并没有提供持久化的用户级堆；</li></ul><h2 id="HARDWARE-SUPPORT"><a href="#HARDWARE-SUPPORT" class="headerlink" title="HARDWARE SUPPORT"></a>HARDWARE SUPPORT</h2><h3 id="Phase-Change-Memory"><a href="#Phase-Change-Memory" class="headerlink" title="Phase Change Memory"></a>Phase Change Memory</h3><p>Phase change memory即PCM是一种非易失性且基于字节寻址的新型存储技术，能提供与DRAM相近的访问速度，也可以组织成类似于DRAM的阵列结构。本论文的假设是基于PCM的存储系统被组织成放置在与DDR兼容的DIMM中一组PCM芯片。</p><h3 id="Wear-Leveling-and-Write-Failures"><a href="#Wear-Leveling-and-Write-Failures" class="headerlink" title="Wear Leveling and Write Failures"></a>Wear Leveling and Write Failures</h3><p>尽管PCM比一般的NAND闪存的写耐久性更高，但考虑到PCM放置在存储器总线上而不是I/O总线上，单元将暴露于更大更多的写入活动，因此需要进行耗损均衡：</p><ul><li>最小化写入的方式设计PCM阵列，延长使用寿命；</li><li>在每个页面内，通过旋转内存控制器级别的位来使损耗均匀；</li><li>在页面之间，可以通过定期交换虚拟页面到物理页面来使损耗均匀映射；</li></ul><h3 id="Enforcing-Atomicity"><a href="#Enforcing-Atomicity" class="headerlink" title="Enforcing Atomicity"></a>Enforcing Atomicity</h3><p>为了对8字节的写入保证原子性，必须要确保在电源故障的情况下，写入要么完全完成（所有位适当更新），要么完全失败（所有位都处于原始状态）。论文建议通过增加DIMM的容量来增强原子性，使得该电容器具有足够的能量来完成PCM子系统中正在进行的最大写入事务数。</p><h3 id="Enforcing-Ordering"><a href="#Enforcing-Ordering" class="headerlink" title="Enforcing Ordering"></a>Enforcing Ordering</h3><p>现代的高速缓存和内存控制器可以重新排列从CPU到内存的写入顺序。考虑到使用BPRAM代替DRAM，写回发生的顺序会变的很重要，例如如果高速缓存控制器在选择在写回缓冲区之前先写回指针更新，则BPRAM中的文件系统将不一致，这种不一致性一般会因为高速缓存一致性和内存屏障机制变得不可见。但如果在所有数据都写回到BPRAM之前发生电源故障，则重新引导计算机时文件系统将变得不一致。为了避免这种情况，需要遵守任何排序约束。</p><p>强制排序有多种选择。一种可能是使用直写式缓存；第二种是在每个内存屏障处刷新整个缓存，以确保所有数据都以正确的顺序到达非易失性内存中；第三种是跟踪在操作期间已修改的所有高速缓存行，以便仅刷新包含脏文件系统数据的行。</p><p>这几种方法都有明显的问题，论文的解决方法是允许软件将排序约束明确地传达给硬件，即epoch barrier。epoch是从同一线程向持久性存储器进行写入的序列，由软件发出的新型存储器屏障来界定。</p><h2 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h2><p>本文主要介绍了一种文件系统，支持按字节寻址和持久化内存，同时也介绍了一种硬件体系来确保原子性和顺序保证。新型文件系统使用了short-circuit shadow paging的技术来提供较强的安全性和一致性保证。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Better-I-O-Through-Byte-Addressable-Persistent-Memory&quot;&gt;&lt;a href=&quot;#Better-I-O-Through-Byte-Addressable-Persistent-Memory&quot; class=&quot;heade
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Bitcoin: A Peer-to-Peer Electronic Cash System——MIT6-824</title>
    <link href="http://yoursite.com/2021/02/18/Bitcoin-A-Peer-to-Peer-Electronic-Cash-System%E2%80%94%E2%80%94MIT6-824/"/>
    <id>http://yoursite.com/2021/02/18/Bitcoin-A-Peer-to-Peer-Electronic-Cash-System——MIT6-824/</id>
    <published>2021-02-18T12:23:44.000Z</published>
    <updated>2021-02-18T12:24:24.189Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Bitcoin-A-Peer-to-Peer-Electronic-Cash-System"><a href="#Bitcoin-A-Peer-to-Peer-Electronic-Cash-System" class="headerlink" title="Bitcoin: A Peer-to-Peer Electronic Cash System"></a>Bitcoin: A Peer-to-Peer Electronic Cash System</h1><blockquote><p>一个纯粹的p2p电子支付能够绕过第三方金融机构直接从一方发到另外一方。数字签名能解决部分场景问题，但还不够好，因为仍旧需要一个信任的第三方去防止双重支付。因此论文提出一种解决方案来解决双重支付问题，即使用了一个点对点网络。</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>目前网上的电子支付越来越依赖金融机构来充当可信的第三方机构，但这种基于信任的第三方机构具有天生的缺点：由于不可逆的交易并不存在，金融机构需要协调买卖双方的争端，产生的成本最终会转嫁到买家头上。而通过使用现金，由于可以一手交货一手交钱，这些成本可以进一步避免，但由于交易双方天生互不信任，在没有可信第三方机构的前提下，仍旧缺乏一个可靠的机制来保障交易的进行。总结来说，第三方的可信与否，现在的这套体系需要付出巨大的成本来处理，这是目前这套体系的“天然缺陷”。</p><p>论文提出的电子支付系统就是一个基于密码学证明而非信任的系统，允许双方在不需要第三方机构的前提下进行直接的交易。计算上的不可逆性能保证卖家不被欺骗，而常规的第三方托管机构可以轻松地被使用来保护买家（卖家比买家更有优势？）。在论文里提出了一种方案来解决双重支付问题：使用一种p2p的分布式时间戳服务，生成交易的时间顺序的可计算证明。只要诚实节点共同控制的算力比攻击节点组织控制的算力大，那么整个系统就是安全。</p><h2 id="Transactions"><a href="#Transactions" class="headerlink" title="Transactions"></a>Transactions</h2><p>论文对电子货币的定义就是一个带有数字签名的链表，每一个货币拥有者交易给下一个人时，先是通过对上一个交易的输出和接受者公钥进行hash后，然后货币拥有者再用自己的私钥对hash值进行数字签名，这样收款人就可以通过验证签名来进行溯源。</p><p><img src="https://img.imgdb.cn/item/600bdec03ffa7d37b3aef39f.png" alt></p><p>但这个过程有一个问题就是，无法验证付款人有没有双重支付，即这个付款人有没有同时转账给了另一个人。一个可靠的方法是引入一个中央机构，在每一笔交易后，这个货币必须被中央机构回收从而发行一个新的货币，并且只有货币是被直接从可信的中央机构发行才能保证不被双重支付，但这又回到了前面的银行老路了。</p><p>论文的做法是，每一笔交易必须被公开广播出来，收款人需要确保，这笔交易是大多数节点所公认的第一次出现，第一次被接收。因为需要一个系统让所有参与者公认一个唯一的历史序列。</p><h2 id="Timestamp-Server"><a href="#Timestamp-Server" class="headerlink" title="Timestamp Server"></a>Timestamp Server</h2><p>论文提出的解决方案先从时间服务器开始，其工作过程是把一组数据形成的区块hash结果加盖上时间戳并广播这个hash。这个时间戳就证明，这些数据在这个时刻一定是存在的。每一个时间戳在hash过程中都包含前面一个时间戳，随着每个新增的时间戳加强了可信度，让每一个区块都包含了前面所有区块的时间戳，这样构成了一个链条。</p><p><img src="https://img.imgdb.cn/item/600be4823ffa7d37b3b17413.png" alt></p><h2 id="Proof-of-Work"><a href="#Proof-of-Work" class="headerlink" title="Proof-of-Work"></a>Proof-of-Work</h2><p>为了实现一个基于p2p的分布式时间戳服务器，将会需要使用一个工作量证明系统。在hash的时候，工作量证明机制将参与扫描一个值，这个hash从一串0bits开始，平均工作量随着0的增长将呈指数级增长，然而只执行一个hash运算就能验证这个hash值。</p><p>对于时间戳网络，我们通过在区块中增加一个随机数来实现这个工作量证明，直到一个指定块的hash所需要的0-bits值被找到。只要CPU效率被花费来作为工作量证明，除非重新做一遍相当的工作量，否则这个区块就不能再被改变。简单来说就是做的工作越多，找到这个随机数的概率就越大，这样就构建了一个工作量证明机制。</p><p>工作量证明机制同时解决了大多数代表的问题，论文解释了不考虑一个IP一票的这种模式，因为这个机制很容易被拥有大多数IP的给颠覆。工作量证明本质上是一CPU一票，最长的链就表示了大多数，同时也有最大的工作量。如果一个大多数CPU的算力都被诚实节点所控制，那么该链就会增长得最快且超过其他任何链。想要改变一个过去的块，攻击者需要重做这个块和所有在这个块后的块工作量证明，之后还要追赶上并超过现在所有诚实节点的工作。一个更慢的攻击者想要追上不断延伸的区块链，可能性是呈指数级下降的。</p><p><img src="https://img.imgdb.cn/item/600c44fd3ffa7d37b3e712cb.png" alt></p><p>同时为了抵消硬件速度提升和节点变化的影响，工作量的困难度是由一个变化的平均目标决定的——每一个小时的平均区块，全网只按一个平均时间来生成一个区块。如果块生成的速度更快了，单位时间所需要的工作量就会变得更大，在同等算力下，计算随机数的难度更大了。</p><h2 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h2><p>网络运行的步骤如下：</p><ol><li>新的交易被广播到所有节点；</li><li>每一个节点都把新交易收集进入到一个块；</li><li>每一个节点都为自己的块去找到那个工作量证明；</li><li>节点找到后，将块广播给所有的节点；</li><li>其他所有节点认可这个块的所有交易合法，并且接受这个块；</li><li>节点开始使用该块的hash作为prev hash，开始转向下一个块的工作量证明；</li></ol><p>节点总是只认可最长的链，如果2个节点同时广播不同版本的块，一些节点会首先收到其中一个块，并为第一个收到块工作，但同时也保存下另一个块。当下一个工作量证明被发现的时候且这时另一条分支会变得更长，在其他分支工作的节点们也将会转换到这个最长的分支上，即块重组。</p><p>新交易是没必要广播到所有的节点上，只要交易到达了许多节点上，它们就会进入到一个区块中。并且块的广播能够容忍被丢失的信息，节点意识到那一块缺失就可以进行请求。</p><h2 id="Incentive"><a href="#Incentive" class="headerlink" title="Incentive"></a>Incentive</h2><p>一般来说，这里存在两种激励。</p><p>一个块里面第一笔交易信息是一个特别的交易，它开始了一个新的币，这个币属于这个块的创造者，这就是系统对这个节点的激励，提供了一个方式来初始化货币进入到整个系统当中。</p><p>另一种激励就是手续费了。如果一个交易的输出值小于输入值，那么这个差值就是交易的手续费，手续费被附加到包含交易信息的块中。一旦所有货币进入流通，这个激励机制就可完全地转变为交易手续费，并且可以完全避免通货膨胀。</p><p>另外，激励可以帮助鼓励节点保持诚实。如果一个贪婪的攻击者能够收集到比所有诚实节点更多的CPU算力，他就面临一个选择：要么用这个算力进行二次支付来欺骗别人，或者使用算力来生成更多的货币。后者的收益更大，这就是一个博弈关系。</p><h2 id="Reclaiming-Disk-Space"><a href="#Reclaiming-Disk-Space" class="headerlink" title="Reclaiming Disk Space"></a>Reclaiming Disk Space</h2><p>一旦一个货币最新的交易收入进入足够多的块中，那么在这笔交易之前的交易信息就能够被抛弃来节省硬盘资源。为了不损害块的hash，交易信息被hash成一种Merkle树的形态，只有root节点被包含进了这个区块的hash。通过拔除Merkle树的分支，不保存内部的hash值，以此来压缩块。</p><p>此时一个块的头部大概会是80byte大小。假设块每10分钟就生成一个，那么每年产生<code>80bytes * 6 * 25 * 365 = 4.2MB</code>的数据。</p><p><img src="https://img.imgdb.cn/item/600da6543ffa7d37b3902338.png" alt></p><h2 id="Simplified-Payment-Verification"><a href="#Simplified-Payment-Verification" class="headerlink" title="Simplified Payment Verification"></a>Simplified Payment Verification</h2><p>支付验证不需要运行所有的网络节点，有些节点已经不再持有全部的块信息，但用户可以通过向网络节点发起询问从而拿到最长工作量证明链条上的块副本，从而得到了Merkle树的分支，连接到这个用户的交易被加上时间戳的地方。用户自己不能验证交易，但可以通过把交易连接到Merkle树的分支。就可以看见一个可以看到一个网络节点曾经接受过它，在它后面增加的块也能证明网络曾经接收过它。</p><p><img src="https://img.imgdb.cn/item/600dae9e3ffa7d37b394b331.png" alt></p><p>因而只要有多数诚实节点控制网络，支付的验证就是可靠的，而一旦网络被攻击者控制，一个简单的验证方法就是：当这些网络节点监测到一个非法的块，就会提醒用户去下载相关的全部区块，进行独立的安全验证。</p><h2 id="Combining-and-Splitting-Value"><a href="#Combining-and-Splitting-Value" class="headerlink" title="Combining and Splitting Value"></a>Combining and Splitting Value</h2><p>虽然可以独立的处理电子货币，但在一次转账中为每一分钱都构造一个独立的交易是不明智的。为了能让价值能够分割和组合，交易包含了多个输入和输出。通常情况，前面的交易要么是一大笔单一的输入或者是包括很多小额的多笔输入，输出也有两种，一个是付款，另一个是找零。bitcoin只关心差额，不关心货币最小单元。</p><p><img src="https://img.imgdb.cn/item/600db0e83ffa7d37b395e1a6.png" alt></p><h2 id="Privacy"><a href="#Privacy" class="headerlink" title="Privacy"></a>Privacy</h2><p>传统的银行系统实现隐私的保护是通过限制访问信息被提供给相关的参与者和第三方。像现在的场景需要将全部交易公开广播的时候，就不能使用这种方法了。这里的做法是公钥匿名，公众可以看到有一个人转账给另一个人，但是没有信息能把交易和人联系在一起。</p><p><img src="https://img.imgdb.cn/item/600db2213ffa7d37b396c40a.png" alt></p><p>还有一个额外的防范机制，就是每次有新的交易，进来都使用一个新的密钥对。但一旦用户的公私密钥被泄漏，由于信息是全网公开的，通过多笔的输入交易，仍然可能推测出这个人是谁。</p><h2 id="Calculations"><a href="#Calculations" class="headerlink" title="Calculations"></a>Calculations</h2><p>接下来我们考虑一个场景，一个攻击者尝试生成一条比目前诚实链还长的替换链。即便这样能实现，也不代表整个系统完全受制于攻击者。节点是不会接受无效的交易作为支付的，攻击者只能只能尝试修改他自己的交易信息，从而要回自己花掉的钱。</p><p>诚实链和攻击链的竞争可以看作是一个Binomial RandomWalk，这是指随机漫步有两个方向的概率模型，要么是诚实链领先，要么是攻击链领先。成功事件是诚实链延长了一个块，使其+1领先，同时失败事件是攻击链延长一个块，使得差距-1。攻击者从一个既定的差距中追上的可能性可以看作是一个Gambler’s Ruinproblem。一个攻击者要追上诚实链，如下所示：</p><ul><li><p>P=诚实链发现下一个区块的概率</p></li><li><p>q=攻击者发现下一个区块的概率</p></li><li><p>qz=攻击者花费了z个区块追赶上了</p></li></ul><p><img src="https://img.imgdb.cn/item/600ef71e3ffa7d37b32d909f.png" alt></p><p>假设p&gt;q，那么攻击者追上的概率就会随着块数目的增加而指数下降。现在可以考虑一个新的交易能够被充分地确认发送方不能再更改交易的情况要等多久，即不能再追上。假设付款人是一个攻击者，他希望收款方认为他已经付过款了，并且在之后把这个钱在付款后拿回来。收款方在这件事情发生的时候会被通知警告，但是付款方希望这件事情很久才发生。</p><p>接收方生成了一个新密钥对并在短时间内把这个公钥给了付款方，这能有效防止付款方事先准备好一个在时间之前的区块链。</p><p>一旦交易被发送，这个不诚实的发送者开始为包含替换他交易版本的并行链而秘密工作。事实上接收方不知道攻击者确切地进展了多少块。假设诚实块是花费平均时间来产生的，那么攻击者的潜在进展会呈现一种泊松密度分布，期望值λ是：</p><p><img src="https://img.imgdb.cn/item/600ef91d3ffa7d37b32e42ca.png" alt></p><p>为了得到攻击者能追上的概率，将泊松密度乘以从该点追上的概率得到：</p><p><img src="https://img.imgdb.cn/item/600ef9e93ffa7d37b32e8e32.png" alt></p><p><img src="https://img.imgdb.cn/item/600ef9e93ffa7d37b32e8e35.png" alt></p><p>附上一段代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;math.h&gt; </span></span></span><br><span class="line">doubleAttackerSuccessProbability(<span class="keyword">double</span> q, <span class="keyword">int</span> z)&#123;</span><br><span class="line">      <span class="keyword">double</span> p= <span class="number">1.0</span> - q;</span><br><span class="line">      doublelambda = z * (q / p);</span><br><span class="line">      doublesum = <span class="number">1.0</span>;</span><br><span class="line">      <span class="keyword">int</span> i, k;</span><br><span class="line">      <span class="keyword">for</span> (k =<span class="number">0</span>; k &lt;= z; k++)</span><br><span class="line">      &#123;</span><br><span class="line">             doublepoisson = <span class="built_in">exp</span>(-lambda);</span><br><span class="line">             <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= k; i++) </span><br><span class="line">                   poisson *= lambda / i; </span><br><span class="line">                   sum -= poisson * (<span class="number">1</span> - <span class="built_in">pow</span>(q / p, z - k));</span><br><span class="line">      &#125;    </span><br><span class="line">      <span class="keyword">return</span> sum; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>论文提出了一个不依赖信任的电子交易系统，为了解决双重支付的问题，提出了一种p2p的网络，并采用工作量证明机制来记录交易的历史。当大多数节点控制主要的CPU算力，攻击者就不会通过计算去修改。整个网络还是比较鲁棒的，独立工作不需要太多协调，不需要被认证，可随意离开或加入网络，通过CPU算力投票进行工作从而延长区块链，以此表达他们对有效区块的接受。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Bitcoin-A-Peer-to-Peer-Electronic-Cash-System&quot;&gt;&lt;a href=&quot;#Bitcoin-A-Peer-to-Peer-Electronic-Cash-System&quot; class=&quot;headerlink&quot; title=&quot;Bi
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS——MIT6-824</title>
    <link href="http://yoursite.com/2021/01/18/Don%E2%80%99t-Settle-for-Eventual-Scalable-Causal-Consistency-for-Wide-Area-Storage-with-COPS%E2%80%94%E2%80%94MIT6-824/"/>
    <id>http://yoursite.com/2021/01/18/Don’t-Settle-for-Eventual-Scalable-Causal-Consistency-for-Wide-Area-Storage-with-COPS——MIT6-824/</id>
    <published>2021-01-17T16:09:57.000Z</published>
    <updated>2021-01-17T16:10:30.621Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Don’t-Settle-for-Eventual-Scalable-Causal-Consistency-for-Wide-Area-Storage-with-COPS"><a href="#Don’t-Settle-for-Eventual-Scalable-Causal-Consistency-for-Wide-Area-Storage-with-COPS" class="headerlink" title="Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS"></a>Don’t Settle for Eventual: Scalable Causal Consistency for Wide-Area Storage with COPS</h1><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p> COPS的KV存储系统，并引出了一种新的一致性模型——具有收敛性冲突处理的因果一致性。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>对于分布式存储系统，论文从CAP转移到关注ALPS——即可用性、低延迟、分区容忍性和扩展性。论文介绍了一个叫COPS的KV存储系统，并实现了一种新的一致性模型causal+ consistency，收敛冲突处理的因果一致性。除此之外还有一个扩展版本——COPS-GT，提供了get事务来保证提供对于多个key的一致性视图，并且是无锁和非阻塞的。</p><ul><li>因果一致性：确保数据存储遵循操作之间的因果依赖关系；</li><li>收敛冲突处理：确保副本永远不会发散，并且在所有节点上对相同key的冲突进行相同的处理；</li></ul><p>两者结合，确保客户端看到因果正确，无冲突且始终在发展的数据存储。</p><h2 id="ALPS-SYSTEMS-AND-TRADE-OFFS"><a href="#ALPS-SYSTEMS-AND-TRADE-OFFS" class="headerlink" title="ALPS SYSTEMS AND TRADE-OFFS"></a>ALPS SYSTEMS AND TRADE-OFFS</h2><p>一个分布式系统主要关注以下几个特性：</p><ul><li>Availability：所有操作不会被永久阻塞或者返回不可用的错误；</li><li>Low Latency：client能快速完成操作；</li><li>Partition Tolerance：在网络分区的情况，数据存储能继续提供服务；</li><li>High Scalability：能做到线性扩展；</li><li>Stronger Consistency：理想的数据存储最好能提供线性化；</li></ul><p>由于CAP的缘故，具备可用性和分区容忍性的分布式系统无法实现强一致性。为了在ALPS系统的要求和易编程之间取得平衡，论文定义了一个中间一致性模型。</p><h2 id="CAUSAL-CONSISTENCY"><a href="#CAUSAL-CONSISTENCY" class="headerlink" title="CAUSAL+ CONSISTENCY"></a>CAUSAL+ CONSISTENCY</h2><p>对于具有收敛冲突处理的因果一致性来说，其抽象模型只有两种操作：put(key,val)和 get(key)=val，即读写。在COPS系统里，单个逻辑副本就是完整的本地集群的所有节点。</p><p>该模型定义了三条规则：</p><ul><li>Execution Thread：如果a和b是单线程内的两个操作，a-&gt;b表示a发生在b之前；</li><li>Gets From：如果a是一个put操作，b是一个获取a写入值的get操作，则是a-&gt;b；</li><li>Transitivity：对于操作a、b、c来说，如果存在a-&gt;b和b-&gt;c，则一定有a-&gt;c；</li></ul><p>下图就是这三条规则的一个样例：</p><p><img src="https://img.imgdb.cn/item/5ffb1adb3ffa7d37b392d6ce.png" alt></p><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>论文将因果一致性定义为两个属性的组合：因果一致性和收敛性冲突处理。</p><p>所谓的因果一致性就是上图提到的一个操作顺序结果，如果client 2读取x的时候，先读取到4，再读取到1就会违反因果一致性。但如果两个操作a和b没有任何顺序关系，那么因果一致性就会认为这是一个并发操作，不会做任何的约束，提高系统性能。如果a和b都在同一个key上做put操作，就意味着发生冲突。冲突会带来两个问题：冲突的值可能不确定，即不同副本的值可能不一致；冲突可能产生需要特殊处理的特殊情况；</p><p>因此就需要收敛的冲突处理，冲突处理函数必须能在所有副本上以相同的方式进行处理，并且满足交换律和结合律的，即$h(a,h(b,c))=h(c,h(b,a))$，不同的副本以接收到顺序处理冲突，收敛处理的结果。</p><p>COPS可以自定义冲突收敛函数，默认使用last writer wins。</p><h3 id="Causal-vs-Other-Consistency-Models"><a href="#Causal-vs-Other-Consistency-Models" class="headerlink" title="Causal+ vs. Other Consistency Models"></a>Causal+ vs. Other Consistency Models</h3><p>这一章主要介绍各种一致性模型的对比，从约束能力来看：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Linearizability &gt; Sequential &gt; Causal+ &gt; Causal &gt; FIFO</span><br><span class="line"> &gt; Per-Key Sequential &gt; Eventua</span><br></pre></td></tr></table></figure><p>Causal+提供了比较适中的一致性模型，且能满足ALPS的系统要求。</p><h3 id="Causal-in-COPS"><a href="#Causal-in-COPS" class="headerlink" title="Causal+ in COPS"></a>Causal+ in COPS</h3><p>COPS系统提供了两个抽象：其一是版本号，每个key都有一个版本号；另外就是依赖关系，如果b依赖a，那么在复制的时候，需要先复制a，才能再复制b；</p><h3 id="Scalable-Causality"><a href="#Scalable-Causality" class="headerlink" title="Scalable Causality"></a>Scalable Causality</h3><p>有些类似的因果一致性系统使用的是日志交换的序列化，在扩展性方便表现不好。而COPS则是采用了划分key空间和编码依赖关系到key元数据的方式来提高扩展性。</p><h2 id="SYSTEM-DESIGN-OF-COPS"><a href="#SYSTEM-DESIGN-OF-COPS" class="headerlink" title="SYSTEM DESIGN OF COPS"></a>SYSTEM DESIGN OF COPS</h2><p>COPS是一个实现了causal+一致性的、能满足ALPS的分布式存储系统，论文提及了两个版本：一个是简单版的，支持causal+ 的一致性，另一个则是升级版的，支持get事务，能确保client请求keys的时候，存储系统能提供一个一致的相关values的快照，成为 COPS-GT。</p><h3 id="Overview-of-COPS"><a href="#Overview-of-COPS" class="headerlink" title="Overview of COPS"></a>Overview of COPS</h3><p>如下图，COPS就是一个在若干个数据中心运行着的kv存储系统。每个数据中心都有一个本地的COPS集群，保存着完整的一份数据。Client只与本地的数据中心进行联系，并通过COPS的client库进行调用。</p><p><img src="https://img.imgdb.cn/item/6002872f3ffa7d37b3d238d1.png" alt></p><p>COPS系统主要由两个组件组成的：</p><ul><li>Key-value store：提供了对keys的线性化操作<ul><li>每个key- value对都有对应的元数据。对于COPS，这个元数据是版本号；对于COPS-GT，则是有版本号和一系列的依赖‘</li><li>kv存储提供了三种额外的操作：get by version, put after和dep check这三种操作确保了client库和异步复制进程能够提供Casula+一致性和get事务；</li><li>对于 COPS-GT，系统保存了kv对的一些老版本数据，提供get事务；</li></ul></li><li>client库：主要提供读写操作，COPS的get， COPS-GT的get_trans，还有put。</li></ul><p>另外，COPS为了在确保casual+一致性的时候，能降低资源和性能开销：</p><ul><li>避免检查所有值的依赖关系；</li><li>做垃圾回收，减少存储多版本key和依赖关系元数据的空间开销；</li><li>最多进行两次的get事务，降低延迟；</li></ul><h3 id="The-COPS-Key-Value-Store"><a href="#The-COPS-Key-Value-Store" class="headerlink" title="The COPS Key-Value Store"></a>The COPS Key-Value Store</h3><p>对于COPS，存储元组是&lt;key: {value, version}&gt;，存储的是最新版本的数据；</p><p>对于COPS-GT，存储元组是&lt;key: {value, version, deps}&gt;，deps就是一个链表，链表元素是&lt;key, version&gt;；</p><p>每个COPS集群都持有完整的一份kv存储数据，每个集群节点根据一致性哈希获得一个独立的keys空间。至于容灾，则是通过链式复制来提供的。在每个集群中，每个key都有一个主节点，主节点会复制到集群内的从节点；至于其他集群也有一个对应的主节点；</p><p>集群内的操作是线性化的，本地commit后，跨集群复制时会将数据放到一个队列上异步复制到其他集群的主节点。待其他集群检查完依赖关系后，就会提交该key；</p><h3 id="Client-Library-and-Interface"><a href="#Client-Library-and-Interface" class="headerlink" title="Client Library and Interface"></a>Client Library and Interface</h3><p>COPS的clientAPI主要包含四个步骤：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1. ctx id ← createContext()</span><br><span class="line">2. bool ← deleteContext(ctx id)</span><br><span class="line">3. bool ← put (key, value, ctx id)</span><br><span class="line">4. value ← get (key, ctx id) [In COPS]</span><br><span class="line">or</span><br><span class="line">4. hvaluesi ← get trans (hkeysi, ctx id) [In COPS-GT]</span><br></pre></td></tr></table></figure><p>与传统的kv系统API不同，这个client库会有一个针对COPS-GT的get_trans的API，还有就是所有的函数都需要一个context的参数，该参数可以记录每个client操作的因果关系；</p><ul><li>COPS-GT Client Library</li></ul><p>COPS-GT的client库中context存了一组&lt;key, version, deps&gt;，读取时，client会将该key和其依赖关系添加到当前的context里；写入时，client先取出最新版本key的依赖关系，重新计算新依赖D，待写入成功后，则将写入该项&lt;key，返回的version，D&gt;到context；</p><p>下图就是运行过程中的依赖关系变化图：</p><p><img src="https://img.imgdb.cn/item/6002908b3ffa7d37b3d70194.png" alt></p><p>这种依赖关系的设计会嗲来两个问题：空间占用大和检查依赖关系的成本高。</p><p>论文的解决方法是：COPS-GT会在依赖关系被提交后进行垃圾回收，另外就是由于依赖关系具备传递性，一旦依赖项被提交，那么可以确定该依赖项的依赖项也被提交了，所以只需要检查最近依赖；</p><blockquote><p>get_trans需要检查全部的依赖</p></blockquote><ul><li>COPS Client Library</li></ul><p>COPS的client库需要更好的状态，因此读取时只需要将拿到的key和版本号添加到context就好，至于写入，则是先使用context作为最近的依赖项，返回数据后，则用返回的数据去副高context。</p><h3 id="Writing-Values-in-COPS-and-COPS-GT"><a href="#Writing-Values-in-COPS-and-COPS-GT" class="headerlink" title="Writing Values in COPS and COPS-GT"></a>Writing Values in COPS and COPS-GT</h3><p>所有对COPS的写入都分为两步：同步写入本地集群，异步复制到其他集群，并且都通过下面的API去完成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;bool,vers&gt; ← put_after (key, val, [deps], nearest, vers=∅)</span><br></pre></td></tr></table></figure><h4 id="写入本地集群"><a href="#写入本地集群" class="headerlink" title="写入本地集群"></a>写入本地集群</h4><p>当client调用put接口时，首先需要计算最近的依赖关系，然后client库会去调用put_after接口，这里COPS不需要传入deps参数。然后该key对应的本地主节点会赋予该key一个版本号。put_after接口可以确保本地集群的commit是强一致性的，至于其他集群的提交在后面叙述。</p><p>主节点使用Lamport时间戳来为每次更新计算一个版本号，其中高位是版本号，低位是节点号，通过比较Lamport时间戳，并应用 last-writer-wins 来检查和解决冲突。Lamport时间戳提供了所有分布式事件的偏序关系，与COPS的因果一致性兼容。</p><h4 id="复制到其他集群"><a href="#复制到其他集群" class="headerlink" title="复制到其他集群"></a>复制到其他集群</h4><p>本地写入提交后，主节点会调用put_after（此时vers参数需要设置为新得到的值）异步复制到其他集群的主节点，主节点进行依赖检查dep_check，一直阻塞直到依赖中的值都写入提交了，参会写入并提交该key值。依赖检查只需要nearest就好。</p><h3 id="Reading-Values-in-COPS"><a href="#Reading-Values-in-COPS" class="headerlink" title="Reading Values in COPS"></a>Reading Values in COPS</h3><p>COPS的读取会通过下面的API完成，并且version会设置为默认的LATEST，并将得的数据按照前面说的添加到context里。COPS-GT可能需要获取非LATEST版本的值；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;value, version, deps&gt; ← get_by_version (key, version=LATEST)</span><br></pre></td></tr></table></figure><h3 id="Get-Transactions-in-COPS-GT"><a href="#Get-Transactions-in-COPS-GT" class="headerlink" title="Get Transactions in COPS-GT"></a>Get Transactions in COPS-GT</h3><p>COPS-GT提供了get_trans接口，以事务的方式返回一对kv，满足因果一致性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @param keys list of keys</span></span><br><span class="line"><span class="comment"># @param ctx_id context id</span></span><br><span class="line"><span class="comment"># @return values list of values</span></span><br><span class="line"></span><br><span class="line">function get_trans(keys, ctx_id):</span><br><span class="line"><span class="comment"># Get keys in parallel (first round)</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> keys</span><br><span class="line">  results[k] = get_by_version(k, LATEST)</span><br><span class="line">    </span><br><span class="line">  <span class="comment"># Calculate causally correct versions (ccv)</span></span><br><span class="line">  <span class="keyword">for</span> k <span class="keyword">in</span> keys</span><br><span class="line">    ccv[k] = max(ccv[k], results[k].vers)</span><br><span class="line">    <span class="keyword">for</span> dep <span class="keyword">in</span> results[k].deps</span><br><span class="line">    <span class="keyword">if</span> dep.key <span class="keyword">in</span> keys</span><br><span class="line">    ccv[dep.key] = max(ccv[dep.key], dep.vers)</span><br><span class="line">          </span><br><span class="line">  <span class="comment"># Get needed ccvs in parallel (second round)</span></span><br><span class="line">  <span class="keyword">for</span> k <span class="keyword">in</span> keys</span><br><span class="line">    <span class="keyword">if</span> ccv[k] &gt; results[k].vers</span><br><span class="line">    results[k] = get_by_version(k, ccv[k])</span><br><span class="line">      </span><br><span class="line">  <span class="comment"># Update the metadata stored in the context</span></span><br><span class="line">  update_context(results, ctx_id)</span><br><span class="line">      </span><br><span class="line">  <span class="comment"># Return only the values to the client</span></span><br><span class="line">  <span class="keyword">return</span> extract_values(results)</span><br></pre></td></tr></table></figure><p>论文举了一个相册例子：A修改相册权限acl为“仅朋友可见”，然后修改相册说明desc，然后添加照片到相册album。</p><p>现在要读取A的相册，如果出现一个这样的顺序：先读取到旧的acl，检查权限，然后acl被修改，最后越权读到了desc和album。为了避免这种问题，使用get_trans就不会有这个问题：</p><ul><li>首先是第一轮并行调用get_by_version，拿到acl，desc和album的值，并获得相应的依赖；</li><li>此时可能读到旧的acl、新的desc和album，然后计算ccv，根据依赖关系可以得知desc和album依赖的acl比读到的acl要更新；</li><li>然后根据前面的计算，得到需要进行第二轮get_by_version的调用，此时获取指定版本的值；（同样是并行调用）；</li><li>此时拿到的acl值就是最新的了；</li></ul><h2 id="GARBAGE-FAULTS-AND-CONFLICTS"><a href="#GARBAGE-FAULTS-AND-CONFLICTS" class="headerlink" title="GARBAGE, FAULTS, AND CONFLICTS"></a>GARBAGE, FAULTS, AND CONFLICTS</h2><h3 id="Garbage-Collection-Subsystem"><a href="#Garbage-Collection-Subsystem" class="headerlink" title="Garbage Collection Subsystem"></a>Garbage Collection Subsystem</h3><p>随着key的更新和插入，系统的空间占用将会无限制增长。COPS的垃圾回收子系统能够删除无用的状态，将系统的空间维持在一个合适的大小。</p><ul><li>Version Garbage Collection. 仅COPS-GT需要</li></ul><p>存储：COPS-GT存储了每个key的多个版本，以便client调用get_by_version；</p><p>get_trans算法会限制完成一个事务需要的版本数，即在第二轮获取所需的旧版本数据，因此使用默认为5s的trans_time限制执行时间，若超时则进行重试。写入新版本的key后，COPS-GT只需要保留一段时间的旧版本数据，在此之后就不再使用旧版本来请求数据，并且GC可以降低删除。</p><ul><li>Dependency Garbage Collection. 仅COPS-GT需要</li></ul><p>存储：存储get事务需要的依赖</p><p>当COPS-GT的get事务不再需要这个依赖的时候，就可以进行GC回收，至于不需要则是指：kv被写入到所有集群后经过了trans_time。此时的回收主要是清楚value的依赖，并且设置一个never-depend的标志。</p><p>清除依赖需要通知其他集群，在其他集群的写提交后trans_time，就需要通知原集群，原集群删除后再通知其他集群也删除。</p><ul><li>Client Metadata Garbage Collection. COPS和COPS-GT</li></ul><p>存储：client存在context里的元数据，包括依赖关系和其他数据。</p><p>COPS清理的方式有两种：</p><ol><li>put_after作用于所有集群后，会对key标记为never- depend，并返回给client，client就可以在context中进行删除；</li><li>COPS节点会从put_after中移除不需要的依赖，这里使用了一个global checkpoint time的概念，版本号比这个小的都移除；global checkpoint time的计算方式：首先是从pending中的put_after里找到最早的Lamport timestamp；然后联系其他集群的等价节点，一对一交换拿到最早的Lamport timestamp，所有数据中心都能知道key范围内最早的Lamport timestamp是什么了；最后数据中心会gossip自己负责的key range的最小时间戳，以找到任何一个节点观测到的最早Lamport timestamp。论文的实现是，每秒执行10次，并且对性能没有明显影响。</li></ol><h3 id="Fault-Tolerance"><a href="#Fault-Tolerance" class="headerlink" title="Fault Tolerance"></a>Fault Tolerance</h3><h4 id="Client-Failures"><a href="#Client-Failures" class="headerlink" title="Client Failures"></a>Client Failures</h4><p>Client出故障意味着不能发送请求，因此不需要做任何处理</p><h4 id="Key-Value-Node-Failures"><a href="#Key-Value-Node-Failures" class="headerlink" title="Key-Value Node Failures"></a>Key-Value Node Failures</h4><p>COPS使用了类似FAWN-KV的设计来做链式复制，从而实现节点容灾。在本地集群中，put_after则是直接作用于链的头节点，然后向后传导，在尾节点commit。读取时get_by_version则是直接读尾节点。跨集群传播，则是源集群尾节点将其传播到其他集群的头部节点，进行dep_check后同样沿着链条将值传播，尾节点commit。</p><h4 id="Datacenter-Failures"><a href="#Datacenter-Failures" class="headerlink" title="Datacenter Failures"></a>Datacenter Failures</h4><p>应对数据中心出故障，COPS能继续对外工作，但可能会有一些key不一致；</p><p>本地集群写入时出错：</p><ul><li>集群宕掉，若没有拷贝，数据丢失；</li><li>网络分区，数据不会丢失，等分区修复则可；</li></ul><p>其他集群写入出错，需要等待管理员解决：</p><ul><li>允许复制队列增长，直到故障修复；</li><li>重配置，去掉失败数据中心；</li></ul><p>数据中心出故障时，COPS-GT无法进行依赖回收，要等到重新配置去掉有问题的数据中心。</p><h3 id="Conflict-Detection"><a href="#Conflict-Detection" class="headerlink" title="Conflict Detection"></a>Conflict Detection</h3><p>多线程并发写同一个key会导致冲突。</p><p>COPS使用的是前文提到过的last- write-win策略来解决冲突，last则是最新的写入版本号。</p><p>COPS也可以自定义冲突检查和解决策略，但需要考虑三个部分的内容：</p><ul><li>所有的写入都需要带上前面的版本元数据，即本地集群看到的最近版本；</li><li>所有的写入都需要带上隐式依赖数据，在写入前进行依赖检查；</li><li>检查出冲突后需要自定义一个收敛的冲突处理函数；</li></ul><p>冲突检查：如果写入的key——new，带有了一个版本号prev，而此时可见的当前版本是curr，如果prev!=curr，则意味着发生冲突。</p><h2 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h2><p>本文介绍了一种可扩展的分布式存储系统COPS，可以在不牺牲ALPS属性的情况下提供因果关系+一致性。COPS通过在每个集群的写入之前跟踪并显式检查是否满足因果关系来实现因果一致性。COPS-GT通过在COPS的基础上引入get事务，使client能够获得多个key的一致性视图； COPS-GT进行了优化，减少状态，最小化多轮协议并减少复制开销。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Don’t-Settle-for-Eventual-Scalable-Causal-Consistency-for-Wide-Area-Storage-with-COPS&quot;&gt;&lt;a href=&quot;#Don’t-Settle-for-Eventual-Scalable-
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Scaling Memcache at Facebook——MIT6-824</title>
    <link href="http://yoursite.com/2021/01/05/Scaling-Memcache-at-Facebook%E2%80%94%E2%80%94MIT6-824/"/>
    <id>http://yoursite.com/2021/01/05/Scaling-Memcache-at-Facebook——MIT6-824/</id>
    <published>2021-01-04T16:03:08.000Z</published>
    <updated>2021-01-04T16:04:47.988Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Scaling-Memcache-at-Facebook"><a href="#Scaling-Memcache-at-Facebook" class="headerlink" title="Scaling Memcache at Facebook"></a>Scaling Memcache at Facebook</h1><blockquote><p>Memcache是一个有名的且简单的纯内存缓存方案。论文主要讲了Facebook基于Memcache来构建一个分布式kv存储来为它的社交网站服务，处理几十亿的QPS，存储了上万亿的数据项</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文主要讲述了Facebook如何改进memcached的开源版本，这是一个全内存哈希表的开源实现，能够以较低的开销提供了对存储的访问。Facebook的目标之一是展现部署在不同规模系统的实现，同时需要保持性能、效率、容错能力和一致性。</p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>论文提到的设计面临的场景是：读多写少，需要能从多个数据源读取数据。</p><p>MemCached提供了一组简单的操作（set、get和delete），这使它能够成为大规模分布式系统重要的基础组件。开源版本是一个单机内存哈希表，本文基于这个开源版本构建了一个可以处理每秒数十亿请求的分布式的KV储存系统。下文将用“memcached”来指代它的源码或者它运行的二进制实例，用“memcache”来指代由每个实例构成的分布式系统。</p><p><img src="https://pic.downk.cc/item/5ff33a4b3ffa7d37b349c45c.png" alt></p><p><strong>Query cache</strong>：依赖memcache来减轻读取数据库的负担。如上图所示，读取的时候先读memcache，不命中再读数据库，查询成功后会更新memcache。写请求则是写到数据库，接着发删除请求到memcache。</p><p><strong>Generic cache</strong>：论文还讲了如何使memcache成为一个更加通用的kv系统，如保存机器学习算法的中间结果。</p><p><img src="https://pic.downk.cc/item/5ff33a4b3ffa7d37b349c464.png" alt></p><p>在系统的迭代中，论文考虑了两个重要的设计：</p><ul><li>只有对用户或者运维产生影响的问题，才值得优化；</li><li>系统可能会暴露轻微陈旧的数据以便后台免受高负载的影响；</li></ul><h2 id="In-a-Cluster-Latency-and-Load"><a href="#In-a-Cluster-Latency-and-Load" class="headerlink" title="In a Cluster : Latency and Load"></a>In a Cluster : Latency and Load</h2><p>这一章主要聚焦于拉取缓存数据时的延迟和缓存不命中时带来的负载</p><h3 id="Reducing-Latency"><a href="#Reducing-Latency" class="headerlink" title="Reducing Latency"></a>Reducing Latency</h3><p>为了减轻数据库的负载，需要准备由数百台memcache机器组成的缓存集群，但多个web服务器对多台memcache服务器的关系，可能会在短时间内导致incast congestion。数据副本可以缓解这种情况，但又会带来内存浪费。</p><p>因此论文中提到的减少延迟的方法主要集中在memcache客户端。</p><p><strong>Parallel requests and batching</strong>：为了尽可能减少网络请求，该系统通过做拓扑图分析来表示数据间的依赖，整合将多个独立请求，并尽可能进行并发操作。</p><p><strong>Client-server communication</strong>：memcached服务器之间并不会直接通信，而是相关控制逻辑集成到client上，memcache的client分为两个部分：sdk和一个叫mcrouter的的proxy，mcrouter在web服务器和memcached服务器之间，提供与memcached相同的接口。</p><p>考虑到对数据错误容忍度高，memcached client的get请求使用UDP与memcached服务器通信，减少了创建和维护连接带来的开销。一旦出现丢包或者乱序包，client会将其作为异常处理，即视作cache miss，get请求会被重传到数据库，论文中提到系统在高峰期也只有0.25%的请求会被丢弃。为了可靠性，对于set和delete，则是通过可靠的TCP通信。</p><p><strong>Incast congestion</strong>：对于Incast congestion问题，memcached的client实现了类似TCP的拥塞控制逻辑，根据网络情况控制滑动窗口。</p><h3 id="Reducing-Load"><a href="#Reducing-Load" class="headerlink" title="Reducing Load"></a>Reducing Load</h3><p>为了减轻负载，论文提到了三种技术；</p><h4 id="Leases"><a href="#Leases" class="headerlink" title="Leases"></a>Leases</h4><p>文中引入了租约机制来解决下面两个问题：stale sets和thundering herds，前者是保证了并发更新下的最终一致性，后者则是缓解惊群效应。</p><p>对于stale sets，是因为发生cache miss的时候，并发读取数据库后需要重新写入到memcache，这样就可能出现过期的数据在数据被删除之后才写入，导致数据库和memcache内的数据不一致。通过引入租约，每次出现cache miss的时候都会返回一个与key绑定的lease id，当数据被删除后，之前发出的lease id会失效，写入数据时，sdk需要带上上次收到的lease id，根据该id是否失效来仲裁写入与否。</p><p>对于惊群效应，当数据出现热点的时候，可能会出现大量的cache miss，导致数据库负载增大。memcache通过控制每个key的lease发送速率，比如每个key在10秒内只发送一个lease id，在这期间有对这个key的请求时，会让客户端等待重试，这时数据可能已经被获得lease的给填上，这时就会重试成功。</p><p><strong>过期值</strong>：对于某些能接受过期数据的应用，memcache会将已经删除的数据短暂地保存到另一个数据结构中，此时web server可以决定是等待新的数据还是读取过期数据，从而减轻负载。</p><h4 id="Memcache-Pools"><a href="#Memcache-Pools" class="headerlink" title="Memcache Pools"></a>Memcache Pools</h4><p>将memcache作为通用缓存意味着所有不同的workloads会共享这一设施，Facebook统计过更新频率高的key很可能会将更新频率低的key给逐出来。</p><p>考虑到这一点，Facebook将集群的memcache服务器分割成独立的池，一个默认pool，一个访问频率高但cache miss成本低的small poll，一个访问频率低但cache miss成本高的large pool。</p><h3 id="Replication-With-in-Pools"><a href="#Replication-With-in-Pools" class="headerlink" title="Replication With in Pools"></a>Replication With in Pools</h3><p>对于某些pool，可以通过数据冗余的方式来提高请求的并发能力。</p><p>###Handling Failures</p><p>论文对于故障处理主要提到了两个维度的故障：网络故障和集群自身服务器宕机。</p><p>对于少数几个server宕机或者网络故障，Facebook主要依赖一个自动恢复机制，如果大规模的停机，Facebook会将用户请求直接转移到另一个数据中心。为了避免在自动恢复的那几分钟里对数据库或者后台服务带来的雪崩，memcached的client会将请求转移到Gutter机器上接管故障服务器的能力。</p><p>一般来说，每次失败的请求都会导致转移到Gutter的存取，从而减轻数据库的负载。</p><h2 id="In-a-Region-Replication"><a href="#In-a-Region-Replication" class="headerlink" title="In a Region: Replication"></a>In a Region: Replication</h2><p>随着流量的增大，需要对Memcached做横向扩展，并且能够解决key的热点问题和网络incast congestion，论文在replication和sharding之间做了取舍，选择了将memcached servers切分成多个集群，这一个memcached集群、前端访问集群还有共享存储集群统称为region。</p><h3 id="Regional-Invalidations"><a href="#Regional-Invalidations" class="headerlink" title="Regional Invalidations"></a>Regional Invalidations</h3><p>考虑到由于存在多个memcached server集群，需要确保数据的一致性，避免同一条数据的不同版本出现在不同集群上。论文的做法是，监控MySQL，一旦出现数据被删除或者更新，且事务提交，那么对应key就会被一个mcsqueal守护进程记录（读取MySQL的commit log），然后批量地将删除明亮发送给对应的Memcached实例。</p><p><img src="https://pic.downk.cc/item/5ff33a4b3ffa7d37b349c46b.png" alt></p><h3 id="Regional-Pools"><a href="#Regional-Pools" class="headerlink" title="Regional Pools"></a>Regional Pools</h3><p>考虑对部分数据的QPS很低，Facebook的做法是不把所有数据在一个region内存储多份冗余，而是在单个region内划分出一个pool来存储那些访问率低的数据。</p><h3 id="Cold-Cluster-Warmup"><a href="#Cold-Cluster-Warmup" class="headerlink" title="Cold Cluster Warmup"></a>Cold Cluster Warmup</h3><p>由于现有集群需要进行定期维护，在新集群上线时，缓存命中率会很低。Facebook构建了一个Cold Cluster Warmup的系统，在新集群发生cache miss时从热集群中加载数据，而不是去读持久化存储。</p><h2 id="Across-Regions-Consistency"><a href="#Across-Regions-Consistency" class="headerlink" title="Across Regions: Consistency"></a>Across Regions: Consistency</h2><p>Facebook在全球都有数据中心，因此每个数据中心都会有若干个region来服务用户。基于MySQL的复制机制，Facebook将一个region设为master，其他的都是只读region，web servers请求的时候只会访问本地的DB或者memcache。至于写入，所有的请求只是发给master处理，然后mysql再将其同步到从region。这样就可能带来一致性的问题，即从region的memcache一直保留着过期数据。</p><p>对于这种场景，该系统保持一致性的方法是：</p><ul><li><p>如果在master region写，前端集群收到更新，请求转发到数据库，同时删除本集群的memcache记录。数据库的进程同步修改到其他集群，其他region删除过期的记录；</p></li><li><p>在非master region写数据d：</p><ul><li>本地的memcache会设置remote marker，rd；</li><li>将d写到master region的db；</li><li>将d从memcache中删除；</li><li>等待master DB同步带有rd信息的数据到非master DB；</li><li>该非master DB通过解析数据，然后删除掉rd；</li></ul><p>在这个过程中，非master region有对该数据d进行读取，并发生cache miss时，如果发现了数据带有rd，则直接跨region访问master DB，否则直接读取本地DB。</p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>论文主要是基于memcache技术来满足Facebook的业务需求，有很多取舍在优化线上系统性能时都非常值得参考。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Scaling-Memcache-at-Facebook&quot;&gt;&lt;a href=&quot;#Scaling-Memcache-at-Facebook&quot; class=&quot;headerlink&quot; title=&quot;Scaling Memcache at Facebook&quot;&gt;&lt;/a&gt;Sc
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing——MIT6-824</title>
    <link href="http://yoursite.com/2021/01/05/Resilient-Distributed-Datasets-A-Fault-Tolerant-Abstraction-for-In-Memory-Cluster-Computing%E2%80%94%E2%80%94MIT6-824-1/"/>
    <id>http://yoursite.com/2021/01/05/Resilient-Distributed-Datasets-A-Fault-Tolerant-Abstraction-for-In-Memory-Cluster-Computing——MIT6-824-1/</id>
    <published>2021-01-04T16:02:46.000Z</published>
    <updated>2021-01-04T16:04:35.440Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Resilient-Distributed-Datasets-A-Fault-Tolerant-Abstraction-for-In-Memory-Cluster-Computing"><a href="#Resilient-Distributed-Datasets-A-Fault-Tolerant-Abstraction-for-In-Memory-Cluster-Computing" class="headerlink" title="Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing"></a>Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing</h1><blockquote><p>本文提出了一种称之为RDDs的分布式内存抽象，以此解决在大规模集群中以容错的方式提供内存计算的方式。当前的计算框架对于迭代算法和交互式数据挖掘的效率都很低，RDDs通过将数据留在内存来提高性能。本文通过Spark系统来实现RDDs。</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>诸如MapReduce 和Dryad之类的集群计算框架已被广泛用于大规模数据分析。这些系统使用户可以使用一组高级API来编写并行计算，而不必担心工作分配和容错能力。</p><p>尽管当前的框架为集群的计算资源提供了许多抽象，但它们还是缺乏对利用分布式内存的抽象。这就导致了在多个计算之间复用中间结果时，显得非常低效。数据重用在许多迭代机器学习和图计算中很常见。另外在交互式数据挖掘中，用户会需要对数据的同一子集运行多个临时查询。然而在大多数框架中，在计算之间（例如在两个MapReducce作业之间）重用数据的唯一方法是将其写入外部稳定的存储系统，例如分布式文件系统。由于数据复制，磁盘IO和序列化，这会导致相当大的开销，这可能会影响应用程序的执行时间。</p><p>在这篇论文中提出了一个全新的抽象，叫做RDDs(Resilient Distributed Datasets)，它可以在广泛的应用程序中实现有效的数据重用。RDDs 是一个可以容错且并行的数据结构，它可以让用户显式的将中间结果数据集保存在内中。</p><p>现存的分布式内存抽象系统，都是基于对可变状态的细粒度更新。这种接口保证容错的方式无非是将数据进行多副本备份，需要在机器节点间复制大量的数据，宽带传输数据的速度远远比RAM 内存慢。</p><p>与这些系统相比，RDD提供了基于粗粒度转换的接口（map，reduce，filter）。这些接口可以对多条数据条目应用相同的操作，这样就可以通过记录来生成某个数据集的一系列转换，而不是记录真实的数据。如果RDD丢失，则RDD具有足够的有关如何从其他RDD派生的信息，可以仅重新计算该分区。因此，丢失的数据通常可以很快恢复。</p><h2 id="Resilient-Distributed-Datasets"><a href="#Resilient-Distributed-Datasets" class="headerlink" title="Resilient Distributed Datasets"></a>Resilient Distributed Datasets</h2><p>本章主要介绍RDD和Spark编程接口，并与细粒度共享内存做对比。</p><h3 id="RDD-Abstraction"><a href="#RDD-Abstraction" class="headerlink" title="RDD Abstraction"></a>RDD Abstraction</h3><p>RDD是一个只读的、可分区的数据集，可以通过对稳定的存储系统或者其他的RDD进行操作来创建一个新的RDD，这些操作称之为transformations，比如map，filter 以及join。另外用户可以控制RDD的存储和分区，指定存储策略，也可以根据key做hash来做数据分区。</p><h3 id="Spark-Programming-Interface"><a href="#Spark-Programming-Interface" class="headerlink" title="Spark Programming Interface"></a>Spark Programming Interface</h3><p>Spark通过集成编程语言API来表示RDD，每一个数据集就是一个对象，通过对象的方法来操作对象。RDD有两种操作，一种是上面说的transformations，另一种则是action，action操作可以得到应用结果值，比如count可以返回数据集的元素个数、collect返回数据集的所有元素以及save则是将输出结果写入到存储系统中。</p><p>Spark定义RDDs是并不会计算，只是采取lazy特性，可以将transformations组成pipeline，触发了actions操作才会真正计算。用户可以通过RDDs的preset方法来缓存数据，也可以调整缓存策略。</p><h3 id="Advantages-of-the-RDD-Model"><a href="#Advantages-of-the-RDD-Model" class="headerlink" title="Advantages of the RDD Model"></a>Advantages of the RDD Model</h3><p>论文将RDD和分布式共享内存系统DSM做了比较，RDD只能粗粒度的操作转换，而DSM可以在任意内存位置进行写入。这样RDD的容错机制更加高效，不需要发生非常耗时的checkpoint，只需重新计算丢数据的分区。另外一个好处就是任务备份比较简单，因为RDD是不变的。还有就是，RDD可以进行进行任务调度来提高大批量的写入效率，在scan-base的操作中也能根据需要将内存数据写到磁盘中。</p><h3 id="Applications-Not-Suitable-for-RDDs"><a href="#Applications-Not-Suitable-for-RDDs" class="headerlink" title="Applications Not Suitable for RDDs"></a>Applications Not Suitable for RDDs</h3><p>RDD更适合批量的数据处理场景，并不适合于需要异步且细粒度的更新共享状态的应用。</p><h2 id="Spark-Programming-Interface-1"><a href="#Spark-Programming-Interface-1" class="headerlink" title="Spark Programming Interface"></a>Spark Programming Interface</h2><p>Spark提供了一个用Scala编写的语言集成API。为了使用Spark，开发者编写了一个driver，该driver会连接workers集群，并定义若干个RDDs，在RDDs上执行action，在driver上的Spark代码会追踪RDDs的lineage。workers是一直运行的进程，能在内存中存储RDD分区。</p><h3 id="RDD-Operations-in-Spark"><a href="#RDD-Operations-in-Spark" class="headerlink" title="RDD Operations in Spark"></a>RDD Operations in Spark</h3><p>下图列出了Spark中RDD的transformations和actions操作。transformations是定义新RDD的lazy操作，而actions才是真正计算结果或者写数据到外部存储；</p><p><img src="https://pic.downk.cc/item/5ff33b793ffa7d37b34abc98.png" alt></p><h2 id="Representing-RDDs"><a href="#Representing-RDDs" class="headerlink" title="Representing RDDs"></a>Representing RDDs</h2><p>抽象RDDs会带来一个问题：如何在广泛转换中表示追踪lineage。理想情况下，一个实现RDDs的系统应该能够提供丰富的·转换算子，用户可以以任意方式进行组合。在Spark中则是提出了一个简单的图表示来达到以上目的。</p><p>论文提出了一个通用接口去表示RDD，接口表达了五种信息：</p><ul><li>一组分片（partitions），数据集的原子组成；</li><li>一组父RDDs上的依赖；</li><li>一个基于父数据集计算的函数；</li><li>分片策略元数据，一个分片函数partitioner；</li><li>数据位置策略，存储每个partition的优先位置；</li></ul><p>论文将RDDs之间的依赖分为了两类：</p><ul><li>窄依赖：父RDD的每个分片被子RDD至多一个分片使用；</li><li>宽依赖：多个子分片依赖一个父分片；</li></ul><p>例如，代表HDFS文件的RDD对文件的每个块都有一个分片，并且通过数据位置策略知道每个块在哪台计算机上。</p><p><img src="https://pic.downk.cc/item/5ff33b793ffa7d37b34abcd2.png" alt="img"></p><p>窄依赖能在一个节点上流水线执行，节点故障的时候也能高效地通过重新计算父分片来进行恢复；而宽依赖，单一节点故障可能会导致一个RDD的所有祖先分片丢失，需要完全重新执行。</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>Spark可以从任何的Hadoop输入源中读取数据，比如HDFS和HBase。本章主要关注下面的几个部分：任务调度、Spark解释器的交互式使用、内存管理和checkpoint。</p><h3 id="Job-Scheduling"><a href="#Job-Scheduling" class="headerlink" title="Job Scheduling"></a>Job Scheduling</h3><p>Spark的调度器与Dryad类似，另外还会考虑持久化了的RDD的哪些分片在内存中可用。任何时候用户在RDD上执行action，调度器就会检查RDD的lineage，建立由stages组成的DAG，然后执行这个图。调度器会使每个stage包含尽可能多的窄依赖，stages的边界是宽依赖shuffle操作，或者任何计算过的分片。</p><p><img src="https://pic.downk.cc/item/5ff33b793ffa7d37b34abd14.png" alt="img"></p><p>调度器会根据数据存放位置使用延迟调度给机器指派任务。</p><p>若一个任务失败了，只要stage的父分片还在，就可以在另一个节点重新运行。如果一些stages都不可用了，就需要重新提交任务去并行计算丢失分片。</p><h3 id="Interpreter-Integration"><a href="#Interpreter-Integration" class="headerlink" title="Interpreter Integration"></a>Interpreter Integration</h3><p>Scala包含一个类似于Ruby和Python的交互式shell，考虑到内存数据的低延迟，Spark可以让用户在解释器上运行。</p><p>Spark中的编译器相对Scala做了一些改变：</p><ul><li>类传输：通过HTTP传输创建类的字节码；</li><li>代码生成：代码生成的单例对象是通过生成类的静态方法访问的，为了避免序列化一个访问不到前面定义变量的闭包，Spark将代码生成逻辑改成直接引用每行对象的实例；</li></ul><p><img src="https://pic.downk.cc/item/5ff33b793ffa7d37b34abd29.png" alt="img"></p><h3 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h3><p>Spark对RDD的持久化提供了三个选项：</p><ul><li>序列成Java对象，存在内存中；性能最好</li><li>作为序列化数据存在内存中；内存空间有限时使用</li><li>存在硬盘中；RDDs过大无法存入内存</li></ul><p>当计算新的RDD分片后，如果没有足够空间去存储，就会基于LRU的淘汰策略去淘汰一个分片。但如果新旧分片属于同一个RDD，则会将旧的分片写入内存，避免相同RDD的分片循环读写。</p><h3 id="Support-for-Checkpointing"><a href="#Support-for-Checkpointing" class="headerlink" title="Support for Checkpointing"></a>Support for Checkpointing</h3><p>虽然lineage可以帮助恢复RDDs，但如果lineage很长的时候就会变得很耗时，因此RDD可以执行checkpoint存入稳定内存。</p><p>Spark为checkpoint提供了一个API，让用户决定checkpoint哪个数据。同样，Spark的调度器也制定每个数据集大小，了解第一次计算的耗时，因此也会基于一定的策略选择一个优化RDDs集合来执行checkpoint，缩短系统恢复时间。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要介绍了一个在集群中共享数据的高效的、具备容错能力的的抽象——RDD。RDD能表达通用的并行应用，提供了一个基于粗粒度转换的API，也能通过lineage来快速恢复数据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Resilient-Distributed-Datasets-A-Fault-Tolerant-Abstraction-for-In-Memory-Cluster-Computing&quot;&gt;&lt;a href=&quot;#Resilient-Distributed-Dataset
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>No compromises distributed transactions with consistency, availability, and performance——MIT6-824</title>
    <link href="http://yoursite.com/2020/11/15/No-compromises-distributed-transactions-with-consistency-availability-and-performance%E2%80%94%E2%80%94MIT6-824-1/"/>
    <id>http://yoursite.com/2020/11/15/No-compromises-distributed-transactions-with-consistency-availability-and-performance——MIT6-824-1/</id>
    <published>2020-11-14T17:43:49.000Z</published>
    <updated>2020-11-14T17:44:27.460Z</updated>
    
    <content type="html"><![CDATA[<h1 id="No-compromises-distributed-transactions-with-consistency-availability-and-performance"><a href="#No-compromises-distributed-transactions-with-consistency-availability-and-performance" class="headerlink" title="No compromises: distributed transactions with consistency, availability, and performance"></a>No compromises: distributed transactions with consistency, availability, and performance</h1><blockquote><p>强一致性和高可用性的事务简化了分布式系统的构建，但在从前，分布式事务的设计实现不大理想，这就迫使以前构建分布式系统的时候抛弃分布式事务或者使用弱一致性，或者使用单机事务，要求业务方通过数据分区的方式，保证事务数据落在一个机器上。</p><p>本文一个名为FaRM的内存分布式计算平台，具备以下特性：强序列化，高性能，持久性和高可用性。</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>具有高可用性和强序列化的事务通过简单的抽象来简化了分布式系统的编程和推理：单机永不失败，一次执行一个实时同步的事务。但是，先前在分布式系统中实现此抽象的尝试都导致了较差的性能。因此，诸如Dynamo或Memcached之类的系统通过不支持事务或实施弱一致性保证来提高性能。其他系统仅在所有数据都驻留在一台机器中时才提供事务。</p><p>本文证明了现代数据中心中的新软件可以消除折衷的要求。它在一种称为FaRM的内存分布式计算平台中描述了事务，复制和恢复协议。 FaRM为分布式ACID事务提供严格的可简化性，高可用性，高吞吐量和低延迟。FaRM平台利用了两个趋势：带有RDMA的网络和提供非易失性DRAM，消除了存储和网络瓶颈，并通过减少消息数量，使用单面RDMA读写存储而不是消息以及有效利用并行性，来解决CPU瓶颈。</p><p>FaRM允许数据分布在不同机器，同时允许事务跨越任何数量的机器。FaRM通过使用vertical Paxos，而不是通过Paxos协议进行coordinators和数据的复制，此时副本是主-备，然后协调者是单个，不进行复制。FaRM使用具有四个阶段提交协议（锁定，验证，提交备份和主要提交）。</p><p>在事务执行和验证期间和在事务中修改的对象副本上将记录记录到非易失性预写日志WAL时，都会使用RDMA，避免了本地CPU开销。不再需要CPU参与，意味着传统的故障恢复（failure-recovery）协议不再适合FaRM，因此文章使用了precise membership的解决方案：保证所有机器都在当前membership configuration上达成一致，并且只会发送请求给组员。</p><p>FaRM中的故障恢复速度很快，因为它有效地利用了并行性。它在集群中平均分配恢复的数据，并在每台计算机之间并行进行恢复。</p><h2 id="Hardware-trends"><a href="#Hardware-trends" class="headerlink" title="Hardware trends"></a>Hardware trends</h2><p>FaRM的设计受到数据中心机器中大量廉价DRAM的推动。FaRM利用两种硬件趋势来消除存储和网络瓶颈：非易失性DRAM和具有RDMA的网络。</p><h3 id="Non-volatile-DRAM"><a href="#Non-volatile-DRAM" class="headerlink" title="Non-volatile DRAM"></a>Non-volatile DRAM</h3><p>distributed uninterruptible power supply (UPS)利用锂离子电池的广泛可用性来降低数据中心UPS的成本，与传统的UPS相比，这种方法更加可靠：锂离子电池配备了多个独立的电池单元，并且电池故障仅会影响机架的一部分。</p><p>分布式UPS有效地使DRAM持久耐用。发生电源故障时，分布式UPS使用电池中的能量将内存内容保存到SSD中。这不仅避免了对SSD的同步写入，从而提高了常见情况的性能，而且还通过仅在发生故障时对其进行写入来延长SSD的寿命。另一种方法是使用非易失性DIMM（NVDIMM），它们包含自己的专用闪存，控制器和超级电容器，但这种设备成本更高。</p><p>FaRM将所有数据存储在内存中，并在将其写入多个副本上的NVRAM中时，将其作为持久数据。</p><h3 id="RDMA-networking"><a href="#RDMA-networking" class="headerlink" title="RDMA networking"></a>RDMA networking</h3><p>FaRM尽可能使用单边RDMA操作，因为它们不使用远程CPU。与RPC相比，RDMA的读取性能更高，并且消除了NIC消息速率瓶颈。但RPC和RDMA与CPU有关，减少CPU开销能更好释放新硬件的潜力。</p><h2 id="Programming-model-and-architecture"><a href="#Programming-model-and-architecture" class="headerlink" title="Programming model and architecture"></a>Programming model and architecture</h2><p>FaRM提供了一个全局的抽象地址空间，提供对事务中本地和远程对象的透明访问。应用程序线程可以随时启动事务，而后会成为事务的协调者。在事务执行期间，线程可以执行任何逻辑，包括读取，写入，分配和释放对象。在执行结束时，线程调用FaRM提交事务。</p><p>FaRM事务使用乐观并发控制，更新在执行期间会缓冲在本地，并且仅在成功提交后才对其他事务可见，FaRM对成功提交的事务提供了严格的串行性。至于读，FaRM保证对单个对象操作的原子性，每次读总能返回最新的值。不同对象间的读取不保证原子性，但保证严格串行。</p><p>下图显示了具有四台计算机的FaRM实例和机器A的内部组成。每台机器在用户进程中运行FaRM，且内核线程固定在每个硬件线程上。每个内核线程运行一个事件循环，该循环执行应用程序代码并轮询RDMA完成队列。</p><p><img src="https://pic.downk.cc/item/5fa03c371cd1bbb86b8e1d77.png" alt></p><p>扩缩容的时候，FaRM实例会随着时间推移逐步进行一系列配置，配置是⟨i, S, F , CM⟩，其中i是唯一单调递增的64位配置id，S是配置的机器集合，F是Pair&lt;机器, 独立故障域&gt;，CM是配置管理机器。FaRM使用Zookeeper来确保机器就当前配置达成一致并进行存储，但是它不像通常那样依靠Zookeeper来管理租约，检测故障或协调恢复。 而是使用配置管理器通过RDMA快速恢复来负责。</p><p>FaRM的全局内存以2GB进行划分，每个2GB称为一个region，每个region保存在1个primary和f个backups上，每个region存储在非易失内存中，能够被其他机器通过RMDA直接读取。一般会先读primary，如果在本地有就读本地内存，远程有就读RDMA。region到primary-backups的映射关系信息则是保存在CM上。</p><p>机器可以与CM联系分配新区域。CM从单调递增的计数器分配region id，为该区域选择副本，并尽可能平衡各个机器的region数。与一致性哈希的方法相比，这种集中式方法提供了更大的灵活性来满足故障独立性和局部性约束。它还使平衡机器之间的负载和接近容量运行变得更加容易。</p><p>每台机器还存储基于FIFO队列的环形缓冲区，用于事务日志或消息队列。每个发送方-接收方对都有自己的日志和消息队列，但物理上位于接收方处。发送方通过RDMA直接写到尾部，然后NIC直接回ACK，接收方则周期性的从头部读取数据处理。</p><h2 id="Distributed-transactions-and-replication"><a href="#Distributed-transactions-and-replication" class="headerlink" title="Distributed transactions and replication"></a>Distributed transactions and replication</h2><p>FaRM结合了事务协议和副本协议来提高性能，并利用单端RDMA读写来提高cpu的有效性和低延迟。FaRM在非易失的内存中使用主备副本协议来存储数据和事务日志，协调器没有副本，并且协调器会直接和主备副本进行通信。在执行阶段，事务使用单面RDMA（如果与协调器在同一个机器则使用本地内存）读取对象，并且它们在本地缓冲写操作，下图是FaRM事务的执行时间表：</p><p><img src="https://pic.downk.cc/item/5fa803141cd1bbb86b451dff.png" alt></p><p>执行结束后，通过以下步骤进行提交：</p><ol><li>lock：协调器将LOCK记录（版本、新值和region列表）写入所有被修改对象的primary中。然后primary会使用CAS尝试锁住这些对象的指定版本，返回是否锁成功的消息。如果自从事务读取对象以来发生任何对象版本的更改，或者当前对象已被另一个事务锁定，则锁定可能失败，协调器终止事务；</li><li>Validate：协调器对事务内所有的只读对象进行读校验，从这些只读对象的primary发起RMDA读或RPC读。默认情况下使用单面RDMA读取，只读对象的数量超过4个，则使用RPC。如果版本号变更了，事务就被终止；</li><li>Commit backups：通过RDMA写log到所有backups，等待网卡的确认；</li><li>Commit primaries：在确认所有COMMIT-BACKUP写入之后，协调器将Commit primaries记录写入每个primary的日志中，收到至少一个响应，协调器马上返回给应用成功。primary通过更新对象，增加其版本并对其进行解锁来处理这些记录，从而完成了事务所提交的写入；</li><li>Truncate：协调器在收到来自所有primary的确认后，会延迟地truncate事务内的primary和backup的日志；</li></ol><p>正确性；</p><p>在获取所有写锁时，已提交的读写事务是串行的，这是在串行点上所有读取和写入对象的版本与执行期间看到的版本相同。锁阶段保证了写对象的串行性，而校验阶段保证了只读对象的串行性，在没有失败的情况下，这等效于在串行点原子地执行和提交整个事务。 </p><p>为了确保故障时的串行性，必须在写入COMMIT-PRIMARY之前等待所有backup的确认。否则当某些COMMIT-BACKUP失败，且协调器故障了，就会丢失记录。</p><p>由于读的集合只保存在协调器中，一旦协调器挂了就没有commit记录可以证明验证成功了，这样就会导致事务abort。所以协调器等待一个primary的提交成功才会响应给client成功。这样能避免f个backup和coordinator一起挂了使得锁记录保存但丢失校验没成功的记录。</p><p>传统的二阶段提交协议，可以在准备阶段去检查有没有资源。但FaRM因为只用单边RDMA，无法使用远程CPU，因此必须要保留空间去记录所有的提交协议记录，包括在开始commit之前截断primary和backup的记录。日志保留是协调器上的本地操作，因为协调器会将记录写入其在每个参与者处拥有的日志中，写完相应记录之后会释放保留空间。</p><h3 id="Failure-detection"><a href="#Failure-detection" class="headerlink" title="Failure detection"></a>Failure detection</h3><p>FaRM使用租约机制来检测故障。除CM之外，每台机器都在CM处拥有租约，而CM则对其他所有机器拥有租约，这是一个双向租约的机制。租约使用三次握手的方式授权，每台机器向CM发送一个租约请求，CM返回的响应消息即代表对机器的授权，也是CM对该机器的租约请求，最后该机器授权租约给CM。</p><p>FaRM租期非常短，这是高可用性的关键。在高负载下，FaRM可以为90台计算机群集使用5毫秒的租约，而不会产生误报。</p><p>为了在高负载的情况下获得短期租约，FaRM使用专门的队列来支持租约，这样就能避免租约消息的延迟。另外为了避免性能的影响，FaRM的租约管理器通过无连接的不可靠数据包去发送和接收租约。默认情况下，租约的延续一般是租约超时周期的五分之一。</p><p>续租还必须及时在CPU上定时调度，FaRM使用专用的租约管理器线程，该线程以最高的用户空间优先级运行，并且租约管理器线程没有固定到任何的硬件线程，它使用中断而不是轮询来避免在每个硬件线程上定期运行的关键OS任务饿死，导致误报租约过期。虽然增加了几毫秒的消息延迟，但对于租约来说不是问题。</p><p>最后，在初始化期间预先分配租约管理器使用的所有内存，然后分页并固定其使用的所有代码，以避免由于内存管理而造成的延迟。</p><h3 id="Reconfiguration"><a href="#Reconfiguration" class="headerlink" title="Reconfiguration"></a>Reconfiguration</h3><p>重新配置协议将FaRM实例从一种配置移到另一种，FaRM使用了RDMA操作来保证极高的性能，因为缺少CPU的使用，因此无法利用租约机制来实现一致性。FaRM使用的是精确的成员身份来实现这个问题，发生故障后，采用新配置的所有计算机必须先同意其成员身份，然后才能进行对象更改。这就允许了在客户端做检查而不是服务端。配置中的计算机不会向不在其中的计算机发出RDMA请求，并且也会忽略配置中不再存在的计算机做回应。</p><p><img src="https://pic.downk.cc/item/5fb00c44ef76db7fe8909662.png" alt></p><ol><li>猜测：当CM上的一个机器租约过期时，CM会猜测那个机器挂了，并初始化重新配置，这个时间点开始阻塞所有外部客户端的请求。如果一个非CM机器上的租约过期了，它会推断CM挂了，这个非CM租约上的机器会尝试请求少量的CM备机去初始化配置。如果超时后配置未更改，则它将尝试重新配置自身。这种设计避免了在CM故障时会有大量机器同时尝试重新配置，在所有情况下，启动重新配置的机器都将尝试成为新的CM，作为重新配置的一部分。</li><li>探测：新的CM向配置中的所有机器发出RDMA读取，除了前面猜测故障的机器和读失败的机器，这些读取探测允许通过一次重新配置来处理影响多台机器的相关故障，例如电源和开关故障。新CM仅在获得大多数响应后才继续进行重新配置。这样可以确保如果网络已分区，则CM不会位于较小的分区中。</li><li>更新配置：CM尝试更新zk的配置为 ⟨c + 1, S, F , CM(id)⟩，c是当前的配置版本号id，S是探测有返回的机器列表，F是故障域映射，CM(id)是自己的id。FaRM使用zk的znode序列号去实现原子的CAS，只有当前配置的的版本仍然是c是，CAS才成功。</li><li>重新映射区域：新CM重新分配先前映射到故障机器的区域，以将副本数恢复到f + 1。它尝试平衡负载并满足容量和故障独立性约束的应用程序指定的局部性提示。对于失败的主数据库，它会将尚存的备份升级为新的主数据库，以减少恢复时间。如果它检测到丢失了所有副本的区域，或者没有空间可以重新复制区域，则会发出错误消息。</li><li>发送新配置：重新映射区域后，CM会使用配置标识符，其自身的标识符，配置中其他机器的标识符以及区域到机器的所有新映射，向配置中的所有机器发送NEW-CONFIG消息。并根据需要重置租约或者进行租约交换；</li><li>应用新配置：当机器收到配置标识符大于其自身配置的NEW-CONFIG时，它将更新其当前配置标识符及其区域映射的缓存副本，并分配空间以容纳分配给它的所有新区域副本。同时还会给CM进行租约的授权。</li><li>提交新配置：一旦CM从配置中的所有计算机接收到NEW-CONFIG-ACK消息，它会等待所有不在新配置中的机器的租约过期。然后CM向所有配置成员发送NEW-CONFIG-COMMIT，和第6步租约申请的授权，最后所有成员解锁外部客户端请求；</li></ol><h3 id="Transaction-state-recovery"><a href="#Transaction-state-recovery" class="headerlink" title="Transaction state recovery"></a>Transaction state recovery</h3><p>在配置更改后，FaRM使用事务修改的对象副本之间的日志来恢复事务状态。这涉及到事务修改的对象副本和协调器恢复状态，以决定事务的结果。</p><p><img src="https://pic.downk.cc/item/5fb016c63e3fc2acb7182059.png" alt></p><ol><li>阻塞访问正在恢复的region：当一个primary的region挂了，其中一个备份就会被提升为primary，在所有更新该region的操作都反映到该primary之前都不允许访问该region；</li><li>清除日志：单面RDMA写一般会和故障恢复冲突，FaRM无法通过网卡来拒绝来自旧配置的消息，只能在收到NEW-CONFIG-COMMIT消息时清除所有的日志记录，然后拒绝新来的日志；</li><li>找到正在恢复的日志：</li><li>锁定恢复：region的每个primary会等本地机器日志被排出，并且从所有backup中收到NEED-RECOVERY消息，然后primary并行地从backup中拉取任意的、本地没有存储的事务日志记录，并对任何被恢复事务修改的对象进行锁定。当锁定恢复完成了一个region时，这个region就可以被本地或远程的coordinator获得本地指针和RDMA引用；</li><li>备份日志记录：在primary中的线通过发送REPLICATE-TX-STATE消息给backup来备份日志记录；</li><li>投票：恢复事务的coordinator基于每个被该事务修改的region的投票决定是否提交或abort事务；</li><li>决定：如果从所有region收到了commit-primary，coordinator就会决定提交事务；如果至少有一个region投票了commit-backup并且所有其他的被事务修改的region提交了lock或commit-backup或truncated，则等待所有region去投票和提交；其他情况会abort；</li></ol><h3 id="Recovering-data"><a href="#Recovering-data" class="headerlink" title="Recovering data"></a>Recovering data</h3><p>FaRM一定会将region数据复制数据到新的backup上，以便将来能容忍f个故障。一个region的一个新的backup初始化空间为0。region被划分给worker线程并行地恢复数据。每一个线程发出一个单端RDMA操作去读primary的一个block。每个恢复对象被复制到backup之前都会做版本检查，然后使用CAS更新对象状态。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;No-compromises-distributed-transactions-with-consistency-availability-and-performance&quot;&gt;&lt;a href=&quot;#No-compromises-distributed-transact
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Spanner: Google’s Globally-Distributed Database——MIT6-824</title>
    <link href="http://yoursite.com/2020/08/21/Spanner-Google%E2%80%99s-Globally-Distributed-Database%E2%80%94%E2%80%94MIT6-824/"/>
    <id>http://yoursite.com/2020/08/21/Spanner-Google’s-Globally-Distributed-Database——MIT6-824/</id>
    <published>2020-08-20T16:50:14.000Z</published>
    <updated>2020-08-20T16:51:30.071Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Spanner-Google’s-Globally-Distributed-Database"><a href="#Spanner-Google’s-Globally-Distributed-Database" class="headerlink" title="Spanner: Google’s Globally-Distributed Database"></a>Spanner: Google’s Globally-Distributed Database</h1><blockquote><p>Spanner是谷歌提出的一个可扩展、多版本、全球分布和支持同步复制的数据库。这是第一个在全球范围内分发数据并支持外部一致性的分布式系统</p></blockquote><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Spanner作为一个数据库，它由遍布全球的数据中心的许多Paxos状态机进行数据分片。Spanner会随着数据量或者服务器数量的变化自动在计算机之间重新分片数据，并自动在计算机之间迁移数据。应用程序可以通过跨大洲复制数据的方式来使用Spanner实现高可用性。</p><p>Spanner的主要重心在于管理跨数据中心的复制数据，但也花了不少时间在分布式系统架构上设计和实现重要的数据库功能。</p><p>作为全球分布的数据库，Spanner提供了一些有趣的功能。应用程序可以细粒度动态地控制数据的复制配置，支持在数据中心透明地移动数据，平衡资源使用，也对外提供外部一致的读写等等。</p><p>Spanner会为事务分配具有全局意义的提交时间戳，这里关键因素是新的TrueTime API及其实现。下面会重点介绍。</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>本章主要介绍Spanner实现的基础架构和原理。然后描述了目录抽象，最后则是描述了数据模型。</p><p>一个Spanner的部署被称为Universe，Spanner则被组织为一组区域，这是管理部署的单位和物理隔离的单位。下图描述了Spanner Universe的服务器，一个区域具有一个zone master和若干个spanserver，通过location proxy来定位提供服务的spannerver。universe master 和 placement driver则是一个单例，前者主要是一个控制台，后者则是定期与spanserver通信，以找出需要移动的数据。</p><p><img src="https://pic.downk.cc/item/5f15cfcd14195aa594670175.png" alt></p><h3 id="Spanserver-Software-Stack"><a href="#Spanserver-Software-Stack" class="headerlink" title="Spanserver Software Stack"></a>Spanserver Software Stack</h3><p>这一章主要讲spanserver的实现，软件架构如图所示，底部为每个spanserver负责的100-1000个称为tablet的数据结构，它实现了一组以下的的映射：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(key:string, timestamp:int64) → string</span><br></pre></td></tr></table></figure><p>tablet的状态存储在一个类似B树的文件和一个预写日志中，所有这些都存在一个叫Colossus的组件里。</p><p><img src="https://pic.downk.cc/item/5f17213614195aa594fd18a2.png" alt></p><p>为了支持复制，Spanserver都在每个tablet的顶部实现了Paxos状态机，用来存储其元数据和tablet的日志。这里的Paxos实现通过基于时间的leader租约来支持生命周期长的leader。Spanner的实现中会写两次Paxos日志，一次在tablet中，一次在Paxos日志里。</p><p>在leader副本中，Spanserver会实现一个锁表来做并发控制，这包含了两阶段锁的状态，能将key的范围映射到锁的状态。需要同步的操作（例如事务性读取）会在锁表中获取锁；其余操作绕过锁表。</p><p>另外，在leader副本中，spansever还实现了一个事务管理器来支持分布式事务。如果一个事物仅仅涉及到一个Paxos组，则可以绕过事务管理器。否则这些组的leader会协调执行两阶段提交。</p><h3 id="Directories-and-Placement"><a href="#Directories-and-Placement" class="headerlink" title="Directories and Placement"></a>Directories and Placement</h3><p>在一系列键值映射的上层，Spanner 实现支持一个被称为“目录”的桶抽象，为包含公共前缀的连续键的集合。一个目录是数据放置的基本单位，同一个目录下的所有数据具有相同的副本配置。当数据在不同的paxos组间移动时，会进行逐个目录的移动。如下图所示：</p><p><img src="https://pic.downk.cc/item/5f1c387614195aa594c3a268.png" alt></p><p>一个Paxos组包含了若干个目录，tablet不一定是一个行空间内按照字典顺序排序的分区，可以是行空间内的多个分区。Movedir 是一个后台任务，用来在不同的 Paxos 组之间转移目录，也可以用来为Paxos组增加或删除副本。</p><p>一个目录也是应用可以指定的放置策略的最小单元，一个应用就可以控制数据的复制。例如，一个应用可能会在自己的目录里存储每个终端用户的数据，这就有可能使得用户 A 的数据在欧洲有三个副本，用户 B 的数据在北美有 5 个副本。</p><p>当一个目录变得太大时，Spanner会进行分片存储。每个分片可能被保存到不同的Paxos组。Movedir在不同组之间不再是转移目录，而是转移分片。</p><h3 id="Data-Model"><a href="#Data-Model" class="headerlink" title="Data Model"></a>Data Model</h3><p>Spanner暴露给应用的数据特性包括了：基于模式化的半关系表数据模型，SQL类型的查询语言和通用事务。</p><p>应用的数据模型是在被目录桶装的键值层之上，一个应用会在一个universe中创建若干个数据库，每个数据库可以包含无限的模式化表。每个表都和关系数据库表类似，具备行、列和版本值。</p><h3 id="TrueTime"><a href="#TrueTime" class="headerlink" title="TrueTime"></a>TrueTime</h3><table><thead><tr><th>Method</th><th>Returns</th></tr></thead><tbody><tr><td>TT.now()</td><td>TTinterval: [earliest, latest]</td></tr><tr><td>TT.after(t)</td><td>true if t has definitely passed</td></tr><tr><td>TT.before(t)</td><td>true if t has definitely not arrived</td></tr></tbody></table><p>本章主要讲TrueTime API，但更多的内容在另一篇论文里。上面的表列出了API的方法，TrueTime是一款高度可用的分布式时钟，面向所有Google服务器上的应用提供，会把时间表达成一个时间区间TTinterval，具有一个有限的时间不确定性。TT.now()方法会返回一个 TTinterval，它可以保证包含调用TT.now()方法时的绝对时间。</p><p>在底层，TrueTime使用的时间是基于GPS和原子钟实现的，这两种类型的时间具有不同的失败模式。GPS的弱点是天线和接收器失效、局部电磁干扰等等。而由于频率误差，在经过很长的时间以后，原子钟也会产生明显误差。</p><p>TrueTime是由每个数据中心里的许多time master机器和每个机器上的一个timeslave daemon实现的。大多数master都具备专门的相互隔离的GPS接收器，而剩余的master则会配置了原子钟。所有master的时间参考值会进行彼此校对，每个master也会交叉检查时间参考值和本地时间的比值，如果二者差别太大，就会把自己踢出去。</p><p>每个daemon会从许多master中收集投票，获知时间参考值，根据确定的界限，来剔除本地时钟误差较大的机器。</p><p>在同步期间，一个daemon会表现出逐渐增加的时间不确定性。ε是从应用的最差时钟漂移中得到的。ε取决于time master的不确定性，以及与time master之间的通讯延迟。论文提到的线上应用环境里，ε通常是一个关于时间的锯齿函数，在1到7ms之间变化。</p><h2 id="Concurrency-Control"><a href="#Concurrency-Control" class="headerlink" title="Concurrency Control"></a>Concurrency Control</h2><p>本章主要讲trueTime是如何保证并发控制的正确性，简单来说则是实现这样的特性：在时间戳为t的读操作，一定能看到在t时刻之前提交的事务。</p><h3 id="Timestamp-Management"><a href="#Timestamp-Management" class="headerlink" title="Timestamp Management"></a>Timestamp Management</h3><p>Spanner支持三种操作类型：读写事务、只读事务和快照读取。独立的写操作会被当作读写事务执行，而非快照的独立读取操作则会被当作只读事务执行。</p><p>一个只读事务是不需要锁机制的，通过选取系统的时间戳来执行，不会阻塞后续到达的写操作。而快照读操作同样不需要锁机制。这两个都可以在任意足够新的副本上执行。</p><h4 id="Paxos-Leader-Leases"><a href="#Paxos-Leader-Leases" class="headerlink" title="Paxos Leader Leases"></a>Paxos Leader Leases</h4><p>Spanner的Paxos实现中通过时间化的租约，来确保长时间的leader角色（默认10s）。</p><p>一个潜在的leader可以发起请求，请求时间化的租约投票，在收到一定数量的投票后，就可以确保自己拥有租约。另外，当一个副本成功完成一个写操作，会隐式延长自己的租约。而租约快要到期时，则会显式请求延长租约。leader的租约有一个时间区间，起点是收到指定数量投票的那一刻，终点则是由于租约过期而失去一定数量投票的那一刻。注意，每个Paxos leader的租约时间区间和其他leader的时间区间是完全隔离的。</p><p>而Paxos leader的退位则可以通过将slave从投票集合中释放的方式来实现，一个leader必须等到TT.after(smax)是真才能发起退位。</p><h4 id="Assigning-Timestamps-to-RW-Transactions"><a href="#Assigning-Timestamps-to-RW-Transactions" class="headerlink" title="Assigning Timestamps to RW Transactions"></a>Assigning Timestamps to RW Transactions</h4><p>事务读写会采用两阶段锁协议，获得所有的锁之后，就可以给事务分配时间戳，这个时间戳是Paxos写操作的，代表了事务提交的时间。在每个Paxos组内，会以单调递增的方式分配时间戳，这个比较好实现。而对于跨越多个leader的情况，一个leader只能分配属于自己租约区间的时间戳。一旦时间戳s被分配，上面提到的smax会变成s。</p><p>另外，Spanner也实现了外部一致性：如果一个事务T2在事务T1提交以后开始执行，那么事务T2的时间戳一定大于事务T1的时间戳。简单来说，写进去的数据能够立即被读到，在被修改之前，读到的数据都是一样的。</p><h4 id="Serving-Reads-at-a-Timestamp"><a href="#Serving-Reads-at-a-Timestamp" class="headerlink" title="Serving Reads at a Timestamp"></a>Serving Reads at a Timestamp</h4><p>上面提到的特性，可以使得spanner可以正确地确定副本是否足够新，每个副本会记录一个安全时间值Tsafe，表示副本最近更新后的最大时间，当读操作的时间戳t小于或等于Tsafe的时候，读操作就可以在这个副本上读取。</p><h4 id="Assigning-Timestamps-to-RO-Transactions"><a href="#Assigning-Timestamps-to-RO-Transactions" class="headerlink" title="Assigning Timestamps to RO Transactions"></a>Assigning Timestamps to RO Transactions</h4><p>只读事务会分成两个阶段执行：分配时间戳sread，然后按照sread的快照读去执行事务操作。在事务开始后的任意时刻，可以分配sread=TT.now().latese。由于Tsafe的存在，或者smax的变化，sread时刻的读操作有可能被阻塞。因为Spanner最好是分配一个可以保持外部一致性的最大时间戳。</p><h3 id="Details"><a href="#Details" class="headerlink" title="Details"></a>Details</h3><h4 id="Read-Write-Transactions"><a href="#Read-Write-Transactions" class="headerlink" title="Read-Write Transactions"></a>Read-Write Transactions</h4><p>Spanner的读写事务，客户端对位于合适位置的组内leader副本发起读操作时，会先获取读锁，然后读取最新的数据。当一个客户端完成了所有的读操作后，会在客户端缓存所有的写操作，开始两阶段提交。客户端选择一个协调组，并且发送提交信息给所有参与的协调者leader，同时发送信息给所有缓冲的写操作。</p><p>每个参与其中的、非协调者leader会先获取写锁，然后选择一个合适的时间戳，并通过Paxos将准备提交记录写入日志。最后，这些leader会将自己的准备时间戳告诉协调者。</p><p>此时，扮演协调者的leader也会先获取写锁，然后选择一个事务时间戳，这个时间戳s必须大于或等于从前面获取到的准备时间戳信息，并且应该大于TT.now().latest。这样，这个leader，就会通过Paxos写入一个提交记录到日志，然后开始commit wait，即该leader会一直等待到TT.after(s)为true，最后发送一个提交时间戳给客户端和所有参与的leader。</p><p>每个参与的领导者会通过Paxos把事务结果写入日志。所有的参与者会在同一个时间戳进行提交，释放锁。</p><h4 id="Read-Only-Transactions"><a href="#Read-Only-Transactions" class="headerlink" title="Read-Only Transactions"></a>Read-Only Transactions</h4><p>分配只读事务的时间戳存在三种方案：</p><ul><li>事务开始时，根据一个表达式确定事务参与者，然后这些参与者的Paxos组之间协调，根据各自的LastTS()进行协商选出一个合适的时间戳；</li><li>对于在单个Paxos组上的读取，直接获取该Paxos组的最后提交的写操作的时间戳；</li><li>TT.now().latest；</li></ul><p>通过选择一个合适的时间戳，然后在相应的节点确认不会发生读写冲突、不会有复制协议的落后的情况下，可以处理这个读请求了。</p><h4 id="Schema-Change-Transactions"><a href="#Schema-Change-Transactions" class="headerlink" title="Schema-Change Transactions"></a>Schema-Change Transactions</h4><p>TrueTime允许Spanner支持原子模式变更。模式变更事务通常是一个标准事务的、非阻塞的变种。它会显式地分配注册一个未来的时间戳，由于读写操作都会依赖于模式，因此当它们的时间戳小于t时，读写操作就会执行到时刻t；大于t时，读写操作必须阻塞，在模式变更事务后进行等待。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Spanner的理论最大亮点还是trueTime，相当于用基于原子钟的时间戳当做版本号，提高数据库的并发效率。Spanner实现的是Multi-Paxos，会有一个long-live的leader，但Spanner对Paxos的实现提及不多。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Spanner-Google’s-Globally-Distributed-Database&quot;&gt;&lt;a href=&quot;#Spanner-Google’s-Globally-Distributed-Database&quot; class=&quot;headerlink&quot; title=&quot;
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Object Storage on CRAQ——MIT6.824</title>
    <link href="http://yoursite.com/2020/05/22/Object-Storage-on-CRAQ%E2%80%94%E2%80%94MIT6-824/"/>
    <id>http://yoursite.com/2020/05/22/Object-Storage-on-CRAQ——MIT6-824/</id>
    <published>2020-05-21T18:03:03.000Z</published>
    <updated>2020-05-21T18:04:00.196Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Object-Storage-on-CRAQ"><a href="#Object-Storage-on-CRAQ" class="headerlink" title="Object Storage on CRAQ"></a>Object Storage on CRAQ</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>该论文描述了一种CRAQ(Chain Replication with Apportioned Queries)的对象存储设计，通过链式备份，能够在保证读取吞吐率的同时维持强一致性。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>对象存储是许多在线服务所需要的，其数据会以一个实体单元来呈现。对象存储支持两种基本原语：读和写。后续，有人开始提出用链式备份的方法来做对象存储，基本思路是将所有存储对象的节点组织在一条链中，其中尾部提供读取请求，而头部则处理所有的写入请求。然后在客户端得到确认之前，写操作会沿着链向后传播。</p><p>但这种思路会有不少局限，比如因为所有的读取都会走到同一个节点。该论文就提出了一种CRAQ的设计，实现了一个能够提供强一致性，并且写入低延迟和高吞吐的对象存储。</p><p>主要的设计如下：</p><ol><li>CARQ所有节点都会处理读请求；</li><li>除了强一致性，CARQ也能为了低延迟对读操作支持最终一致性；</li><li>利用负载均衡特性，提出了一种广域的系统设计，用于跨地理分布的集群来构建CRAQ链，同时保留强大的局部性；</li></ol><h2 id="Basic-System-Model"><a href="#Basic-System-Model" class="headerlink" title="Basic System Model"></a>Basic System Model</h2><p>这一章介绍链式复制模型的主要概念。</p><h3 id="Interface-and-Consistency-Model"><a href="#Interface-and-Consistency-Model" class="headerlink" title="Interface and Consistency Model"></a>Interface and Consistency Model</h3><p>一个对象存储系统主要提供两个基本原语：</p><ul><li>write(objID, V);</li><li>V &lt;—— read(objID);</li></ul><p>另外，论文提及了系统实现的两种一致性类型。</p><ul><li>强一致性：对于一个对象的读写操作会以某个顺序执行，并且读取对象时会看到最近的写入值；</li><li>最终一致性：对于不同的节点的读取可能会返回过时的数据；</li></ul><h3 id="Chain-Replication"><a href="#Chain-Replication" class="headerlink" title="Chain Replication"></a>Chain Replication</h3><p>Chain Replication（CR）是一种在多节点之间备份数据，提供强一致性存储接口的方法。</p><p>简单来说就是，节点组成一个链表，所有的写请求由链表头部接收，然后向后传导，直到到达尾部节点（此时视为committed）。然后尾部节点将会将响应返回到头部，由头部响应成功（因为实际实现使用的是TCP）。</p><p>读请求则是由尾部节点接收。</p><p><img src="https://pic.downk.cc/item/5eaf0238c2a9a83be5078e18.png" alt></p><h3 id="Chain-Replication-with-Apportioned-Queries"><a href="#Chain-Replication-with-Apportioned-Queries" class="headerlink" title="Chain Replication with Apportioned Queries"></a>Chain Replication with Apportioned Queries</h3><p>对于读取请求比较多的场景，CARQ会通过本地读取来尝试提高读取吞吐量。具体设计如下：</p><ol><li>CARQ的节点会存储对象的多个版本，并且会标示每个版本是dirty还是clean；</li><li>当一个节点得到新版本的写入，会追加到版本列表中；<ol><li>如果节点不是尾节点，则标示该版本是dirty的；</li><li>如果是尾节点，则直接标示为clean，然后通过链条去答应通知前面的节点；</li></ol></li><li>前面的节点收到响应后，得知某个版本的节点可以修改为clean；</li><li>如果一个节点得到了对象的读取请求；<ol><li>如果对象最后一个节点是clean的，则马上响应；</li><li>否则，节点会联系尾节点，询问尾部节点最后一个committed版本。</li></ol></li></ol><p>具体效果如图所示：</p><p><img src="https://pic.downk.cc/item/5eafce3cc2a9a83be58fe0d0.png" alt></p><h3 id="Consistency-Models-on-CRAQ"><a href="#Consistency-Models-on-CRAQ" class="headerlink" title="Consistency Models on CRAQ"></a>Consistency Models on CRAQ</h3><p>CRAQ提供了三种一致性模型：</p><ul><li>强一致性（默认的）：如上述所示；</li><li>最终一致性：允许读取时返回本地已知的最新的对象版本；</li><li>最大界限的最终一致性：允许读取请求返回最新的写入对象，即便该对象还没有commit。但会提供一个限制，比如基于特定时间内存的写入，或者某个绝对的版本；</li></ul><h3 id="Failure-Recovery-in-CRAQ"><a href="#Failure-Recovery-in-CRAQ" class="headerlink" title="Failure Recovery in CRAQ"></a>Failure Recovery in CRAQ</h3><p>双向链表的模式，即一个节点可以知道其后继节点和前驱节点，保证在节点失败时，由其周围的节点去接手。</p><h2 id="Scaling-CRAQ"><a href="#Scaling-CRAQ" class="headerlink" title="Scaling CRAQ"></a>Scaling CRAQ</h2><p>在本节中，我们讨论应用程序如何在CRAQ中指定单个数据中心内和多个数据中心内的部署方案</p><h3 id="Chain-Placement-Strategies"><a href="#Chain-Placement-Strategies" class="headerlink" title="Chain Placement Strategies"></a>Chain Placement Strategies</h3><p>一个分布式应用需要面临很多问题，比如对象的大多数写入可能位于同一个数据中心，一些对象只与数据中心的子集有关，重要的对象可能需要不同的副本策略。</p><p>CARQ提供了更加灵活的链式配置策略，对于对象来说，使用的是链表ID和key ID结合的两层命名结构，另外就是配置的策略：</p><ul><li>Implicit Datacenters &amp; Global Chain Size: {num_datacenters, chain_size}</li></ul><p>简单来说，就是定一个存储链的数据中心数量，通过对数据中心ID作一致性哈希来明确标识唯一的数据中心；</p><ul><li>Explicit Datacenters &amp; Global Chain Size: {chain_size, dc1, dc2, …, dcN}</li></ul><p>这个方法是每个数据中心都适用相同大小的链表去存储备份，链表头部位于dc1的节点，链表尾部则在dc2的其中一个节点，以此类推；</p><ul><li>Explicit Datacenter Chain Sizes: {dc1, chain_size1, …, dcN, chain_sizeN}</li></ul><p>与上面的方法类似，但每个数据中心的链表大小不同；</p><h3 id="CRAQ-Across-Multiple-Datacenters"><a href="#CRAQ-Across-Multiple-Datacenters" class="headerlink" title="CRAQ Across Multiple Datacenters"></a>CRAQ Across Multiple Datacenters</h3><p>CRAQ本地读取的方法降低了延迟，client也可以灵活选择距离更近的节点。</p><p>另一方面，通过链优化，应用程序可以选择组成链的数据中心顺序来最大程度降低写入延迟，确保单个链在每个方向上仅仅需要跨越数据中心的网络边界一次。随着节点增加，很可能写延迟也会明显增加，但相比主备的方法，流水线的写操作可以极大地写入吞吐量。</p><h3 id="ZooKeeper-Coordination-Service"><a href="#ZooKeeper-Coordination-Service" class="headerlink" title="ZooKeeper Coordination Service"></a>ZooKeeper Coordination Service</h3><p>CARQ使用zookeeper来追溯成员身份，并存储链元数据。另外就是当添加或者删除节点时，可以确保CARQ节点能够收到通知。</p><p>由于不了解数据中心原始的拓扑结构，因此Zookeeper节点之间的协调消息会在广域网上多次传输。为了消除跨数据中心ZooKeeper冗余的通讯，一个方法是可以构建一个Zookeeper实例的层次结构：每个数据中心可以包含其自己的本地ZooKeeper实例（由多个节点组成），并具有一个参与全局ZooKeeper实例的代表。另一个方法是，修改ZooKeeper本身以使节点知道网络拓扑。</p><h2 id="Extensions"><a href="#Extensions" class="headerlink" title="Extensions"></a>Extensions</h2><p>本章主要讲述了CARQ的一些拓展点</p><h3 id="Mini-Transactions-on-CRAQ"><a href="#Mini-Transactions-on-CRAQ" class="headerlink" title="Mini-Transactions on CRAQ"></a>Mini-Transactions on CRAQ</h3><p>对于某些应用来说，简单的对象存储读写可能比较局限。有些应用可能需要支持批量操作，有些可能需要有权限控制。因此CARQ提供了拓展功能来支持事务操作。</p><h4 id="Single-Key-Operations"><a href="#Single-Key-Operations" class="headerlink" title="Single-Key Operations"></a>Single-Key Operations</h4><p>CRAQ支持几种单key操作：</p><ul><li>Prepend/Append: 在一个对象的当前值上追加data；</li><li>Increment/Decrement: 递增或者递减一个key的对象；</li><li>Test-and-Set: 只有在当前版本与指定版本匹配时才会更新对象；</li></ul><p>对于前面两种操作来说，可以直接对链表的头节点进行apply，而不用管它的节点是clean还是dirty，应用完之后向后传播就行。</p><p>而对于Test-and-Set操作来说，CARQ并不会锁住对象，而是版本不匹配的时候直接返回。</p><h4 id="Single-Chain-Operations"><a href="#Single-Chain-Operations" class="headerlink" title="Single-Chain Operations"></a>Single-Chain Operations</h4><p>Sinfonia最近提出的mini-transactions可以支持对单个链的多个key进行事务操作。它使用了乐观的两阶段提交协议，在prepare阶段会尝试在每个指定的内存地址上获取一个锁。如果可以锁定所有的地址，则协议提交。否则会释放所有的锁并进行充实。在CRAQ中，由于可以指定多个对象存储在同一个链表中，因此这里的两阶段提交减少到单个的交互，即使用单个头部节点则可以接受访问。</p><h4 id="Multi-Chain-Operations"><a href="#Multi-Chain-Operations" class="headerlink" title="Multi-Chain Operations"></a>Multi-Chain Operations</h4><p>对于多链参与多对象更新，优化的两阶段协议提交只需要用多个链表头部节点实现即可，链表锁住所有参与事务的keys，直到满足提交条件。</p><p>当然这个方法没办法pipeline实现，在一定程度上会影响吞吐量。</p><h3 id="Lowering-Write-Latency-with-Multicast"><a href="#Lowering-Write-Latency-with-Multicast" class="headerlink" title="Lowering Write Latency with Multicast"></a>Lowering Write Latency with Multicast</h3><p>CARQ使用多播协议来提高写入性能，由于链的成员资格在节点成员资格改变时是相对文婷的，因此可以为每个链创建一个多播组。然后，不是在整个链上串行传播完整的写入，而是将真实值多播到整个链表，然后紧紧在链上传播少量的元数据信息，以确保所有的副本都在尾部之前收到写操作。</p><p>如果存在节点由于某种原因未接收到多播，则该节点可以在接收到写入提交消息之后，然后进一步传播提交消息之前，从其前任中获取对象。</p><p>另外，当尾部节点接收到传播的写请求时，可以将多播确认消息发送到多播组，而不是将其沿链向后传播。这样既减少了节点对象在写入后重新进入清洁状态所花费的时间，又减少了客户端感知的写入延迟。如果链中的某个节点未收到确认，则当下一个读取操作要求它查询尾部时，它将重新进入clean。</p><h2 id="Management-and-Implementation"><a href="#Management-and-Implementation" class="headerlink" title="Management and Implementation"></a>Management and Implementation</h2><h3 id="Integrating-ZooKeeper"><a href="#Integrating-ZooKeeper" class="headerlink" title="Integrating ZooKeeper"></a>Integrating ZooKeeper</h3><p>CRAQ使用zookeeper的文件结构来维持数据中心中节点列表的成员资格。</p><p>在初始化时，一个CRAQ节点会创建一个临时文件(/nodes/dc_name/node_id)，dc_name就是数据中心的唯一名称，no de_id就是数据中节点的唯一ID。文件内容则是包含了节点的ip地址和端口号。</p><p>CRAQ可以查询/nodes/dc_name，来判断数据中的成员资格，通过添加一个watch到/nodes/dc_name，就可以被通知到节点的添加或者删除。</p><p>/chains/chain_id则是在CRAQ节点收到创建新链表的请求时，会创建一个文件，chain_id是一个160位的唯一标识符，文件内容时链表的配置策略。而节点通过监控链表文件，从而保证在链表元数据改变时得到通知。</p><h3 id="Chain-Node-Functionality"><a href="#Chain-Node-Functionality" class="headerlink" title="Chain Node Functionality"></a>Chain Node Functionality</h3><p>节点在加入系统时会生成一个随机标识符每个数据中心内会使用该标识符作为one-hop DHT。节点之间或者节点与客户端之间的RPC通信都是通过TCP连接进行的。每个节点及其链的前任，后继和尾部维护着一组连接的TCP连接。请求通过这些连接进行管道传输和循环轮询。</p><p>对于跨多个数据中心的链，一个数据中心的最后一个节点保持与其后继数据中心的第一个节点的连接。当外部数据中心中的节点列表发生更改时，订阅更改的节点可以从其本地ZooKeeper中接收通知。</p><h3 id="Handling-Memberships-Changes"><a href="#Handling-Memberships-Changes" class="headerlink" title="Handling Memberships Changes"></a>Handling Memberships Changes</h3><p>对于正常的写传播，CRAQ节点遵循前面的协议。在恢复过程中，有时需要第二种传播方式，即反向传播。例如链表节点可能会在完成向后传播到头部节点之前失败。由于这些可能的故障状况，当新节点加入系统时，新节点会从其前任节点接收传播消息，并从其后继节点接收反向传播消息，以确保其正确性。新节点拒绝客户端对特定对象的读取请求，直到其与后继对象达成协议为止。</p><p>无论是节点添加或者删除，变更的节点对应的后继者或者前驱节点都需要传播足够的信息以确保链表的一致性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Object-Storage-on-CRAQ&quot;&gt;&lt;a href=&quot;#Object-Storage-on-CRAQ&quot; class=&quot;headerlink&quot; title=&quot;Object Storage on CRAQ&quot;&gt;&lt;/a&gt;Object Storage on CR
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Golang内存模型</title>
    <link href="http://yoursite.com/2020/04/04/Golang%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2020/04/04/Golang内存模型/</id>
    <published>2020-04-04T14:36:02.000Z</published>
    <updated>2020-04-04T14:37:48.226Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Golang内存模型"><a href="#Golang内存模型" class="headerlink" title="Golang内存模型"></a>Golang内存模型</h1><blockquote><p>参考自：<a href="https://golang.org/ref/mem" target="_blank" rel="noopener">https://golang.org/ref/mem</a></p></blockquote><p>Golang的内存模型描述了这样的一种场景：在一个goroutine中对一个变量的读取能保证是由不同gorountine写入相同变量所产生的。</p><h2 id="Happens-Before"><a href="#Happens-Before" class="headerlink" title="Happens Before"></a>Happens Before</h2><p>在单个goroutine中，只有在满足不改变语言规范所定义的行为时，编译器才能对单个goroutine所执行的读写进行重新排序。但由于重新排序，一个goroutine所观察到的执行顺序可能与另一个goroutine察觉到的执行顺序不同。</p><p>为了指定读写要求，在go程序中定义了一个叫Happens Before的偏序关系——如果事件e1发生在事件e2之前，那么我们说e2发生在e1之后。同样，如果e1不在e2之前发生并且在e2之后也没有发生，那么我们说e1和e2同时发生。</p><p>在单个goroutine中，Happens Before的顺序就是程序所表现出来的顺序。</p><p>为了保证对变量的读取R可以读取到由特定的对变量的写入W，即W是R可以观察到的唯一写入，必须要满足以下两个条件：</p><ol><li>W发生到R之前；</li><li>任何对变量的其他写入要么发生在w之前，要么发生在r之后；</li></ol><p>变量的初始化为零值，其实也是内存模型中的零值写入。</p><h2 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h2><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>程序的初始化是在单个goroutine中进行的，但goroutine可以创建其他goroutine，这是并发的。</p><p>如果一个package引入了另一个package，即被引入的package会先初始化。</p><p>main.main的开始必须要在所有init函数完成之后。</p><h3 id="Goroutine的创建"><a href="#Goroutine的创建" class="headerlink" title="Goroutine的创建"></a>Goroutine的创建</h3><p>以下面的为例子，f()打印出hello world可能会在hello()结束后才打印。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">hello</span><span class="params">()</span></span> &#123;</span><br><span class="line">a = <span class="string">"hello, world"</span></span><br><span class="line"><span class="keyword">go</span> f()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Goroutine的销毁"><a href="#Goroutine的销毁" class="headerlink" title="Goroutine的销毁"></a>Goroutine的销毁</h3><p>无法保证goroutine的退出在程序中的任何其他事件发生之前发生。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">hello</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; a = <span class="string">"hello"</span> &#125;()</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对a的赋值很可能在下面的print中看不到，因为缺乏同步。</p><h3 id="Channel的同步"><a href="#Channel的同步" class="headerlink" title="Channel的同步"></a>Channel的同步</h3><p>通道通信是goroutine之间同步的主要方法。channel的发送必定发生在该channel接受完成之前。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> c = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">10</span>)</span><br><span class="line"><span class="keyword">var</span> a <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line">a = <span class="string">"hello, world"</span></span><br><span class="line">c &lt;- <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> f()</span><br><span class="line">&lt;-c</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就能保证打印出hello, world。</p><p>另外，channel的关闭会发生在返回零值的接收之前，这样用close(c)替代c&lt;-0也可以产生相同的保证行为。</p><p>而对于缺乏buffer的channel，其接收会发生在该channel的发送完成之前，例如这样也可以保证打印出正确的hello world，这里的发送和接收顺序与上面的例子相反。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> c = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line"><span class="keyword">var</span> a <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line">a = <span class="string">"hello, world"</span></span><br><span class="line">&lt;-c</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> f()</span><br><span class="line">c &lt;- <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但如果channel是带有buffer，就无法保证打印出hello world了。</p><p>在容量为C的通道上的第k个接收发生在该通道的第k + C个发送完成之前，因为不从channel接收数据就无法继续写入。</p><p>该规则将前一个规则推广到缓冲通道。 它允许通过缓冲的通道对计数信号量进行建模：channel中的项目数量对应于活动使用的数量，channel的容量对应于同时使用的最大数量，发送一个项目获取信号量，接收项目则会释放信号量。通过这种操作就可以限制其并发。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> limit = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> _, w := <span class="keyword">range</span> work &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(w <span class="keyword">func</span>()</span>)</span> &#123;</span><br><span class="line">limit &lt;- <span class="number">1</span></span><br><span class="line">w() <span class="comment">// 不处理完成，无法释放该信号量</span></span><br><span class="line">&lt;-limit</span><br><span class="line">&#125;(w)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">select</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Locks"><a href="#Locks" class="headerlink" title="Locks"></a>Locks</h3><p>sync包里实现了两种锁相关的数据类型：sync.Mutex和sync.RWMutex。通过锁的使用，我们可以在goroutine中保证同步。这样的一个程序就可以顺利打印出hello world。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> l sync.Mutex</span><br><span class="line"><span class="keyword">var</span> a <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line">a = <span class="string">"hello, world"</span></span><br><span class="line">l.Unlock()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">l.Lock()</span><br><span class="line"><span class="keyword">go</span> f()</span><br><span class="line">l.Lock()</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Once"><a href="#Once" class="headerlink" title="Once"></a>Once</h3><p>sync包还提供了一种初始化的安全机制，通过使用Once数据类型，多个线程都可以执行once.Do(f)，但只有一个会运行f()，其他的调用将会block直接f()返回。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="keyword">string</span></span><br><span class="line"><span class="keyword">var</span> once sync.Once</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">setup</span><span class="params">()</span></span> &#123;</span><br><span class="line">a = <span class="string">"hello, world"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doprint</span><span class="params">()</span></span> &#123;</span><br><span class="line">once.Do(setup)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">twoprint</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> doprint()</span><br><span class="line"><span class="keyword">go</span> doprint()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这种机制下，a的赋值将会在打印之前执行。</p><h3 id="Incorrect-synchronization"><a href="#Incorrect-synchronization" class="headerlink" title="Incorrect synchronization"></a>Incorrect synchronization</h3><p>需要注意的是读取R可能会观察到与R同时发生的写入W所写入的值，但这并不意味着在R之后的读取会观察到在W之前所发生的写入。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a, b <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line">a = <span class="number">1</span></span><br><span class="line">b = <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">g</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> f()</span><br><span class="line">g()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里可能发生的情况是g()打印出了2和0，也就是即便g()已经读取了f()里面对b的写入，但这不意味着g()里面的a能够读取到f()中在b写入之前的a。</p><p>同理，类似的错误也会发生在同步的使用：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="keyword">string</span></span><br><span class="line"><span class="keyword">var</span> done <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">setup</span><span class="params">()</span></span> &#123;</span><br><span class="line">a = <span class="string">"hello, world"</span></span><br><span class="line">done = <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doprint</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> !done &#123;</span><br><span class="line">once.Do(setup)</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">twoprint</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> doprint()</span><br><span class="line"><span class="keyword">go</span> doprint()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里并不意味着能够观察到done设置为true，就隐式地说明a已经被初始化。</p><p>另一种典型错误则是忙等，这种情况下并不意味着done被设置为true后，能够表示a已经被初始化，可以跳出for循环。真实情况是，此时print(a)，a可能还是空字符串。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="keyword">string</span></span><br><span class="line"><span class="keyword">var</span> done <span class="keyword">bool</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">setup</span><span class="params">()</span></span> &#123;</span><br><span class="line">a = <span class="string">"hello, world"</span></span><br><span class="line">done = <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> setup()</span><br><span class="line"><span class="keyword">for</span> !done &#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>应对这些问题也很简单，使用显式地同步。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Golang内存模型&quot;&gt;&lt;a href=&quot;#Golang内存模型&quot; class=&quot;headerlink&quot; title=&quot;Golang内存模型&quot;&gt;&lt;/a&gt;Golang内存模型&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;参考自：&lt;a href=&quot;https://gola
      
    
    </summary>
    
    
      <category term="Golang" scheme="http://yoursite.com/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>decltype in c++11</title>
    <link href="http://yoursite.com/2019/12/20/decltype-in-c-11/"/>
    <id>http://yoursite.com/2019/12/20/decltype-in-c-11/</id>
    <published>2019-12-19T17:59:14.000Z</published>
    <updated>2019-12-19T17:59:45.016Z</updated>
    
    <content type="html"><![CDATA[<h1 id="decltype"><a href="#decltype" class="headerlink" title="decltype"></a>decltype</h1><p>decltype是c++11引入的类型推导标记符，与auto类似。基本语法比较简单，就是给一个表达式，返回表达式的类型：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">decltype</span> ( expression )</span><br></pre></td></tr></table></figure><p>这里只会查询表达式的返回类型，并不会对表达式进行求值。</p><p>decltype的判断规则是比较复杂的，主要分为以下几类：</p><ul><li>如果参数是无括号的标识表达式或无括号的类成员访问表达式，decltype会返回以该表达式命名的实体类型。但如果参数是一个重载函数，则会编译错误；</li><li>若参数是其他类型为 <code>T</code> 的任何表达式<ul><li>表达式的值类型为临时值/亡值，则会返回T&amp;&amp;；</li><li>表达式的值类型为左值，则会参会T&amp;；</li><li>纯右值，则会返回T；</li></ul></li></ul><p>需要注意的是，如果对象的名字带有括号，则它被当做通常的左值表达式，从而 decltype(x) 和 decltype((x)) 通常是不同的类型。</p><p>举个简单的例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span> &#123;</span> <span class="keyword">double</span> x; &#125;;</span><br><span class="line"><span class="keyword">const</span> A* a;</span><br><span class="line"><span class="keyword">int</span> i=<span class="number">10</span>;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">decltype</span>(a-&gt;x) y;       <span class="comment">// y 的类型是 double（其声明类型）</span></span><br><span class="line"><span class="keyword">decltype</span>((a-&gt;x)) z = y; <span class="comment">// z 的类型是 const double&amp;（被当作左值表达式）</span></span><br><span class="line"><span class="keyword">decltype</span>((i))b = i;   <span class="comment">// b 的类型是 int&amp;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者用在无名函数的类型推导上</span></span><br><span class="line"><span class="keyword">auto</span> f = [](<span class="keyword">int</span> a, <span class="keyword">int</span> b) -&gt; <span class="keyword">int</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> a * b;</span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">decltype</span>(f) g = f; </span><br><span class="line">i = f(<span class="number">2</span>, <span class="number">2</span>);</span><br><span class="line">j = g(<span class="number">3</span>, <span class="number">3</span>);</span><br></pre></td></tr></table></figure><p>在日常编程中，用到decltype的情况还是比较少的，我们一般用在模版中，结合auto和尾返回类型，我们可以写出语言级别支持的简洁代码：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span><br><span class="line">auto foo(T t, U u) -&gt; decltype(t + u) &#123; return t + u; &#125;</span><br></pre></td></tr></table></figure><p>另外，要判断是否为左值，可以考虑使用c++11标准库提供的模版类来做检查：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">is_lvalue_reference&lt;<span class="keyword">decltype</span>(++i)&gt;::value;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;decltype&quot;&gt;&lt;a href=&quot;#decltype&quot; class=&quot;headerlink&quot; title=&quot;decltype&quot;&gt;&lt;/a&gt;decltype&lt;/h1&gt;&lt;p&gt;decltype是c++11引入的类型推导标记符，与auto类似。基本语法比较简单，就是给一
      
    
    </summary>
    
    
      <category term="C++" scheme="http://yoursite.com/tags/C/"/>
    
  </entry>
  
</feed>
